From ryan@whitewolf.com.au Mon, 01 May 2000 12:55:31 +1000
Date: Mon, 01 May 2000 12:55:31 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Java Processes: Final Summary?

Gilbert Carl Herschberger II wrote:

> With a certain level of redirection, a system-wide object might be "owned"
> by one or more processes if a list inside the object holds a reference to
> each process. At the machine code level, all objects are owned by a virtual
> machine.

This points out the problem with this approach. The JVM spec says that
an Object has a reference to exactly one java.lang.Class, and a Class
has a reference to exactly one java.lang.ClassLoader. 

> This is the best thing I've heard all week. We can provide a function to
> "move" an object from one user process to another. In other words, an
> object can be passed to another process simply by modifying its Process
> property.

Or more likely, by modifying the class loader reference (to a class
loader that shares the same class definition for that object). This will
be a primordial class loader, so this will provide an indirect reference
to the process if you need it.

> I can imagine that a DatagramPacket can be "sent" to another user process
> by updating its Process property from a protocol stack to a user process.
> Since the protocol stack no longer owns the object, it can be garbage
> collected in the usual way.

These protocol stack optimisations do not, however, depend on changing
the ownership of an object (ie. the datagram). The datagram will still
be garbage collected when there are no more references to it.

> The idea of moving an object around, from process to process, is a strong
> point of Java technologies. The same function could move an object from one
> machine to another.

And "sharing objects" is an extension of this concept. Rather than
changing the owner, you can *add* an owner. Well, there are two ways you
might share an object: a) share ownership, and b) have a single owner
but share access. The latter is easier to implement and less
controversial, so we will probably do that first (down below, I point
out that they may actually both be the same thing, implementation-wise).

> There is only one catch. A complex object could not be moved from one
> process to another without moving all of its dependent objects. While it
> might be good for shallow moves, it could not be automatic for deep moves.

Although a partial move is not illegal. For example, if we only move the
root object, then it is considered to simply have a reference to an
object in another process, which we have already discussed as being ok.

> >Sharing by proxy is another idea again. But we can share an object
> >between multiple processes and still have a single owner.
> 
> A directory entry is a proxy for a file's payload. A directory and payload
> are separate. An object proxy is like a directory entry. A proxy is owned
> by exactly one process. Behind the scenes, a proxy has an object property.
> The object property always points to an object owned by the system process.

This is the approach I like, but I'd replace "the system process" with
"a system process", sort of like a shared object broker process. So,
shared ownership can be emulated by taking ownership away all of the
participating processes and giving it to a single, independent master
process: the shared object broker.

This is not to say that processes are forced to share ownership when
sharing processes; They can still share access but retain sole ownership
(ie. the original process is taking on the responsibility of the shared
object broker for this particular object).

Also, whether or not the shared object reference is a proxy or not is a
different question.

> I believe a proxy will be more efficient than direct references. When the
> Process property of each object is an item, it is very easy for the process
> to be de-referenced. It is straight forward.
> 
> The idea of maintaining a list (see above) of processes makes it simple to
> maintain process information but makes it difficult to de-reference. The
> complexity is this: a process object returned from getProcessList() belongs
> to another process. The implications of this are incomprehensible.

I think I comprehend them. :=) Let's make an analogy with Threads. One
thread has a reference to another thread running in the same process,
but when that thread terminates, the first thread still has a reference
to that thread. All that has happened is that the referenced thread has
moved into the DEAD state, and it has been removed from the scheduler.
As soon as the first thread releases its reference, the garbage (that's
what it is) can be collected.

I don't see a problem with handling references to processes in the same
way. If the referenced process exits, it moves into the DEAD state. When
a process is dead, the object does not need to be thrown away
immediately. In fact, it needs to hang around so the caller can call
java.lang.Process.exitValue().

So, I see both direct sharing and proxy sharing as useful. Proxy sharing
would be implemented on top of the primitive direct sharing
functionality.

BTW, in the case of sharing JavaProcesses, the user-space shared object
broker will probably not be the one to manage the shared instances.
JavaProcesses will probably be owned by the KernelClassLoader. Same
principle but different broker.

> When each object belongs to exactly one process, the implications are easy
> to understand (easy to code) and limit the object sharing to a centralized API.

I agree that it is simpler. And shared object ownership can be emulated
by having a broker process.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Mon, 01 May 2000 13:00:42 +1000
Date: Mon, 01 May 2000 13:00:42 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Java Processes: Final Summary?

"Todd L. Miller" wrote:
> 
>         w.r.t. to the ownership of JavaProcess objects, it has occured to
> me that we could do things the UNIX way.  getJavaProcess() does not return
> the process object used by the VM, but an object wrapping a pid with
> whatever functions we feel are appropriate.

Proxies are not required to do this (as I explained in response to
Gilbert's email). JavaProcesses would still be owned by the system, but
access does not need to be through proxy (in fact, this is the way I've
currently implemented it in rheise.os).

> With the process identified
> with a by-value variable (e.g. the pid), we don't have to worry about who
> owns what; we just return the pid by-value, or create a new pid wrapper
> every time getJavaProcess() is called.  ("Those who forget UNIX are doomed
> to re-write it, poorly.")

That saying might not apply here - I hope we can base JOS around
object-oriented principles, and that hopefully means having references
to objects rather than passing around id numbers (as UNIX does with
files and sockets).

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Mon, 01 May 2000 13:03:40 +1000
Date: Mon, 01 May 2000 13:03:40 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Java Processes: Final Summary?

"Todd L. Miller" wrote:

> > If a primordial class loader is written in bytecode, it needs to intern
> > class definitions too. Any class definition could be intern'd by any class
> > loader. If both primordial and custom class loaders can intern a class
> > definition, an object can be shared if its class definition is the same.
> 
>         No.  A custom classloader which does not use findSystemClass() (or
> equivalent, e.g. asking a process-wide static for a Class) can not share
> definitions with another custom classloader.  The semantics of the VM
> require that those classes be considered different, and to do otherwise is
> not transparent to 'legacy' applications which use custom
> classloaders.  If a custom classloader passes on a Class from somewhere
> else in the same process, naturally the Class is the same in both
> classloaders, and casting is allowed.  (According to my recollection of
> the spec.)

There appears to be some confusion in the understanding of Gilbert's
bytecode cache. One of the advantages of Gilbert's idea is that it
_does_ allow class definition sharing with classes loaded by custom
class loaders. This does not mean it goes against the spec, if you
realise that classes and class definitions are not the same thing. We
just need to understand that this changes the rules for object sharing.
Instead of allowing illegal casts between any two classes that share the
same class definition, we only allow illegal casts if the Classes were
also both loaded by primordial class loaders.

To clarify, there are two constraints for illegal casting between two
classes:

1. The two class defintions must be the same
2. The two classes must be loaded by primordial class loaders

In my proposal for class definition sharing, (1) implies (2), therefore
there was no need to separate the two. But if we use Gilbert's bytecode
cache, we must consider both constraints individually.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Mon, 01 May 2000 13:13:20 +1000
Date: Mon, 01 May 2000 13:13:20 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Bytecode vs. class definition

Gilbert Carl Herschberger II wrote:

> The subtle difference -- the only one I've been able to find so far -- is
> how bytecode retains the original payload of a class file and a class
> definition does not. The slight difference is only an issue of how
> efficiently they can be intern'd, not semantics.

The bytecode cache idea loses out on three things:

1. it must retain the original payload of the class file
2. it must always read the class data from disk or network when defining
a class.
3. it must always do a byte for byte comparison to ensure class
definition sharing is valid.

But it gains these things:

1. the ability to include custom loaded classes in class definition
sharing.
2. the ability to share class definitions between classes loaded by
primordial class loaders even if the byte-equivalent classes are in
different locations on disk.

It is a trade-off. My class defintion sharing proposal (based on
location and modification date) loses out to your gains, but makes up
for where the bytecode cache falls short. If we just consider these two
proposal, I believe equivalence determination based on location and
modification date is more attractive. But there is a third idea:

A hybrid between the two approaches is possible. It is possible to use
my location and modification date as the first check, which will cover
most of the cases, and use Gilbert's bytecode cache as a fallback if no
equivalent class definition was found in the cache. If Gilbert's code
finds a match, the location and modification date should be recorded so
that subsequent comparisons can use the efficient location/modification
date method.

This idea has the benefits of both approaches, but retains two of the
disadvantages with Gilbert's approach:

- In the case where we must fall back on Gilbert's checking mechanism,
it is slower.
- bytecode payload must be retained.

But again, this is a tradeoff, and a less severe tradeoff considering
that efficiency is gained most of the time through location and
modification date checking. As for retaining the bytecode payload, it
depends whether we are saving more memory than we are using for the
bytecode cache.

I would propose that we implement location/date checking first, and then
integrate Gilbert's bytecode cache at a later stage _if_ we feel we need
to gain more memory efficiency, or if someone wants to implement it
anyway - assuming that the tradeoff is reasonable (this needs to be
verified). This should be transparent to user apps so it shouldn't
matter either way.

One more thought that just occurred to me: maybe we will end up
retaining the bytecode payload anyway. Consider filesystem caching, such
as that which is implemented in Linux. If you read a file once, the
second read will be faster because it is actually cached in memory.
Since the bytecode of a class is exactly the same as what the filesystem
might cache, it might be possible to integrate the two subsystems. This
might be tricky but it's just a thought. If we do this, only one
disadvantage remains for the hybrid approach:

- In the case where we must fall back on Gilbert's checking mechanism,
it is slower.

So, eventually, integrating Gilbert's bytecode cache might be
beneficial. We just need to examine the tradeoff, perhaps by
experimenting with a prototype.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Mon, 01 May 2000 15:05:23 +1000
Date: Mon, 01 May 2000 15:05:23 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Bytecode vs. class definition

Ryan Heise wrote:

> But again, this is a tradeoff, and a less severe tradeoff considering
> that efficiency is gained most of the time through location and
> modification date checking.

I should clarify this. Obviously the first time classes are loaded it is
more expensive, but subsequent loads will be more efficient because they
will be able to take advantage of location/date most of the time.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From gchii@mindspring.com Mon, 01 May 2000 10:22:50 -0400
Date: Mon, 01 May 2000 10:22:50 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] Bytecode vs. class definition

At 01:13 PM 5/1/00 +1000, Ryan Heise <ryan@whitewolf.com.au> wrote:
>The bytecode cache idea loses out on three things:
>
>1. it must retain the original payload of the class file
>2. it must always read the class data from disk or network when defining
>a class.
>3. it must always do a byte for byte comparison to ensure class
>definition sharing is valid.

1. Yes, a bytecode cache must retain the original payload. This means that
a class definition can point to the original Code attribute of a method,
rather than copy it. It means a class definition can point to the original
class access, field access and method access, not copy it.

A class definition cache must retain something, a conversion of the
original payload to something else. A class definition might make a copy of
Code attributes for each method. This means a class definition may require
multiple calls to alloc(), one for each Code attribute.

2. No, not at all. When defining a class, a bytecode cache has little to do
with a disk or network. A bytecode cache is plugged into the
ClassLoader.defineClass() method. It does not know and does not care where
the payload came from. It works across the board for both primordial and
custom class loaders.

A bytecode cache may or may not be virtualized. A virtual bytecode cache is
connected to a swap partition, like virtual memory. If a bytecode cache is
connected to a swap partition on a local or remote machine, it uses a disk
or network after a class has been defined by ClassLoader.defineClass(). A
virtual cache can discard all of the class definitions that are not being
used.

3. Not exactly. If the payload is retained, a byte-for-byte comparison of
one payload to another is the most efficient comparison I can think of. But
the implementation of the comparison operator is left up to the
implementor. If there is a safer or faster way to compare two class
definitions, find it and use it.





From gchii@mindspring.com Mon, 01 May 2000 10:26:17 -0400
Date: Mon, 01 May 2000 10:26:17 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] Bytecode vs. class definition

At 03:05 PM 5/1/00 +1000, Ryan Heise <ryan@whitewolf.com.au> wrote:
>> But again, this is a tradeoff, and a less severe tradeoff considering
>> that efficiency is gained most of the time through location and
>> modification date checking.
>
>I should clarify this. Obviously the first time classes are loaded it is
>more expensive, but subsequent loads will be more efficient because they
>will be able to take advantage of location/date most of the time.

This efficiency should not be built into each class loader when it does not
have to be. With a system-wide URL cache, this efficiency is automatic for
both primordial and custom class loaders. The URL cache concentrates the
optimization of downloading the same document twice, including class,
archive and package files. Everybody wins.





From gchii@mindspring.com Mon, 01 May 2000 10:44:07 -0400
Date: Mon, 01 May 2000 10:44:07 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] rheise.os-0.1.3 released.

At 01:12 AM 5/1/00 +1000, Ryan Heise <ryan@whitewolf.com.au> wrote:
>All implementation specific classes have been moved out of the main
>public packages and into rheise.os.impl. So, for example,
>rheise.os.process only contains classes that application developers
>might wish to use. This is similar to how java.* only contains classes
>application developers might use, and sun.* contains their private
>implementation classes.

At the right time, implementation should be separated from its interface.
Also, it is a good idea to give different package names to different
versions of a framework/API.

An interface is needed to support a wide variety of implementations. A wide
variety of implementations may be required here because there are a wide
variety of virtual machines. The rheise.os framework can be implemented in
both decaf and other virtual machines. The decaf-specific implementation is
unlike other virtual machines.

>I would imagine that if rheise.os.* is renamed to jos.*, we could have
>jos.process.ProcessManager, and
>org.jos.process.host.HostProcessManagerImpl. This implies that
>application developers should never use the org.jos package. I realise
>that the JOS project has already agreed on the exact opposite, but this
>seems to make more sense to me so I thought I'd raise the issue again.

Yes, we have agreed to the opposite for very good reason.

An interface is used by applications. Applications are unconcerned (or
should be) about the implementation. The well-known interface to the
framework/API should be used by other applications, so it must go in
org.jos.*. Your personal implementation of the framework/API is rheise.os,
and should be. There is no good reason to change it, now or ever.

When there is a rheise-specific implementation of org.jos.process.*, it
should go somewhere within the rheise.* or org.jos.rheise.* packages. When
there is a decaf-specific implementation of org.jos.process.*, it should go
somewhere within the decaf.* or org.jos.decaf.* packages.

A factory should link a framework/API to a specific implementation. A
factory and only a factory should always provide an implementation of a
process manager. A process manager should implement the getProcess()
method. The process manager implementation should not contain static
methods. If static methods are provided, they must use the factory and
dispatch requests to the real process manager.





From tmiller@haverford.edu Mon, 1 May 2000 15:57:27 -0400 (EDT)
Date: Mon, 1 May 2000 15:57:27 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Java Processes: Final Summary?

> In my proposal for class definition sharing, (1) implies (2), therefore
> there was no need to separate the two. But if we use Gilbert's bytecode
> cache, we must consider both constraints individually.

	Quite right.  I don't think I was confused as to Gilbert's
proposal; his phrasing,

> If both primordial and custom class loaders can intern a class
> definition, an object can be shared if its class definition is the same.

	does not consider (2), which is absolutely necessary -- for the
reasons I'd outlined previously.  (That is, transparency/spec-compliance.)


	The summary, (http://www.metamech.com/wiki/view/Main/MultipleJavaProcesses)
then, must be adjusted as follows: drop the second bullet point in the
section, "A share may be attempted if and only if [4]", and the
explanation of it in the following paragraph.  Then, a third condition
(and its explanation) must be added to the section "allowing illegal
casts", that the two class definitions must have been loaded by primordial
loaders.  I will make these changes shortly.

-_Quinn
	





From tmiller@haverford.edu Mon, 1 May 2000 15:58:57 -0400 (EDT)
Date: Mon, 1 May 2000 15:58:57 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Java Processes: Final Summary?

> Proxies are not required to do this (as I explained in response to
> Gilbert's email). JavaProcesses would still be owned by the system, but
> access does not need to be through proxy (in fact, this is the way I've
> currently implemented it in rheise.os).

	What the pid idea does is create an implicit proxy for us, so that
we can have JavaProcesses without having to develop an object-sharing
infrastructure, and the same with sockets.  What I intended here, and
perhaps explained poorly, is that JoeApplication won't be able to tell the
difference between a JavaProcess shared object and a JavaProcess wrapping
a pid; the interface and results are identical.  It's an expedient so, if
we choose to, we can implement Java Processes before we implement object
sharing.  Likewise with Sockets, except, of course, we're re-writing
(actually, I'm pretty sure it will be adjusting, because even Windows uses
UNIX socket semantics, and hence magic numbers  -- the last time I
checked) the SocketImpl code that the Socket uses.

	At any rate, my guess is we'll be done hammering out the spec long
before I get to programming it...

-_Quinn






From tmiller@haverford.edu Mon, 1 May 2000 16:10:50 -0400 (EDT)
Date: Mon, 1 May 2000 16:10:50 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Java Processes: Final Summary?

	This message concerns Ryan's response to Gilbert's implementation
of object-sharing by proxy/ownership lists.  I feel like I'm missing
something of importance -- I don't find myself concerned by having
multiple 'owners' of an object.  Ownership is a concern of the security
system, rather than of IPC.  (I realize that security has to be built in
from the ground up to really work, but hold on a second here.)  All that
garbage collection cares about is the number of references -- one per
accessor/(shared) owner.  If an object is shared, our security system has
OK'd it, so the 'ownership' of an object doesn't seem particularly
important; security should be checking permissions against the process,
not the object, so having a higher-permission process share an object with
a lower priority class isn't a problem.  (BTW -- I really like the idea
of just re-assigning the classloader property for object passing.)

	Ownership seems to be important only if it confers privileges that
accessors don't have.  Maybe I'm missing something, but it seems like the
processes sharing the object must have equal access to it, because once
the object is shared, the JVM isn't going to call security again, unless
explicitly directed to do so.  Being able to do some things but not others
to an object, without those explicit security checks, also seems like it
would violate the spec.  What am I missing here?

-_Quinn






From ryan@whitewolf.com.au Tue, 2 May 2000 06:50:39 +1000 (EST)
Date: Tue, 2 May 2000 06:50:39 +1000 (EST)
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Java Processes: Final Summary?

On Mon, 1 May 2000, Todd L. Miller wrote:

> > In my proposal for class definition sharing, (1) implies (2), therefore
> > there was no need to separate the two. But if we use Gilbert's bytecode
> > cache, we must consider both constraints individually.
> 
> 	Quite right.  I don't think I was confused as to Gilbert's
> proposal; his phrasing,

Yes, it appears that was the case. My sincerest apologies.

> > If both primordial and custom class loaders can intern a class
> > definition, an object can be shared if its class definition is the same.
> 
> 	does not consider (2), which is absolutely necessary -- for the
> reasons I'd outlined previously.  (That is, transparency/spec-compliance.)

I must have missed this sentence in his email. So, Gilbert's idea as /I/
understood it :-) is workable. That is, everything he said, except this
sentence (ie. objects can't be shared just because they have the same
class definition if the classes weren't both loaded by primordial class
loaders).

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From gchii@mindspring.com Mon, 01 May 2000 22:07:22 -0400
Date: Mon, 01 May 2000 22:07:22 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [multiple process] Stumped, again

I have searched and searched; but, I cannot find anything that prevents us
from sharing class definitions for all class loaders, both primordial and
custom. Where does this requirement come from?

 - Is it a security issue? I don't see how the internals of how a virtual
machine uses class definitions affects security. The mechanism, as I
understand it so far, is transparent to a Java application.

 - Is it a process issue? Even the ClassLoader property is a static field
for a class; it is not part of a class definition. A class definition is
system-wide or vm-wide. A class definition cannot be optimized to resolve
references to other classes because those classes are process-wide. For
example, a codepool reference to a field or method in another class cannot
be resolved at the class definition level. A bytecode pre-compiler can only
perform a limited amount of optimization at the class definition level.

 - Is it an efficiency issue? If the payloads are exactly the same, two
class definitions have an equivalent payload and are themselves equivalent.
Since the class definition is everything except static fields, the class
loader is not involved at this level.

 - Is it an interpretation issue? When two classes come from two different
class loaders, a classic virtual machine won't allow a dynamic cast from
one to the other. This is not object sharing. Object sharing is, like RMI
and CORBA, where an object in one process is used in another process.
Object sharing and dynamic casting are separate issues, aren't they?





From ryan@whitewolf.com.au Tue, 02 May 2000 13:06:55 +1000
Date: Tue, 02 May 2000 13:06:55 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Bytecode vs. class definition

I think it is important to understand both the positives and negatives I
pointed out (I know I wasn't clear enough, though) in order to put
things into perspective. I hope after I explain those points a little
better, you might have some comments on the rest of my original email
(which IMHO was the more interesting part to discuss):

Gilbert Carl Herschberger II wrote:

> >1. it must retain the original payload of the class file
> 
> 1. Yes, a bytecode cache must retain the original payload. This means that
> a class definition can point to the original Code attribute of a method,
> rather than copy it. It means a class definition can point to the original
> class access, field access and method access, not copy it.

_Quinn might like to comment here. As he pointed out, when you look at
the implementation of decaf, a class definition is not the same as what
you would put in the bytecode cache. Therefore, it is "extra"
information that we need to hang on to. Sure, you can propose an
alternate JVM design that always keeps the complete class file contents
in memory, and for for this JVM, it would not be considered extra
information.

But, my point is that if a JVM implements the bytecode cache idea, "it
_must_ retain the original payload of the class file".

> A class definition cache must retain something, a conversion of the
> original payload to something else. A class definition might make a copy of
> Code attributes for each method. This means a class definition may require
> multiple calls to alloc(), one for each Code attribute.

I'll leave _Quinn to respond to JVM implemenation details :-)

> >2. it must always read the class data from disk or network when defining
> >a class.
> 
> 2. No, not at all. When defining a class, a bytecode cache has little to do
> with a disk or network. A bytecode cache is plugged into the
> ClassLoader.defineClass() method. It does not know and does not care where
> the payload came from. It works across the board for both primordial and
> custom class loaders.

I think you missed my point completely :-) "it" doesn't refer to the
bytecode cache, but to the code that is *forced* by the bytecode cache
to generate or read the class data from some source every time.

So, my point is that you "must always read --or generate-- class data
from disk or network --or some other source-- when defining a class" in
the bytecode cache approach.

The "or some other source" should cover any further responses, I think,
including sources such as the filesystem cache.

> >3. it must always do a byte for byte comparison to ensure class
> >definition sharing is valid.
> 
> 3. Not exactly. If the payload is retained, a byte-for-byte comparison of
> one payload to another is the most efficient comparison I can think of. But
> the implementation of the comparison operator is left up to the
> implementor. If there is a safer or faster way to compare two class
> definitions, find it and use it.

Just to keep things in perspective (my aim), a perfect comparator is
always more computationally expensive, however you do it.

So, my point is that "it must always do a byte for byte comparison -- or
something to that effect -- to ensure class definition sharing is valid.
This is inherently more computationally expensive."

I hope this time my points are clear. If they still contain errors, I
hope you at least see the actual disadvantages I am trying to show in
each point, as well as the advantages I am trying to show in each point.
I do still believe this is an accurate analysis that puts things in
perspective and enables us to see that merging our two approaches (yours
which focusses memory efficiency, and mine which focusses on
computational efficiency) "might" be beneficial in the end.

Which of the three alternatives is most beneficial we can discuss in the
other thread.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Tue, 02 May 2000 13:09:49 +1000
Date: Tue, 02 May 2000 13:09:49 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Bytecode vs. class definition

Gilbert Carl Herschberger II wrote:
> 
> At 03:05 PM 5/1/00 +1000, Ryan Heise <ryan@whitewolf.com.au> wrote:
> >> But again, this is a tradeoff, and a less severe tradeoff considering
> >> that efficiency is gained most of the time through location and
> >> modification date checking.
> >
> >I should clarify this. Obviously the first time classes are loaded it is
> >more expensive, but subsequent loads will be more efficient because they
> >will be able to take advantage of location/date most of the time.
> 
> This efficiency should not be built into each class loader when it does not
> have to be. With a system-wide URL cache, this efficiency is automatic for
> both primordial and custom class loaders. The URL cache concentrates the
> optimization of downloading the same document twice, including class,
> archive and package files. Everybody wins.

You do realise that the URL cache is based on the same principles I have
been pushing all along for class loading efficiency? That is, location
(the URL reference itself), and *optionally* the last modified date
which it discovers when it reads the first few bytes from the socket
(it's the first line in the header for efficiency).

I'm glad you see the benefits of this algorithm, if only at the URL
cache level. It's the same algorithm used by the filesystem cache too
(except in this case, the version information is *not* optional), and
I'm sure you see the benefit here too. I am proposing that we use the
same algorithm for determining whether a class definition is already in
decaf's cache.

You're point was, why bother when we can implement an optimisation at a
lower level (disk and url cache) which benefits all upper layers? My
answer is the same answer to a similar question you had about optimising
the protocol stack to benefit all implementations of IPC in the upper
layers. We have the potential to make things *much* faster. The lower
level optimisations (eg. disk cache) will still be beneficial to all
upper layers, but both direct object sharing and internal location/date
checking (inside findSystemClass()) provide significant *additional*
speed improvements for the parts of the system that use it.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Tue, 02 May 2000 13:24:19 +1000
Date: Tue, 02 May 2000 13:24:19 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] rheise.os-0.1.3 released.

Gilbert Carl Herschberger II wrote:
> 
> At 01:12 AM 5/1/00 +1000, Ryan Heise <ryan@whitewolf.com.au> wrote:
> >All implementation specific classes have been moved out of the main
> >public packages and into rheise.os.impl. So, for example,
> >rheise.os.process only contains classes that application developers
> >might wish to use. This is similar to how java.* only contains classes
> >application developers might use, and sun.* contains their private
> >implementation classes.
> 
> At the right time, implementation should be separated from its interface.

That was actually the goal of this release. I was trying to remove all
implementation specific stuff out of the public API package. What's left
in the public API package is only the classes that JOS programs might
interact with (where rheise.os is a proposal for the JOS
process/security/user APIs).

My current implementations of this API are currently included in the
rheise.os package for convenience, but I would like them moved into
somewhere private.

Would you care to take a look in the public API packages of rheise.os
and tell me what you think? See if my separation is actually what you
want?

> Also, it is a good idea to give different package names to different
> versions of a framework/API.

Agreed. SwingToolkit will remain as rheise.swingtoolkit, while
java.awt.peer will remain as that.

However, the core APIs such as process/user/security APIs need to be in
jos.* or org.jos.*, wherever we decide. For example, take a look in the
rheise.os.process.* package. It contains classes I'd imagine would go on
jos.process.*. This package defines the set of methods used to create
processes, query processes, destroy running processes and so on. So, JOS
programs might have direct references to jos.process.JavaProcess
objects(*), just like current java programs have direct references to
java.lang.Thread objects. If you compare those two classes, you will
find they are similar in style, except rather than passing off
implementation specific stuff to native methods, I pass my stuff off to
the "impl" objects.

(*) Note that JavaProcess is castable to java.lang.Process which is a
nice compatibility feature. This also explains why it is a class, not an
interface (although there are other reasons).

> >I would imagine that if rheise.os.* is renamed to jos.*, we could have
> >jos.process.ProcessManager, and
> >org.jos.process.host.HostProcessManagerImpl. This implies that
> >application developers should never use the org.jos package. I realise
> >that the JOS project has already agreed on the exact opposite, but this
> >seems to make more sense to me so I thought I'd raise the issue again.
> 
> Yes, we have agreed to the opposite for very good reason.
> 
> An interface is used by applications. Applications are unconcerned (or
> should be) about the implementation. The well-known interface to the
> framework/API should be used by other applications, so it must go in
> org.jos.*.

That's not actually a reason to choose org.jos.* over jos.*. What I
meant was that (from memory) it was decided that jos.* would contain
implementation specific classes, while org.jos would contain public API
stuff. I think the reverse is probably nicer. Rationale:

The public core API of java goes under java.* which is nice and concise.
Sun recommend that any software developer release their software
products under package names that match their reverse dns name. In the
case of JOS, this means org.jos. java.* is the exception to this rule
because it is the core of the Java system.

We are developing an operating system, and our core could exempt from
the same rule. Meaning, rather than having to use the longer package
name "org.jos" we could put our core stuff in jos.*.

This leaves org.jos for additional software that we, the JOS
organisation, write. This could include collaborative software projects
that JOS members work on, but which are not considered part of the core
operating system. This could also include our own implementations of the
JOS process APIs (etc.), although Sun have (conveniently) broken the
rules again with this, and in a way that is difficult for us to mimic.
They have java.* for the core, com.sun.* for software they write to work
with java.*, and sun.* which is a private package for software they
never intend to release the source to (and there's also javax.*). We
want something like sun.* to put our implementations of the public JOS
APIs.

So, they have:

	java.* - core (the Java product)
	sun.*  - private (prefixed with company name)
	com.sun.* - public software (this time following their own package
naming guidlines)

As you can see, we can't generate all three the same way because our
product name is the same as our organisation name. So, I thought maybe
we could just put sun.* type stuff into org.jos.

> Your personal implementation of the framework/API is rheise.os,
> and should be. There is no good reason to change it, now or ever.

I'm not sure I understand you, because you are telling me what rheise.os
is when I should be telling you what it is. rheise.os a set of core
classes that provide an interface to managing processes, users and
security. This package includes implementations of those core classes,
but while rheise.os remains fixed, different implementations may be
plugged in. The existing implementations are just implementations that
rheise.os includes in its release.

Given what rheise.os *is*, I was initially offended by your claim that
rheise.os, as it is, is just one implementation of some other
hypothetical API, and that there is no good reason to change it, now or
ever. I hope that is not what you mean! :-)

If you mean that the host implementation included with my rheise.os
package should be renamed to rheise.os, and the current rheise.os be
renamed to something else, I'm with you. However, I don't want implied
ownership over rheise.impl.process.host.*, I'd rather it be a
collaborative effort without my name on it - something like
org.jos.impl.process.host.* that the JOS project can distribute to users
wanting to run JOS In a host environment.

> A factory should link a framework/API to a specific implementation. A
> factory and only a factory should always provide an implementation of a
> process manager. A process manager should implement the getProcess()
> method. The process manager implementation should not contain static
> methods. If static methods are provided, they must use the factory and
> dispatch requests to the real process manager.

If you look at the current design, The public APIs are frontends to
implementations which are generated by factories. In my first version,
the only way I could think of to support factories was to make
ProcessManager an object returned by a factory, meaning it couldn't be
used via static methods (which is inconvenient). In the latest release,
I have solved that problem (still using factories) and I feel the
interface is much nicer.

Rather than calling:

	ProcessManager processMgr = ProcessManager.get();
	JavaProcess process = processMgr.getCurrentProcess()

You call:

	JavaProcess process = ProcessManager.getCurrentProcess();

Sort of like the way Thread.currentThread() is a static method which is
much more convenient than having to first obtain a ThreadManager object.
There is only really one thread manager in the system, just like there
is only one ProcessManager, so the fact that the ProcessManager you're
using is created through a factory should be totally hidden.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Tue, 02 May 2000 13:26:02 +1000
Date: Tue, 02 May 2000 13:26:02 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Java Processes: Final Summary?

"Todd L. Miller" wrote:

>         What the pid idea does is create an implicit proxy for us, so that
> we can have JavaProcesses without having to develop an object-sharing
> infrastructure, and the same with sockets.  What I intended here, and
> perhaps explained poorly, is that JoeApplication won't be able to tell the
> difference between a JavaProcess shared object and a JavaProcess wrapping
> a pid; the interface and results are identical.  It's an expedient so, if
> we choose to, we can implement Java Processes before we implement object
> sharing.

I see. So, the nativ package (do we call it the decaf sub-package now?)
could initially do it this way. That seems possible, using the factory
based design in rheise.os, and completely transparent. Cool.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Tue, 02 May 2000 13:32:32 +1000
Date: Tue, 02 May 2000 13:32:32 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Java Processes: Final Summary?

"Todd L. Miller" wrote:
> 
>         This message concerns Ryan's response to Gilbert's implementation
> of object-sharing by proxy/ownership lists.  I feel like I'm missing
> something of importance -- I don't find myself concerned by having
> multiple 'owners' of an object.  Ownership is a concern of the security
> system, rather than of IPC.  (I realize that security has to be built in
> from the ground up to really work, but hold on a second here.)  All that
> garbage collection cares about is the number of references -- one per
> accessor/(shared) owner.

Right. It so happens that ProcessClassLoader has a reference to the
process that it is loading classes for. This reference is used in
ProcessManager.getOwningProcess(clazz) which traverses up the class
loader chain until the primordial class loader is reached, then finally
calls getProcess() on it to return the process owning that class. This
is also a method which you felt should be defined at the generic level
because it would work the same for host and nativ implementations. I
think I agree.

What this means is, it sort of does matter which process owns the
object, because this reference will stop the real owner of the process
from being garbage collected if it drops out of the distributed system.

>  If an object is shared, our security system has
> OK'd it, so the 'ownership' of an object doesn't seem particularly
> important;

The above was actually in response to this bit.

> (BTW -- I really like the idea
> of just re-assigning the classloader property for object passing.)

It seems like this is the primitive for doing all sorts of stuff related
to do object ownership. For example, to emulate multiple owners of an
object, ownership of the object can be re-assigned to an independent
master process: the(/a) shared object broker.

>         Ownership seems to be important only if it confers privileges that
> accessors don't have.  Maybe I'm missing something, but it seems like the
> processes sharing the object must have equal access to it, because once
> the object is shared, the JVM isn't going to call security again, unless
> explicitly directed to do so.  Being able to do some things but not others
> to an object, without those explicit security checks, also seems like it
> would violate the spec.  What am I missing here?

Security doesn't really depend on having shared ownership, it's more to
do with designing elegant distributed systems, to avoid the problem
where the object owner drops out of the ring.

But security is an interesting topic in itself. One way of handling it
is as you said: each process that shares access to the object is
restricted in exactly the same way. But when you look at how access
restriction is implemented, you see it is possible to actually allow one
process to have more access than another. Each method which the client
process can call is able to check who the calling process is and grant
or deny access. So some methods on the object can be called by process
A, some methods can be called by process B, and some can be called by
both.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From tmiller@haverford.edu Mon, 1 May 2000 23:50:29 -0400 (EDT)
Date: Mon, 1 May 2000 23:50:29 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Java Processes: Final Summary?

> What this means is, it sort of does matter which process owns the
> object, because this reference will stop the real owner of the process
> from being garbage collected if it drops out of the distributed system.

	OK.  I see why the process which originated object might want to
maintain a reference to the shared object; I don't see that this reference
needs to be any different than any other kind, or have tha distinction
maintained by the kernel.  (Or, necessarily, that having provided a shared
object, it should necessarily persist once it drops out of the disributed
system.)

> It seems like this is the primitive for doing all sorts of stuff related
> to do object ownership. For example, to emulate multiple owners of an
> object, ownership of the object can be re-assigned to an independent
> master process: the(/a) shared object broker.

	I'm still stuck on the idea of ownership over here.  All I
(still) see a need for is object references.  Even if we were to
implement finer-grained security than by-process, what special priviliges
does the object/process from which the shared object under consideration
came (the 'owner') have, as a matter of kernel-level policy?

> So some methods on the object can be called by process A, some methods
> can be called by process B, and some can be called by both.

	This is very true.  It is not, however, something that the kernel
needs to concern itself with -- because it's written into the shared
object itself.

	All your points are good, but the connection to ownership
continues to elude me.  Why is 'ownership' a kernel-level primitive?

-_Quinn





From ryan@whitewolf.com.au Tue, 02 May 2000 13:45:44 +1000
Date: Tue, 02 May 2000 13:45:44 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [multiple process] Stumped, again

Gilbert Carl Herschberger II wrote:
> 
> I have searched and searched; but, I cannot find anything that prevents us
> from sharing class definitions for all class loaders, both primordial and
> custom. Where does this requirement come from?

We can do this. But we can no longer allow object sharing simply because
the class definitions are the same (as you had thought).

There are two constraints for illegal casting between two classes:

1. The two class defintions must be the same
2. The two classes must be loaded by primordial class loaders

I apparently misunderstood your proposal in that I thought you
recognised (2), but as _Quinn pointed out, your proposal explicitly
stated that (2) was to be ignored. So, if you misunderstand yourself the
same way I did, then you're proposal will work :-)


-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From tmiller@haverford.edu Mon, 1 May 2000 23:55:53 -0400 (EDT)
Date: Mon, 1 May 2000 23:55:53 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Bytecode vs. class definition

> > >1. it must retain the original payload of the class file
> > 
> > 1. Yes, a bytecode cache must retain the original payload. This means that
> > a class definition can point to the original Code attribute of a method,
> > rather than copy it. It means a class definition can point to the original
> > class access, field access and method access, not copy it.

	Implementation-wise, pointers are more expensive than copies --
the access flags aren't 32 bits wide, and more indirect lookups are just
what we don't need.  The majority of bytes in a classfile, so far as I am
aware, are method code, followed by the constant pool.  Method code I
already cache unchanged; certainly, the code pointer could point into a
bytecode cache.  I believe I've already mentioned the efficiency costs of
not pre-processing the constant pool.

> > A class definition cache must retain something, a conversion of the
> > original payload to something else. A class definition might make a copy of
> > Code attributes for each method. This means a class definition may require
> > multiple calls to alloc(), one for each Code attribute.

	Well, yes, creating a class definition generates many, many, calls
to alloc.  As it happens, because I'm streaming files out of the ramdisk,
that I do make copies of the Code attribute; presumambly, the ramdisk is
going away Real Soon Now from the kernel bootloader/strapper.  OTOH, those
calls to alloc are, I hope, cheaper than the alternatives I've described
before, and some of them could be eliminated with a bytecode cache.

-_Quinn





From tmiller@haverford.edu Tue, 2 May 2000 00:02:13 -0400 (EDT)
Date: Tue, 2 May 2000 00:02:13 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [multiple process] Stumped, again

> I have searched and searched; but, I cannot find anything that prevents us
> from sharing class definitions for all class loaders, both primordial and
> custom. Where does this requirement come from?

	We're misunderstanding each other.  My current understanding --
and Ryan's, apparently -- is that we can share bytecode as prolificly
(sp?) as we like.  The condition I had been getting hung up was from your
implication that we could ignore the classloader in which it
originated.  This is big no-no w.r.t. to the VM spec, which I'm sure
you're aware of.  Our solution is to allow casts to ignore the ClassLoader
equality requirement if and only if both classes were loaded by the
primordial classloader.  Our understanding is that this will not violate
transparency; if a class is loaded into the process's primordial class
loader in, it will behave exactly as if it were loaded the /only/
primordial classloader in a single-process VM.  Allowing a cast from a
different process will not break the VM model -- since it does not have a
process model!  (Previously, we had thought only primordial classloaders
could share classes because we had incorrectly conflated sharing with
casting.)

-_Quinn





From Matt.Albrecht@trilogy.com Tue, 2 May 2000 09:37:06 -0500
Date: Tue, 2 May 2000 09:37:06 -0500
From: Matt.Albrecht@trilogy.com Matt.Albrecht@trilogy.com
Subject: [JOS-Arch] Bytecode vs. class definition

Perhaps I'm missing something.  But, to me, aren't these the ways the
comparison must be done?

For Bytecode (bytecode A vs. bytecode B):
   1. The bytes within the bytecode must match exactly between A and B.
   I believe this is the only requirement.

For Class Definitions (class def C vs. class def D)
   1. Internal bytecodes of C and D must match.
   2. The Class Definitions for their parent classes must match (superclass
of C must match superclass of D, and all interfaces must match as well).

So, if two processes E and F load the exact same bytecode for class
"MyClass", that doesn't mean that their classes match.  Process E may load
a completely different version of the superclass than process F.  Variables
may not match, method invocation may not be the same, and so on.

True, we can still share the bytecode, but I don't believe we can acurately
share class definitions based on whether the bytecodes are shared.

"If it works, it's not advanced enough."
-Matt








From tmiller@haverford.edu Tue, 2 May 2000 11:23:37 -0400 (EDT)
Date: Tue, 2 May 2000 11:23:37 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Bytecode vs. class definition

	I'd kind of been hoping that the superclass problem would take
care of itself somewhere along the line in a recursion, but we do need to
think about this...

-_Quinn





From gchii@mindspring.com Tue, 02 May 2000 19:25:55 -0400
Date: Tue, 02 May 2000 19:25:55 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] Bytecode vs. class definition

At 09:37 AM 5/2/00 -0500, Matt.Albrecht@trilogy.com wrote:
>For Bytecode (bytecode A vs. bytecode B):
>   1. The bytes within the bytecode must match exactly between A and B.
>   I believe this is the only requirement.

Exactly! The raw payload of A must match the raw payload of B.

  memcmp( A.getPayload(), B.getPayload() );

>For Class Definitions (class def C vs. class def D)
>   1. Internal bytecodes of C and D must match.
>   2. The Class Definitions for their parent classes must match (superclass
>of C must match superclass of D, and all interfaces must match as well).
>
>So, if two processes E and F load the exact same bytecode for class
>"MyClass", that doesn't mean that their classes match.  Process E may load
>a completely different version of the superclass than process F.  Variables
>may not match, method invocation may not be the same, and so on.

Wait! I thought a class definition has no static fields. If it has no
static fields, it has no link to any superclass. A class definition only
knows the name of its superclass, not the class definition of its superclass.

Otherwise, both a class definition and a class would be the same thing.

Let's talk about resolving a class. A class can be resolved. It has static
fields, like ClassLoader, that help resolve the class. A class definition
cannot be resolved because that requires static fields. A class definition
can pre-convert UTF8 fields and convert the external representation of
other constants to a vm-specific form. It can even pre-compile the Code
attribute of methods. The pre-compiled code would be platform- and vm-specific.





From Matt.Albrecht@trilogy.com Tue, 2 May 2000 18:40:15 -0500
Date: Tue, 2 May 2000 18:40:15 -0500
From: Matt.Albrecht@trilogy.com Matt.Albrecht@trilogy.com
Subject: [JOS-Arch] Bytecode vs. class definition

>Wait! I thought a class definition has no static fields. If it has no
>static fields, it has no link to any superclass. A class definition only
>knows the name of its superclass, not the class definition of its
superclass.

>Let's talk about resolving a class. A class can be resolved. It has static
>fields, like ClassLoader, that help resolve the class. A class definition
>cannot be resolved because that requires static fields. A class definition
>can pre-convert UTF8 fields and convert the external representation of
>other constants to a vm-specific form. It can even pre-compile the Code
>attribute of methods. The pre-compiled code would be platform- and
vm-specific.

Ah.  Here's the heart of the matter for me.  I wasn't understanding what
exactly was meant by "class definition".  I was under the impression that
this was a kind of intermediate phase in the loading of the Class.  From
the sound of it, a class definition is bytecode which has been loaded by a
class loader and passed to the JVM, but has not yet been resolved (via a
native method).  So then I hear you saying that a class definition is
bytecode associated with a class loader.

It's always nice to speak the same language.  It's even better if you
understand the same language.  Which reminds me, I've got to get back to
programming in GAP (Grunting And Pointing). :-)


"If you lurk long enough, you'll understand."
-Matt








From tmiller@haverford.edu Tue, 2 May 2000 20:30:48 -0400 (EDT)
Date: Tue, 2 May 2000 20:30:48 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Bytecode vs. class definition

> Ah.  Here's the heart of the matter for me.  I wasn't understanding what
> exactly was meant by "class definition".  I was under the impression that
> this was a kind of intermediate phase in the loading of the Class.  From
> the sound of it, a class definition is bytecode which has been loaded by a
> class loader and passed to the JVM, but has not yet been resolved (via a
> native method).  So then I hear you saying that a class definition is
> bytecode associated with a class loader.

	Yes, no, and maybe.  Yes, a byte-array in class file format, as
defined in the VM spec, is a 'class definition' in the sense that you pass
one to defineClass().  No, a 'class definition' is not bytecode; it is the
machine-and-vm specific translation of the 'bytecode class definition'
into something more efficient to use internally.  Maybe, in that /I/ try
to always say 'bytecode' when I mean 'an array of bytes in class file
format defining a legal class', and 'class definition' when I mean
'instances of the C++ classes decaf uses internally which are distinct
from the statics associated with a native java.lang.Class'; but I don't
always succeed, and it may not be clear from context.

	Most specifically, when I distinguish between a class definition
and bytecode, I mean, an instance of the decaf C++ class
'JavaClass'.  Because the data in this instance is immutable under
legal Java operations to the class, it may safely be shared accross
multiple Java processes.

-_Quinn





From tmiller@haverford.edu Tue, 2 May 2000 20:47:31 -0400 (EDT)
Date: Tue, 2 May 2000 20:47:31 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Bytecode vs. class definition

> Wait! I thought a class definition has no static fields. If it has no
> static fields, it has no link to any superclass. A class definition only
> knows the name of its superclass, not the class definition of its superclass.
> 
> Otherwise, both a class definition and a class would be the same thing.

	No.  The link to a superclass is not a static field; it's an index
into the constant pool, defined in the class file specification*. The
security/type violation occurs as follows.  I compile two classes, A and
B.  A and B are the same, and use reflection to access their fields,
except that A subclasses C, and B subclasses D.  Clearly, classes A and B
are not the same -- suppose C were Thread and D were ClassLoader.  Classes
A and B could be /identical/, save for the 'extends' clause; failed
reflections could be caught and ignored.  Now I load A and B into the VM
and want to share their class definitions.  Obviously, there's a
problem.  If A 'wins' the share, B becomes a Thread subclass, instead of a
ClassLoader subclass.  And vice-versa.

	However, we don't need to worry about this.  Parent classes, as
I've noted, are explicitly embedded in the classfile.  Therefore, only
classes whose parents share a symbolic name will have identical
classfiles.  The question to ask, then, is: what happens when process one
loads A and C, C is recompiled, and process two loads B and C'?  If B
still works with C' (suppose you only changed a method body), A will work
with it also.  However, is allowing A and B to cast to each other (or to
C, actually) still OK?  If I try share an object whose parent class in my
process is out of date,	should it go through?  I would think, for ease of
upgrading, the answer should be yes -- but if we use recursion to attempt
an 'illegal' cast between the parent classes, the answer would be no.  Any
thoughts?
 
-_Quinn

* That is, the set of things immutable under the setstatic() bytecode
includes the parent of the class.





From ryan@whitewolf.com.au Wed, 03 May 2000 17:19:12 +1000
Date: Wed, 03 May 2000 17:19:12 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Java Processes: Final Summary?

"Todd L. Miller" wrote:

>         OK.  I see why the process which originated object might want to
> maintain a reference to the shared object;

It's the other way around, actually.

>         I'm still stuck on the idea of ownership over here.  All I
> (still) see a need for is object references.  Even if we were to
> implement finer-grained security than by-process, what special priviliges
> does the object/process from which the shared object under consideration
> came (the 'owner') have, as a matter of kernel-level policy?

None which are granted by the kernel. The fact that it is recorded by
the kernel, though, means it can be used at the user level.

The kernel doesn't care how it is used. But garbage collection in the
kernel would benefit from smart use of object ownership by user
processes. That was my point about multiple ownership of objects. If we
emulate it the way I suggested, that helps the garbage collector - it
doesn't leave dead processes around in memory (besides, that's ugly,
conceptually).

>         All your points are good, but the connection to ownership
> continues to elude me.  Why is 'ownership' a kernel-level primitive?

That's the nature of the system. An object is associated with one class,
which is associated with one defining class loader, which is associated
with one process. Therefore, objects are owned by (/associated with)
processes and that is reflected in the implementation of the
kernel(/JVM). Reassigning ownership of an object to another process is
therefore a kernel(/JVM) primative, too.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From tmiller@haverford.edu Wed, 3 May 2000 03:55:19 -0400 (EDT)
Date: Wed, 3 May 2000 03:55:19 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Java Processes: Final Summary?

> None which are granted by the kernel. The fact that it is recorded by
> the kernel, though, means it can be used at the user level.

	I begin to see the light.

> The kernel doesn't care how it is used. But garbage collection in the
> kernel would benefit from smart use of object ownership by user
> processes. That was my point about multiple ownership of objects. If we
> emulate it the way I suggested, that helps the garbage collector - it
> doesn't leave dead processes around in memory (besides, that's ugly,
> conceptually).

	Er -- aren't references and ownership indistinguishable from the
POV of the garbage collector*?  Let me re-phrase the question: when is it
beneficial to make the distinction between process-with-reference and
process-with-ownership?  (Or, more accurately, but equivalently, when is
it beneficial to distinguish between reference-from and
reference-from-owner?)  If a process dies, its entire memory tree is
pruned.  If we decide that all shared objects operate with weak
references, this is not a problem, right?  The reference just becomes
null.  (Having never /used/ weak references, I'm probably wrong about
something here.)  (OTOH, weak references are a JDK1.2 thing, right?)

> That's the nature of the system. An object is associated with one class,
> which is associated with one defining class loader, which is associated
> with one process. Therefore, objects are owned by (/associated with)
> processes and that is reflected in the implementation of the
> kernel(/JVM). Reassigning ownership of an object to another process is
> therefore a kernel(/JVM) primative, too.

	Okay, I think I understand where you're coming from here.  I tend
to think of it as an object HasA process, rather than a process OwnsAn
object.  This is because a process is not an object abstraction at the JVM
level, except for the back-end to the interface.  This is done
deliberately so that we can be absolutely certain that whatever
correctness our single-process JVM has, the multiple-process one does
also.  The necessary exception -- cross-process casting -- is the one
which we've spending so much time on to ensure its theoretical
correctness.

	W.r.t. to garbage collection, that a Process OwnsAn object (or
that an Object HasA process) doesn't seem -- that I'm seeing - to impact
the number of live references to the object, which is what matters to a
garbage collector.  If a process sharing an object terminates without
using the setSomeOtherOwner() (or whatever) function, it may have good a
reason for doing so -- the shared object may depend on its
originating/owner process for functionality.  I don't see that the GC
needs to worry about.


	Quick little question session: the kernel (/decaf) already
maintains 'ownership' (origination) information.  Is the proposal that for
(only shared?) objects, we should be able to perform a lookup from it to
the classloaders/processes which could reference it?  (e.g. had, at one
point, shared it.  This does not necessarily mean it actually /does/
reference it.)  And that there is some efficiency/elegance gain from
maintaining such a reverse lookup?

-_Quinn

* I couldn't, in the time available, find the e-mail where you talked
about GC w.r.t. ownership of processes, so you may have explained it
there.





From ryan@whitewolf.com.au Wed, 3 May 2000 23:11:03 +1000 (EST)
Date: Wed, 3 May 2000 23:11:03 +1000 (EST)
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Bytecode vs. class definition

On Tue, 2 May 2000 Matt.Albrecht@trilogy.com wrote:

> Perhaps I'm missing something.  But, to me, aren't these the ways the
> comparison must be done?
> 
> For Bytecode (bytecode A vs. bytecode B):
>    1. The bytes within the bytecode must match exactly between A and B.
>    I believe this is the only requirement.
> 
> For Class Definitions (class def C vs. class def D)
>    1. Internal bytecodes of C and D must match.
>    2. The Class Definitions for their parent classes must match (superclass
> of C must match superclass of D, and all interfaces must match as well).

Excellent point about superclasses (more on this down below).

The bytecode vs. class definition discussion we have been having refers
to the two proposals that have been made for saving memory and at the
same time, allowing safe object sharing between processes for efficient
IPC. The terms are badly named, leading to confusion.

- class definition: apparently refers to my proposal to share class
  definitions between java.lang.Class'es with the same name that were
  loaded from the same version of the same archive (through a primordial
  class loader), and to allow illegal casts between any two classes that
  share the same class definition (thus giving us inter-process object
  sharing). This proposal was published at:

  http://www.progsoc.uts.edu.au/~rheise/jos/java_processes.txt

- bytecode: apparently refers to Gilbert's proposal to share class
  definitions between java.lang.Class'es whenever their bytecodes
  exactly match. This, for example, picks up the opportunity to share
  class definitions when the two classes were loaded from two completely
  different archives (eg. in two different users' home directories) but
  are still exactly the same when compared byte for byte. Thus it squeezes
  even more memory out of the system, but at the expense of a less
  efficient algorithm (comparing byte for byte is much slower than
  comparing file location and modification date)

  The same semantics for illegal casts applies here, with the
  clarification that, since Gilbert's proposal allows byte comparison of
  classes loaded by custom class loaders, illegal casts are only allowed
  for the subset of classes that are loaded by primordial class loaders.

So, your point about requiring the line(s) of superclasses(*) to also
share class definitions with the line(s) of superclasses in the other
process applies to illegal casts in both styles of class definition
sharing.

Requiring superclasses to share class definitions for illegal casts to
work is clearly the most correct way to handle it. But as _Quinn pointed
out, things might work out by themselves anyway. If they do, we can save
ourselves from having to do a more expensive check to allow illegal
casts.

To answer _Quinn's question, what happens if we don't verify the
compatibility of superclasses? The calling process is only able to
access the subset of inhehrited methods it knows about (ignoring
reflection for the moment). In addition, if it tries to call a method it
thinks is there but is not, it should throw a NoSuchMethodError(**). The
object, defined by its class and superclasses is really owned by the
other process so there is no doubt what methods can be called on it and
what methods cannot. The same goes for fields.

The behaviour is similar to what I proposed for access to static members
of shared objects. The client process accesses only what it sees, but
internal method calls inside the shared object will see through the eyes
of the owning process.

Whether or not we verify all superclasses before permitting an illegal
cast, it will very rarely be the case that the superclasses are not
compatible (the inheritance chain would have to go through a number of
different archives). The difference is what error we get when it does
happen: NoSuchMethodError or ClassCastException. That, and a
NoSuchMethodError might never be thrown if the method is never called.
This can be considered a good thing or a bad thing.

(*) This is to imply Java does have multiple inheritence but only one
superclass may be a class. The rest must be interfaces.

(**) The same error you get when you find yourself running your program
against the wrong version of a library.

{{ BTW, for some reason, admin@jos.org was being CC'd on this thread.
I've removed that CC on this reply }}

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Thu, 4 May 2000 00:30:28 +1000 (EST)
Date: Thu, 4 May 2000 00:30:28 +1000 (EST)
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Java Processes: Final Summary?

On Wed, 3 May 2000, Todd L. Miller wrote:

> 	Er -- aren't references and ownership indistinguishable from the
> POV of the garbage collector*?  Let me re-phrase the question: when is it
> beneficial to make the distinction between process-with-reference and
> process-with-ownership?

The key reference when talking about the GC is the reference from the
shared object to its owning process (via the ProcessClassLoader).

A process-with-reference (or more correctly, a process running a program
with a reference) to a shared object is indirectly causing the process
that owns that object to hang around in memory needlessly. I'm just
pointing out that although having a reference to an object like this is
nothing out of the norm, it is conceptually ugly in the case where the
process object being referenced (indirectly) is no longer needed. It is
a dead process.

Although, you do talk about this being useful later on. I'll get to
that.

> If a process dies, its entire memory tree is
> pruned.

Not its entire memory tree. If another process has a reference to one of
its shared objects, the memory tree of that object will hang around in
memory. Note that this includes the process that is supposed to be dead.
Invoking an object in a dead process doesn't strike me as a good idea
conceptually (at least not in this context - read on)

>  If we decide that all shared objects operate with weak
> references, this is not a problem, right?  The reference just becomes
> null.  (Having never /used/ weak references, I'm probably wrong about
> something here.)  (OTOH, weak references are a JDK1.2 thing, right?)

I consider weak reference as an option because they are not as
convenient to program against. You have to call
(ObjectType)reference.get() before you do anything. If you just called
get() once and always referred to that, that would defeat the purpose of
weak references. But they are useful. We just don't always need to use
them, especially when we can avoid the problem by making sure the owner
of the shared object is always alive as long as other processes wish to
use it. This means re-assigning ownership if the current owner wishes to
die.

Yes, weak references are a JDK 1.2 thing.

> > That's the nature of the system. An object is associated with one class,
> > which is associated with one defining class loader, which is associated
> > with one process. Therefore, objects are owned by (/associated with)
> > processes and that is reflected in the implementation of the
> > kernel(/JVM). Reassigning ownership of an object to another process is
> > therefore a kernel(/JVM) primative, too.
> 
> 	Okay, I think I understand where you're coming from here.  I tend
> to think of it as an object HasA process, rather than a process OwnsAn
> object.

I think the "concept" of multiple Java processes is that the process
"contains" everything running inside of it. So, I would say an object
HasAn owning process (for instance, ProcessManager.getOwningProcess()).

Compare the concept of a hierarchical structure with a particular
implementation of it. You would think that a directory contains a list
of children. However, in the implementation, each child may have a link
to the directory instead (eg. a relational database) or as well as. Do
you say each child has a directory? Rather, you say each child has an
owning directory, or more commonly in this case, a parent directory.

> garbage collector.  If a process sharing an object terminates without
> using the setSomeOtherOwner() (or whatever) function, it may have good a
> reason for doing so -- the shared object may depend on its
> originating/owner process for functionality.

You want to depend on a dead process for functionality? I think that if
a process was ever alive, its purpose was to live, and any functionality
you're talking about should be carried on while it is still alive.

However, and this is an idea I couldn't work out how to implement until
you gave me the idea, it might be desirable to have processes that have
no threads. ie. they are never technically alive. All they provide is a
separate namespace for code that is actually executed by threads which
belong to other processes. Sort of like how a JavaBean can provide
useful functionality even though it usually doesn't run in its own
thread.

Consider, for example, a servlet engine. Today's servlet engines run all
servlets in the same namespace which makes it difficult for different
users to run servlets on the same server that don't trust each other.
The way a servlet is invoked is not the same as a program. The servlet
engine treats each servlet as an object (like a bean) and calls a method
on it, service(), and passes in a request and response object. It is
also not like a process in that the thread in which the servlet is
executing is not owned by the servlet, but by the servlet engine.
However, ideally it would be nice to treat a servlet as a process in one
way: it should have its own namespace and user privileges. A JavaProcess
provides both of these things through the ProcessClassLoader and the
UserToken. Working out how to actually implement this is tricky, though.

> 	Quick little question session: the kernel (/decaf) already
> maintains 'ownership' (origination) information.  Is the proposal that for
> (only shared?) objects, we should be able to perform a lookup from it to
> the classloaders/processes which could reference it?  (e.g. had, at one
> point, shared it.  This does not necessarily mean it actually /does/
> reference it.)  And that there is some efficiency/elegance gain from
> maintaining such a reverse lookup?

I was never suggesting we add a reverse lookup. As you just said, the
kernel already maintains ownership information. All I'm proposing is
that we provide a function to reassign ownership. Multiple ownership can
then be emulated without any further kernel support.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From Matt.Albrecht@trilogy.com Wed, 3 May 2000 09:44:04 -0500
Date: Wed, 3 May 2000 09:44:04 -0500
From: Matt.Albrecht@trilogy.com Matt.Albrecht@trilogy.com
Subject: [JOS-Arch] Bytecode vs. class definition

>Requiring superclasses to share class definitions for illegal casts to
>work is clearly the most correct way to handle it. But as _Quinn pointed
>out, things might work out by themselves anyway. If they do, we can save
>ourselves from having to do a more expensive check to allow illegal
>casts.

Here's my thoughts on the subject so far, muddy as hell as always.

1. For "class definition"/"bytecode" sharing for memory compression, it is
my personal belief that only a "rough combination of the two" should be
allowed to be shared.  Let me elaborate.  The JVM should of course take the
bytecode and transform it into its internal optimized version.  Usually (as
it seems), this also includes defining the superclass / interface pointers
as well.  IMHO, only the "internal optimized version" should be shared,
while the pointers to superclass / interfaces need to be tacked to the
static data associated with the class instance.  For performance purposes,
we could have a low-priority thread in memory which does bytecode/internal
version checking for each newly added class.  This means that two instances
of the same class file can be at different memory positions.

2. If we only allow illegal casts with classes loaded by the primordial
class loader, then all we need to check is if the two class instances
indeed were loaded by that class loader, and have the same name, since
class loaders should only allow one class instance per class name.  This
also implies that the class' superclasses should be identical as well.

Or is that what everyone's already been saying?


"If it works, it's not advanced enough."
-Matt








From gchii@mindspring.com Wed, 03 May 2000 11:16:01 -0400
Date: Wed, 03 May 2000 11:16:01 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] Java Processes: Final Summary?

At 05:19 PM 5/3/00 +1000, Ryan Heise <ryan@whitewolf.com.au> wrote:
>The kernel doesn't care how it is used. But garbage collection in the
>kernel would benefit from smart use of object ownership by user
>processes.

A kernel does not care how real or virtual memory is used. All of the
usable RAM is allocated to a single virtual machine when there is only one.
A kernel allocates a part of RAM to each virtual machine where there are
more than one.

A kernel is not a virtual machine, is it? Garbage collection goes inside a
virtual machine, not a kernel. A kernel has neither objects nor classes. It
has no mechanism to interpret bytecode. These are all functions of a
virtual machine.

A virtual machine is linked to a kernel. It may be statically linked. It
may be dynamically linked. In the i386 build, decaf is statically linked to
jJOS. In the host build, decaf is statically linked to jJOS, but
dynamically linked to a Linux kernel. Neither the Linux kernel nor the jJOS
kernel does garbage collection; decaf does.





From tmiller@haverford.edu Wed, 3 May 2000 11:52:16 -0400 (EDT)
Date: Wed, 3 May 2000 11:52:16 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Java Processes: Final Summary?

> The key reference when talking about the GC is the reference from the
> shared object to its owning process (via the ProcessClassLoader).

	Which is maintained in the kernel.  Therefore, we can program the
garbage collector to ignore it.  (And if we've got a GC that ignores
reference cycles for purposes of determining liveness -- which it can do,
when it runs a GC from the root -- we don't need this, either.)

> A process-with-reference (or more correctly, a process running a program
> with a reference) to a shared object is indirectly causing the process
> that owns that object to hang around in memory needlessly.

	OK, I understand your point now.  Thanks for bearing with me :)

> Not its entire memory tree. If another process has a reference to one of
> its shared objects, the memory tree of that object will hang around in
> memory.

	I should have said, its exclusive tree.  Anything shared is now in
someone else's tree as well... which sounds alot like shared 'ownership',
doesn't it? :)

> Yes, weak references are a JDK 1.2 thing.

	Summary: probably not a good idea, for the programming annoyances
you mentioned above, unless we can't come up with anything better.

> Compare the concept of a hierarchical structure with a particular
> implementation of it. ... you say each child has an
> owning directory, or more commonly in this case, a parent directory.

	I think I'm slowly recovering from a bad case of keyboard vision
here.  Conceptually, yes, processes contain ('own') everything in them,
and that's where it matters.

> You want to depend on a dead process for functionality? I think that if
> a process was ever alive, its purpose was to live, and any functionality
> you're talking about should be carried on while it is still alive.

	Exactly.  Therefore, something absolutely terrible should happen
to the shared object if the process it depends on for functionality is
killed.  The handling of such objects is an open question; weak references
are designed to allow something awful to happen (e.g. GC), so they seemed
like a natural answer to me.

> However, and this is an idea I couldn't work out how to implement until
> you gave me the idea, it might be desirable to have processes that have
> no threads.

	The 'ObjectBroker' process comes to mind.  It may be
cleaner/easier to implement this as a process that has a single thread
whose run() method is "sleep();", though.

> I was never suggesting we add a reverse lookup. As you just said, the
> kernel already maintains ownership information. All I'm proposing is
> that we provide a function to reassign ownership. Multiple ownership can
> then be emulated without any further kernel support.

	I understand now.  (I think.  I sure didn't before.)  The proposal
is that the kerne/JVM adds only ownership-reassignment, and the user
library can provide the rest of the sharing API and implementation.  I
like it.

-_Quinn







From tmiller@haverford.edu Wed, 3 May 2000 11:56:06 -0400 (EDT)
Date: Wed, 3 May 2000 11:56:06 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Java Processes: Final Summary?

> A kernel is not a virtual machine, is it? Garbage collection goes inside a
> virtual machine, not a kernel. A kernel has neither objects nor classes. It
> has no mechanism to interpret bytecode. These are all functions of a
> virtual machine.

	True, and me and Ryan have been abusing terminology mercilessly
throughout this discussion, and really ought to stop. :)  Strictly,
garbage collection /could/ be a kernel function (is now, for that matter),
or a non-JVM native library, but writing one for a particular JVM gives a
GC striking advantages.


> Neither the Linux kernel nor the jJOS kernel does garbage collection;
> decaf does.

	I could argue this -- the current GC is a conservative GC written
in C living in common/nativecode/gc -- but common/nativecode is more of a
statically-linked library for decaf than actual kernel code, so I won't :)

-_Quinn





From gchii@mindspring.com Wed, 03 May 2000 18:41:26 -0400
Date: Wed, 03 May 2000 18:41:26 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [bytecode resource] Status Report

I have been working on a new version of a Java application that generates
C/C++ code for bytecode resources. On the one hand, it is a round-about way
to link binary data to an executable. On the other, it encapsulates raw
bytecode into a rc_Bytecode class. The rc_Bytecode class is intended to be
a vm-independent C++ class to extract data from raw bytecode.

The major change from my previous version is this: a factory is always
responsible for creating an implementation of the rc_Bytecode interface (a
pure virtual class). This means that the implementation of rc_Bytecode can
change from one vm to the next; or, rc_BasicBytecode can be extended to be
more vm-specific.

The factory method (in straight C) is this:

rc_Bytecode *rc_CreateBytecode( const void *payload, size_t size );





From ryan@whitewolf.com.au Thu, 04 May 2000 09:25:06 +1000
Date: Thu, 04 May 2000 09:25:06 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Bytecode vs. class definition

Matt.Albrecht@trilogy.com wrote:

> The JVM should of course take the
> bytecode and transform it into its internal optimized version.  Usually (as
> it seems), this also includes defining the superclass / interface pointers
> as well.  IMHO, only the "internal optimized version" should be shared,
> while the pointers to superclass / interfaces need to be tacked to the
> static data associated with the class instance.

Another interesting point. If we share class definitions without caring
which version of the superclass is being loaded (as we have apparently
been discussing), then the class definitions need tack on the
superclasses with the static data.

On the other hand, if we include the superclass pointers with the class
definition, we are saying that a class definition may only be shared
between two classes if their superclasses also share class definitions.
And if we do this, we don't have to worry about checking that
superclasses match when performing illegal casts.

However, if we do this, we don't get to share class definitions when the
superclasses are different versions. BUT, as I pointed out in my last
email, it is very rarely the case that the superclasses will be
different (the inheritance chain would have to go through a number of
different archives to even allow the possibility). So, my vote is for
keeping superclass pointers with the class definition. This allows us to
do illegal cast checks the way you wanted (ie. the "most correct" way)
at minimal computational expense.

> 2. If we only allow illegal casts with classes loaded by the primordial
> class loader, then all we need to check is if the two class instances
> indeed were loaded by that class loader, and have the same name, since
> class loaders should only allow one class instance per class name.

Note that there are multiple primordial class loaders: one per process.
If you are only considering a single primordial class loader, you are in
fact talking about "legal" casts, not "illegal" casts. "Illegal" casts
refers to casts between processes.

{{ BTW, Matt, you seem to be CC'ing the admin list automatically. Is
this something to do with your mail client? }}

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Thu, 04 May 2000 09:52:47 +1000
Date: Thu, 04 May 2000 09:52:47 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Java Processes: Final Summary?

"Todd L. Miller" wrote:
> 
> > The key reference when talking about the GC is the reference from the
> > shared object to its owning process (via the ProcessClassLoader).
> 
>         Which is maintained in the kernel.  Therefore, we can program the
> garbage collector to ignore it.  (And if we've got a GC that ignores
> reference cycles for purposes of determining liveness -- which it can do,
> when it runs a GC from the root -- we don't need this, either.)

I'm not sure this is a good idea. If the GC ignores the link from
ProcessClassLoader to ClassLoader, you also need to ensure that the
reference value of this link becomes null. And a better way to
accomplish the same thing would probably be to simply set this reference
to null the standard way. But what are the implications? Well for
starters, ProcessManager.getOwningProcess() will fail, and I think this
is conceptually bad. Setting this reference to point to another process
rather than null would be better, and a better way of doing this is to
re-assign the class loader link as I have been saying.

I don't know if I understand you're goal here. What makes it desirable
to break the conceptual model? (ie. that an object is always contained
within a process)

> > Not its entire memory tree. If another process has a reference to one of
> > its shared objects, the memory tree of that object will hang around in
> > memory.
> 
>         I should have said, its exclusive tree.  Anything shared is now in
> someone else's tree as well... which sounds alot like shared 'ownership',
> doesn't it? :)

The way I have been seeing it (as I described in another email) is that
there is a difference between sharing ownership and sharing access. This
looks like sharing access - meaning that there is still an original
owner and that affects things when you find that the owning process is
hanging around in memory until the other processes let go of the shared
object which it owns.

> > You want to depend on a dead process for functionality? I think that if
> > a process was ever alive, its purpose was to live, and any functionality
> > you're talking about should be carried on while it is still alive.
> 
>         Exactly.  Therefore, something absolutely terrible should happen
> to the shared object if the process it depends on for functionality is
> killed.  The handling of such objects is an open question; weak references
> are designed to allow something awful to happen (e.g. GC), so they seemed
> like a natural answer to me.

So, the functionality you're depending on in the dead process is to make
something terrible happen. Fair enough.

> > However, and this is an idea I couldn't work out how to implement until
> > you gave me the idea, it might be desirable to have processes that have
> > no threads.
> 
>         The 'ObjectBroker' process comes to mind.  It may be
> cleaner/easier to implement this as a process that has a single thread
> whose run() method is "sleep();", though.

Maybe the ObjectBroker might want to have its own threads to do other
stuff anyway. I suppose you could implement the ObjectBroker the way you
suggested. But I would like something more convenient for embedded
programs like servlets where the parent server simply calls
servlet.service(request, response) and the code in that method is
restricted to its namespace and its own UserToken. When you look at the
way the service() method is called, it is natural that the thread is
owned by the parent process, and the servlet doesn't actually have its
own thread. JDK 1.2 has the concept of changing privileges granted to
the running code depending on where the current class was loaded from.
That's sort of what I want. I need to work on the idea some more.

>         I understand now.  (I think.  I sure didn't before.)  The proposal
> is that the kerne/JVM adds only ownership-reassignment, and the user
> library can provide the rest of the sharing API and implementation.

Right. And the ownership-reassignment function depends on how we share
class definitions w.r.t. superclasses. See my response to Matt's email
for my thoughts on that. If we only share class definitions if the
superclasses also share class definitions, then ownership-reassignment
can easily be managed for all superclasses. If we can share class
definitions independently of the superclasses, then ownership
reassignment may fail if the superclasses don't match.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From tmiller@haverford.edu Wed, 3 May 2000 23:47:44 -0400 (EDT)
Date: Wed, 3 May 2000 23:47:44 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Java Processes: Final Summary?

public class SharedObject extends/* | implements */ SharedObjectAPI {
	public void doSomethingUseful() { /* like calculate pi */ }
	}

public class jpOne extends JavaProcess {
	public SharedObject so = null;

	public void run() {
		SharedObject so = new SharedObject();
		jpTwo jp = new jpTwo();
		jp.put( so );
		so.wait();
		so.notify();
		this.kill();
		} /* should die at the end of run, anyway */
	} /* end jpOne */

public class jpTwo extends JavaProcess {
	public SharedObject so = null;

	public void put( SharedObject so ) {
		this.so = so;
		so.notify();
		so.wait();
		so.doSomethingUseful();
		}
	} /* end jpTwo */

	Admittedly, this is the pathological case, but that just makes it
easier to consider.  jpOne generates a shared object, and as the parent of
the jpTwo process, has implicit permission to share so with it.  It then
waits for jpTwo to say that it has so, tells it move along, and kills
itself.  jpTwo notifies jpOne that it has the object, and then waits for
confirmation, after which if doesSomethingUseful() with so, the shared
object.  However, odds are good the so's process has been killed / died
/ lost in the woods.

	What do we want to happen right now?  Can we fail
so.doSomethingUseful() with a null pointer exception?  Is that semantically
legal?  (Probably not.)  Is it allowed by the VM or language
specs?  (Probably not.)  For simplicity's sake, a SharedObject doesn't
even have any fields; it's just used as a semaphore.  (Shared references
confuse the issue; I'm hoping we can deal with them recursively.)

	At a bare minimum, it's clear that anything aside from nulling
requires the class definition* of SharedObject -- wherever it may be
'located' -- to remain legal.  This is assured by normal garbage
collection; the so object in jpTwo requires a Class pointer, which in turn
contains a pointer to its definition.  (The static values in the class are
lost; I believe that the expectation is that a SharedObject would access
the statics of whichever process happened to be using it at the time,
information that would be procured from the scheduler.)  Any class
definition contains a reference to a super class.  Bytecode references are
purely symbolic; native references are pointers.  For native references,
this means that the super class will always be shared.  (Since we, by
definition, have a single copy of that pointer.  It is probably desirous
to force the sharing of class definitions to be recursive for this matter;
that is, all class references located in a class definition will either
match, or a share attempted; if any of them fail, the whole share fails.  
Otherwise, you hit type-safety snags.)  The picture for bytecode
references is similar; if we're maintaing bytecode payloads, we must have
the parent class's bytecode somewhere, and the two payloads can be checked
for equality.

	So the minimum is satisfied by the recursion necessary to succeed
in the share.  (This needs to be added to the summary.)  In fact, so long
as the originating/single-owner process remains live, the minimum is
sufficient for proper sharing; all references are still live.

	Back to the case at hand -- a hard reference to an object whose
'owner' pointer will prevent a threadless/killed/dead process from being
garbage collected.  I expect we agree that is Not Good.  Since the shared
object has already met the minimum requirements -- that is, without
references, it can't tell if it's operating in its originating process or
not -- it is transparent to re-write the classloader pointer to point to
jpTwo.**  So far, so good.  Referenceless shared objects work OK, because
we can transparently rewrite the classloader reference of the shared
object to avoid GC problems.***

	All static references are stored with the class in the process's
classloader, and exist on a per-process basis.  We have never considered
sharing classes themselves.  So static references in shared objects will
work just fine -- because we can rewrite the classloader reference of the
shared object to avoid GC problems.

	The problem is instance references.  Every instance reference
which escapes must be a shared object, for the same reasons we can't just
hand unchecked references around between processes.  I think to here is as
far as we've discussed; at least, it's as far as I have a good idea of
what's going on.  I believe, also, that the semantics of this care are
fairly clear; every escaping variable must be handled in the same as an
explicit request to share an object -- whatever that might be.

	If things follow the trend, we should come to a conclusion that
instance references in shared objects are OK, because we can
recursively rewrite the classloader references in all of them.

	All of this is in the case that the object's classloader reference
becomes invalid, and I think that is a key way of phrasing things.  A
process and (primordial, but that's what been under discussion)
classloader define each other; killing a process means invalidating its
classloader.  (Though not, necessarily, everything in it, because of
shared objects.)  It looks like three elements will suffice for general
object sharing:

(1) Shared class definitions.  This includes parent class definitions,
whensoever this might be checked.  (At share or access time.)  This is
provided and run by the kernel/VM.

(2) The ability to rewrite an object's classloader reference.  This is
provided by the kernel/VM to Java.  In the above examples, there was no
distinction made between rewriting an object's classloader reference, and
the CL references of the class it pointed to; since the classloader of the
class was already invalid, no harm is done by blind-writing to it.  (The
shared class under consideration will not be GC'd because jpTwo's
classloader has a pointer to it.)  In the general case, where both
processes are still active, it may be necessary to have a per-object CL
reference.  This needs more discussion.)

(3) The ability to determine when a classloader reference is invalid, and
then the ability to use (2) to correct it.

-_Quinn

* Here, I'm not concerned with the mechanics of definitions.  It seems
clear to me that we will eventually hammer out the differences between
native and bytecode representations so as to be able to use both to our
mutual advantage, if we haven't already.

** I won't go into the exact mechanism here, though clearly one that adds
no additional references is necessary.  A list must be attatched to the
shared object and maintained; I leave the question of how open to 'the
floor'. :)

*** Necessarily, the VM /must/ always ask for its current process rather
than following its classloader pointer when fetching classes on the shared
object's behalf.  Doing this for /every/ object, shared or not, will be
too expensive; some optimization will be necessary.  (An O(1) test if
there is more than one 'potential owner' -- e.g. accessor?)







From gchii@mindspring.com Fri, 05 May 2000 09:23:41 -0400
Date: Fri, 05 May 2000 09:23:41 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [JDK 1.2] Bad news

In one project, I'm using JDK 1.1 because it is the only one available for
OS/400. It depends heavily on the JDBC drivers inside IBM's "AS/400 Toolkit
for Java".

I was very surprised when this application stopped working on my machine.
It seems that the JDBC drivers inside IBM's "AS/400 Toolkit for Java" do
not work  on my machine with JDK 1.2. The virtual machine from JDK 1.2
locks up, so that even the Control+C signal does not work.

I won't speculate about what IBM will do. I won't guess what part of JDK
1.2 has become incompatible with the JDBC drivers. But I do know this:
backward compatibility is extremely important to my ultra-conservative
corporate customers. They want software that lasts. They do not want to
repeatedly write the same application year after year. There are so many
more applications they would like to write.

As for JOS, I want an operating system that I can use. I can't use an
operating system that requires me to repeatedly write the same applications
each year.





From ryan@whitewolf.com.au Mon, 8 May 2000 10:38:29 +1000 (EST)
Date: Mon, 8 May 2000 10:38:29 +1000 (EST)
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Java Processes: Final Summary?

5 days later...

(sorry)

On Wed, 3 May 2000, Todd L. Miller wrote:

> 	At a bare minimum, it's clear that anything aside from nulling
> requires the class definition* of SharedObject -- wherever it may be
> 'located' -- to remain legal.  This is assured by normal garbage
> collection; the so object in jpTwo requires a Class pointer, which in turn
> contains a pointer to its definition.

Understood.

> (The static values in the class are
> lost; I believe that the expectation is that a SharedObject would access
> the statics of whichever process happened to be using it at the time,
> information that would be procured from the scheduler.)

At this point we disagree. I believe that:

- static values won't be lost until the class they are associated with
  is garbage collected.
- the expectation is that a SharedObject would internally access the
  statics associated with the object's class.

I think we need to do it right so it works in complex cases. In the
windowing system, shared objects may be as complex as swing components.
Those objects may work with the rest of the swing system via statics, so
it is important that the shared objects which communicate with the rest
of the window manager (via statics) actually communicate with the rest
of the window manager - not with the uninitialised statics in the
calling process.

> Any class
> definition contains a reference to a super class.  Bytecode references are
> purely symbolic; native references are pointers.  For native references,
> this means that the super class will always be shared.

Great, so this does solve the problem of incompatible superclasses (ie.
to share class definitions, we must share the superclass' class
definitions).

> Otherwise, you hit type-safety snags.)  The picture for bytecode
> references is similar; if we're maintaing bytecode payloads, we must have
> the parent class's bytecode somewhere, and the two payloads can be checked
> for equality.

I think the bytecode cache can ignore the superclasses - it saves
memory. It is when class definitions are formed or reused from the cache
that the superclass constraint must apply. The two caches are separate
so they can have different rules depending on their requirements.

> 	Back to the case at hand -- a hard reference to an object whose
> 'owner' pointer will prevent a threadless/killed/dead process from being
> garbage collected.  I expect we agree that is Not Good.  Since the shared
> object has already met the minimum requirements -- that is, without
> references, it can't tell if it's operating in its originating process or
> not -- it is transparent to re-write the classloader pointer to point to
> jpTwo.**  So far, so good.  Referenceless shared objects work OK, because
> we can transparently rewrite the classloader reference of the shared
> object to avoid GC problems.***

As I've said, we disagree here. I think an object needs to know which
process it's running in. I don't see why it is a "minimum requirement"
that an object not know what process it's running in. This is not
necessary to rewrite the class loader reference, and if we do it, I
believe the system won't work correctly.

> 	The problem is instance references.  Every instance reference
> which escapes must be a shared object,

Or as I see it, every instance reference which escapes is, by
definition, a shared object. Is that the way you see it?

> 	All of this is in the case that the object's classloader reference
> becomes invalid, and I think that is a key way of phrasing things.  A
> process and (primordial, but that's what been under discussion)
> classloader define each other; killing a process means invalidating its
> classloader.  (Though not, necessarily, everything in it, because of
> shared objects.)

Note that if we have thread-less processes (as I discussed in a previous
email), the class loader should not be invalidated. We have two options:

1. Invalidate the class loader only for "normal" processes once they
die (your suggestion), ie. when they have no more threads running.
Thread-less processes, however, would not have their class loaders
invalidated in this case.

2. Handle it generically: never invalidate the class loader. Allow it to
operate until it is garbage collected.

At this point I don't know which way is best but I thought I'd point out
that (1) is not the only way.

If your goal is to make something "very bad" happen when the owner of a
shared object dies, then (1) can achieve part of that goal, but it won't
have any affect unless the shared object tries to load a new class.
Maybe the answer is to invalidate the process rather than invalidate the
class loader. Invalidating the class loader prevents you from loading
classes, but invalidating the process (however that is implemented)
stops anything in that process from working. I have no idea how to
implement this though, and maybe we can just forget about it and go with
(2) alone.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Mon, 08 May 2000 14:37:17 +1000
Date: Mon, 08 May 2000 14:37:17 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] rheise.os-0.1.4-pre1 screenshot (plus name change)

Hello people.

I have put up a screenshot of my current development version of
rheise.os running at full screen at:

http://www.progsoc.uts.edu.au/~rheise/projects/rheise.os/rheise.os-0.1.4-pre1-screenshot.gif

SwingToolkit is getting to the point where it is actually kinda usable.
There is now one AWT EventDispatchThread per process, too, which is more
compatible with the spec.

Another reason for sending this email before I release the next version
is that rheise.os is ready for a name change, you know, since rheise.os
is a tad unimaginative :-) My classes will be renamed to jos.* in this
release but will be packaged under a different "product" name. This
prevents tie-in to rheise.os, so long as we define common class names
and method names in a sort of JOS Specification (rather like POSIX).

My question to the JOS team is, does anyone have any ideas for a name?
The usual requirements apply: it should be catchy, cool'ish, abstract,
and must contain the letter 'X' :-) Ok, the 'X' is not a requirement.
I'd just as easily go for 'K', 'S' or 'T'.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From gchii@mindspring.com Mon, 08 May 2000 12:51:15 -0400
Date: Mon, 08 May 2000 12:51:15 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [JOS 1f] Update

For more information on JOS Technical Edition - Release 1f, see the
following article on JOS Wiki:

<URL:http://www.metamech.com/wiki/view/Main/JOSDistribution1f>





From tmiller@haverford.edu Mon, 8 May 2000 18:11:00 -0400 (EDT)
Date: Mon, 8 May 2000 18:11:00 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] name change

klaws -- Kit for Light-weight Abstract Windowing with Swing
lokjaw - Light-weight Object Kit for Java (JOS) Abstract Windowing
awoks -- Abstract WindOw Kit in Swing
swat --- Swing Windowing for Abstract Toolkits
	
-_Quinn






From ryan@whitewolf.com.au Tue, 09 May 2000 09:50:31 +1000
Date: Tue, 09 May 2000 09:50:31 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] name change

"Todd L. Miller" wrote:
> 
> klaws -- Kit for Light-weight Abstract Windowing with Swing
> lokjaw - Light-weight Object Kit for Java (JOS) Abstract Windowing
> awoks -- Abstract WindOw Kit in Swing
> swat --- Swing Windowing for Abstract Toolkits

Thanks for your suggestions. Just to be clear though, I'm happy to leave
SwingToolkit with its current name, but I'm after a new name for
rheise.os (which just handles the core part of the Java layer:
processes, users and security, while SwingToolkit is an add-on that
supports the execution of graphical applications (in the same way X and
Gnome are add-ons)).

Is anyone here well versed in mythology (ie. can extract interesting
names from myths) or know the names of interesting place names?

Thanks again for your suggestions.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From tmiller@haverford.edu Mon, 8 May 2000 19:36:14 -0400 (EDT)
Date: Mon, 8 May 2000 19:36:14 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] name change

> but I'm after a new name for rheise.os

	Oop.  I misunderstood you completely.  That'll show me to write
email at four in the morning :)

-_Quinn





From gchii@mindspring.com Tue, 09 May 2000 21:41:48 -0400
Date: Tue, 09 May 2000 21:41:48 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [websource 3b] Release 3

Release 3 of WebSource 3b is now available. See the DownloadWebSource
article on JOS Wiki for more information.





From gchii@mindspring.com Tue, 09 May 2000 21:42:32 -0400
Date: Tue, 09 May 2000 21:42:32 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [Smart API 2a] Release 9

Release 9 of Smart API 2a is now available. See the DownloadSmartAPI
article on JOS Wiki for more information.





From gchii@mindspring.com Tue, 09 May 2000 22:06:14 -0400
Date: Tue, 09 May 2000 22:06:14 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [CVS Snapshot] Release 1

Release 1 of "CVS Snapshot 1f" is now available for immediate download. See
the DownloadCVSModules article on JOS Wiki for more information.





From robfitz@geocities.com Wed, 10 May 2000 15:42:58 +0000 (UTC)
Date: Wed, 10 May 2000 15:42:58 +0000 (UTC)
From: Robert Fitzsimons robfitz@geocities.com
Subject: [JOS-Arch] JOS news on JavaLobby

Hi all

There seems to have been a post on JavaLobby yesterday
<URL:http://www.javalobby.org/servlet/News?action=displayStories&xsl=comment.xsl&format=full&id=510100000000663>.  It's
about the progress of the project, and the good news is that it is good
news.  :)

There is a request for an update about the project, i'm going to try and
post something about this.  But it would be good if some of the other
developers could post something want's going on, ie the move
to sourceforge, multipule java process, etc.

I've haven't been taken part in any of the discussions over the last few
months, so don't leave this up to me. ;)

Robert Fitzsimons
robfitz@geocities.com





From tmiller@haverford.edu Wed, 10 May 2000 18:11:43 -0400 (EDT)
Date: Wed, 10 May 2000 18:11:43 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] JOS news on JavaLobby

	Gilbert should discuss what he's been doing w.r.t. continous
source releases and his new packages, because I don't really know much
about them.

	Likewise, Ryan should discuss SwingToolkit and rheise.os -- which
means it ought to have its new name soon, huh?

	I'll talk a little about multiple java processes and the move to
SourceForge here.

	Multi-processing is a necessity for a modern operating
system.  Conventional JVMs and O/S's team up to run multiple java
processes by running multiple JVMs.  This is not particularly
efficient; the class library must be reloaded and stored separately for
each JVM.  While it may be possible to write a JVM such that it could
share class definitions between instances of itself, we have chosen to
implement multiple Java processes in a single JVM.*

	The idea is relatively straightforward, starting with the
observation that processes are processes because they posses their own
address space.  Typically, this is handled in the hardware MMU, which
allows a program to poke at any virtaul memory address and have it
transparently translated to the physical address.  In Java, because there
are no (arbitrary) pointers, it is not necessary to involve the hardware;
a given process can only point at things it already owns.  The two
pictures are as follows: imagine a process as a transparency, with used
memory being dots on it.  Normally, you have a stack of such
transparencies, and the MMU shuffles them around so that the light from
the projector passes through no more than one dot on its way to the screen
-- the mapping of virtual to physical memory.  (Virtual memory/swap space
adds a larger and slower light.)  Multiple Java processes in a single JVM
-- that is, on a single sheet -- are possibly because the JVM can just
tile the sheet with dots, as the processes can't ask for a dot in a random
memory location; since there is only one sheet, we don't have to worry
about contending for the light.  For more on this, please see
http://www.metamech.com/wiki/view/Main/?topic=MultipleJavaProcesses.


* In part because our current kernel does not support native multitasking.


	Our move to SourceForge is part of more general project, still
underway, of reorganizing JOS's presence on the web.  Primarily, we're
SourceForge for its cvs and cvsweb services, both of which were
administrative headaches.  Once it's ready, we'll be adopting the sfWiki
project and using it host our Wiki on SourceForge as well.  (Thanks to the
kind folks at metamech for hosting it for so long!)  sfWiki uses PHP and
MySQL, so we should be able to reactivate several features we had
deactivated (searching among them) because they used too many resources
with our current implementation for metamech to host them.  (IIRC, of
course.)  We'll also be adding some aliases to simplify links to and
within our website, and improve our ability to correct machine problems
that may occur.  We want to roll out cvs.jos.org, lists.jos.org,
ftp.jos.org, and wiki.jos.org sometime soon.

-_Quinn









From ryan@whitewolf.com.au Thu, 11 May 2000 11:30:18 +1000 (EST)
Date: Thu, 11 May 2000 11:30:18 +1000 (EST)
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] JOS news on JavaLobby

On Wed, 10 May 2000, Todd L. Miller wrote:

> 	Likewise, Ryan should discuss SwingToolkit and rheise.os -- which
> means it ought to have its new name soon, huh?

Here's my write-up. It's a bit higher level than your bit. It starts off
by talking about the basic architecture: kernel -> JVM -> Java layer.
I've created my javalobby account so I can post it whenever (the sooner
the better since our story is scrolling off the front page already).

====

In addition to Robert's introduction, I would like to give a brief
overview of the parts of JOS which I have been working on. An important
goal of JOS is to provide a highly efficient kernel so that most of the
operating system code can be written in the Java language itself. I use
the term kernel to refer collectively to the actual kernel and the JVM.
Our JVM is written by _Quinn (Todd Miller) and is currently built on top
of the JJOS kernel, written by John Morrison.

My focus is on the Java layer of JOS which implements the user/security
model and much of the process architecture, including inter-process
communication. My research so far has mainly revolved around how to
implement multiple processes, how to save memory when different
processes are using the same class files (without violating the spec),
and how to support inter-process communication using object sharing as a
primitive. My original proposal, which is old but still relevant, is at:

	http://www.progsoc.uts.edu.au/~rheise/jos/java_processes.txt

_Quinn (a major participant in the brainstorming phase) will give a more
up to date perspective on processes as it relates to his Virtual
Machine.

Since all people ask is "show me the code!", yes, I do have some code
available. rheise.os (name change pending :-) is a multiple process Java
execution environment designed to handle processes on top of _Quinn's
JVM, but based on a flexible architecture that also supports execution
on top of a standard JVM (to the extent that is possible). A screenshot
of the next release is available at:

	http://www.progsoc.uts.edu.au/~rheise/projects/rheise.os/rheise.os-0.1.4-pre1-screenshot.gif

Yes, that's a pure Java window manager (replacement AWT Toolkit using
Swing as its backend). I have not yet released the code to this version
(wait 'till the weekend), but the current version is available at:

	http://www.progsoc.uts.edu.au/~rheise/projects/rheise.os/

Be warned that it is only known to work on JDK 1.1.x for Linux with
Swing 1.1.x. If you notice anything not working in release 0.1.3,
version 0.1.4 will be a vast improvement (for instance, SwingToolkit
(the replacement AWT Toolkit) actually sort of works in 0.1.4, as
demonstrated in the screenshot).

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/


-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Thu, 11 May 2000 13:03:27 +1000
Date: Thu, 11 May 2000 13:03:27 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] JOS news on JavaLobby

Ryan Heise wrote:

> Here's my write-up. It's a bit higher level than your bit. It starts off
> by talking about the basic architecture: kernel -> JVM -> Java layer.
> I've created my javalobby account so I can post it whenever (the sooner
> the better since our story is scrolling off the front page already).

Done.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From gchii@mindspring.com Thu, 11 May 2000 10:45:24 -0400
Date: Thu, 11 May 2000 10:45:24 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

At 06:11 PM 5/10/00 -0400, "Todd L. Miller" <tmiller@haverford.edu> wrote:
>	Multi-processing is a necessity for a modern operating
>system.  Conventional JVMs and O/S's team up to run multiple java
>processes by running multiple JVMs.  This is not particularly
>efficient; the class library must be reloaded and stored separately for
>each JVM.  While it may be possible to write a JVM such that it could
>share class definitions between instances of itself, we have chosen to
>implement multiple Java processes in a single JVM.*

What is the critical difference between JNI and MPCL? It is not the
reloading of classes. It is not the sharing class definitions. It is not
the implementing of multiple Java processes in a single machine code
process. The critical difference between JNI and MPCL is this:

1. JNI is supported by hundreds of organizations; MPCL is not. Both conform
to the same Java Virtual Machine Specifications. Both manage multiple
bytecode processes in a single machine code process.

2. JNI automatically creates four threads per bytecode process; MPCL might
create only three. The four threads are main thread, UI thread, garbage
collection thread and finalizer thread. Of the four threads, only garbage
collection thread is different. JNI creates a process-wide garbage
collection thread. MPLC creates a vm-wide garbage collection thread.

Otherwise, JNI and MPCL are the same.

Efficiency is beyond the scope of the Java Virtual Machine Specification. A
highly efficient virtual machine comes from the hard work of a virtual
machine designer. There are already many highly efficient virtual machines
using both the classic and JNI design.

Some programmers have written a obviously poor implementation of
ClassLoader.findSystemClass(). We can't dismiss the entire classic design
just because of that. The greatest inefficiency of some virtual machines
comes from their primordial class loader. The specification does not
require a virtual machine to implement a inefficient primordial class
loader. Any primordial class loader will do. A class loader could obtain
all of its classes from bytecode as a resource. A class loader can obtain
all of its classes through a dynamic shared library or a primordial class
service. It does not need a local file subsystem. An efficient class loader
does not need to keep track of where classes came from.

No matter how fast it is, it still exists. Each new class must be loaded,
verified and resolved. The creation, verification and resolution of classes
cannot be removed successfully and maintain compatibility with the
specification. Every virtual machine must create and resolve every class in
the standard class library for every independent process. This step cannot
be skipped, only made more efficient.

A cache of platform-independent bytecode would make it more efficient. A
cache of platform-dependent class definitions would make it more efficient.
In the end, a virtual machine must create a unique class that is owned
exclusively by a process. Even if that class is a proxy for some hidden
component, it still exists and must be created. Even if a class is a shared
object, it still exists and must be shared.

Conventional JVMs use either a classic or JNI design. The classic design
should not be confused with the JNI design. The primordial class loader in
the classic design is not particularly efficient. For example, a poor
implementation of CLASSPATH enables someone to run a virtual machine with
the wrong standard class libraries. The virtual machine specification does
not require this. You /can't/ get it wrong on IBM's JVM for OS/400.

The JNI design is far more efficient. The JNI design enables many JVMs in a
single machine code process. An highly efficient virtual machine for OS/400
has been available from IBM for at least a year, maybe longer. IBM chose to
implement multiple Java processes in a single JVM.

Multiple primordial class loader is a research project. It is only a little
different than the classic and JNI design. A MPCL-compatible virtual
machine is an extension of the classic design, not JNI. It enables a
virtual machine to run multiple bytecode processes by enabling multiple
primordial class loaders. A combination of JNI and MPCL is possible.

While a JNI-compatible design assumes at least four threads for each
bytecode process, an MPCL-compatible design does not. With all four threads
it becomes only slightly more efficient than JNI.

Without three threads for each bytecode process, the MPCL is incompatible
with the specification. Even MPCL needs a finalizer thread, so that the
finalize() method runs in the correct bytecode process. You wouldn't want
code in a finalize() method to run in some other process, would you?

All three designs can be made more efficient with bytecode as a resource
and/or a bytecode cache and/or a class definition cache. There is nothing
inherent in MPCL that always makes it better than classic or JNI designs.

Look at JNI. There is nothing inherent in multiple virtual machines that
requires more than a single machine code process.





From ryan@whitewolf.com.au Mon, 15 May 2000 00:58:42 +1000
Date: Mon, 15 May 2000 00:58:42 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] rheise.os-0.1.4-pre4

This is prerelease 4 of rheise.os-0.1.4. I haven't had time to put
together a proper release, but at least you can try out the new
functionality I've been working on:

	http://www.progsoc.uts.edu.au/~rheise/projects/rheise.os/

The main changes in this release are:

	- Packages renamed to jos.*
	- SwingToolkit more usable.
	- Preliminary JDK 1.2 support.

Windows is still an issue. I don't have a copy of Windows so I am unable
to test it. I have heard that there are various security exceptions that
get thrown because I'm doing evil things, but I believe that can be
fixed by editing the security policy file for your JVM. If not, there is
probably another way to get it to work.

A few things to notice: in graphics mode, the shell program runs inside
a graphical terminal program called GTerm (like xterm). It's very basic
- no scrollbar yet, and the delete key actually, inserts a delete
character, but it basically works. Also note that shell commands can now
be followed by a '&' to run a command in the background. Since you will
have downloaded JTA, you may as well try running de.mud.jta.Main
<hostname> to test running the telnet app from inside SwingToolkit.

BTW, thanks to everybody who suggested new names for rheise.os. I
haven't decided which one I'll go with yet, but I will eventually.

Here is the full change-log for this release:

 - Renamed rheise.os.* to jos.*
 - Renamed rheise.os.impl.* to josp.* (jos-private)
 - JavaProcess.waitFor() skips daemon threads.
 - JavaProcess.waitForAll() includes daemon threads.
 - JavaProcess.destroy() implemented using ProcessDeath.
 - All processes are added to the root thread group.
 - HostProcessClassLoader works with jars and zips.
 - Implemented a simple archive cache for class loading efficiency.
 - HostInit is now a process spawned by HostBoot.
 - HostBoot provides a -g option to enable graphics mode.
 - Standard awt.toolkit no longer supported (must use SwingToolkit).
 - SecurityManager delegator is no longer set (interferes with menus).
 - Provided hook to allow SwingToolkit to clean up after process dies.
 - Fixed System.exit() so it works from within AWT Thread.
 - JDK 1.2/Linux works in text mode.
 - Introduced jos.system package (includes shutdown() method).

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Mon, 15 May 2000 07:49:55 +1000
Date: Mon, 15 May 2000 07:49:55 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] rheise.os-0.1.4-pre4

Gilbert Carl Herschberger II wrote:
> 
> At 12:58 AM 5/15/00 +1000, you wrote:
> > - Introduced jos.system package (includes shutdown() method).
> 
> Ugh! There is already a jos.system package. The jos.system package already
> contains these classes:
> 
> console
> consoled
> ConsoleDriver
> interrupt
> interrupts
> machine
> 
> You should pick another package name. You should check the "all packages"
> list to make sure a package has not been used.

I believe the OTHER package was incorrectly named :-)

Take a look at my email about jos.* being the most convenient package
name for classes application writers would like to write against. For
example, jos.process.JavaProcess. Interrupts/ConsoleDriver..., on the
other hand is something that should be hidden in some kernel package,
only to be seen by kernel developers or driver writers. I don't think
it's too late to change the other package used by decaf if people agree
with the package organisation I proposed in that other email.

I'll CC this to the list for people to comment.

I'm not sure where classes like interrupt and ConsoleDriver should go,
but I think jos.system is better used as a packag name for classes that
Application developers might program against. If we do think it makes
sense for these classes to go somewhere in jos.*, then perhaps they can
go in jos.kernel.*.

Thoughts?

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From jewel@pixie.co.za Sun, 14 May 2000 23:39:00 -0200 (GMT+2)
Date: Sun, 14 May 2000 23:39:00 -0200 (GMT+2)
From: jewel@pixie.co.za jewel@pixie.co.za
Subject: [JOS-Arch] [bytecode resource] Status report

> I have finished a BytecodeResource application using the Java programming
> language. It searches a directory tree for .class files and generates the
> corresponding C++ source code. Basically, this puts the raw data from a
> .class file into the DATA segment of your C++ program.

Forgive me for asking (I haven't been following the list closely), but why
do you want to do this?

John






From jewel@pixie.co.za Mon, 15 May 2000 04:46:10 -0200 (GMT+2)
Date: Mon, 15 May 2000 04:46:10 -0200 (GMT+2)
From: jewel@pixie.co.za jewel@pixie.co.za
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

On Thu, 11 May 2000, Gilbert Carl Herschberger II wrote:
> At 06:11 PM 5/10/00 -0400, "Todd L. Miller" <tmiller@haverford.edu> wrote:
> >	Multi-processing is a necessity for a modern operating
> >system.  Conventional JVMs and O/S's team up to run multiple java
> >processes by running multiple JVMs.  This is not particularly
> >efficient; the class library must be reloaded and stored separately for
> >each JVM.  While it may be possible to write a JVM such that it could
> >share class definitions between instances of itself, we have chosen to
> >implement multiple Java processes in a single JVM.*
> 
> What is the critical difference between JNI and MPCL? It is not the
> reloading of classes. It is not the sharing class definitions. It is not
> the implementing of multiple Java processes in a single machine code
> process. The critical difference between JNI and MPCL is this:
> 
> 1. JNI is supported by hundreds of organizations; MPCL is not. Both conform
> to the same Java Virtual Machine Specifications. Both manage multiple
> bytecode processes in a single machine code process.

What is JNI? Are you referring to the Java Native Interface? 

> ....... 
> 
> Efficiency is beyond the scope of the Java Virtual Machine Specification. A
> highly efficient virtual machine comes from the hard work of a virtual
> machine designer. There are already many highly efficient virtual machines
> using both the classic and JNI design.

What is the JNI design?
 

John Leuner






From gchii@mindspring.com Mon, 15 May 2000 10:23:39 -0400
Date: Mon, 15 May 2000 10:23:39 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [bytecode resource] Status report

At 11:39 PM 5/14/00 -0200, "jewel@pixie.co.za" <jewel@pixie.co.za> wrote:
>Forgive me for asking (I haven't been following the list closely), but why
>do you want to do this?

Treating bytecode as a C/C++ resource puts the raw data from a .class file
into the DATA segment. It stores bytecode in the same file with a virtual
machine.

I am working toward a primordial class loader that enables a virtual
machine and its vm-specific classes to be statically linked into a single
executable image. A single executable image is easier to boot and easier to
make ROM-able.

A primordial class loader must load vm-specific classes. It is one of the
implementation details outlined in the Java Virtual Machine Specification.
Each virtual machine must implement some kind of primordial class loader.

IBM's JDK 1.1.6 on OS/400 is a good example of how it should work. This
virtual machine always knows how to load its vm-specific classes. It never
puts the standard class library on CLASSPATH. It simplifies the launch of a
Java application. Compared to other virtual machines, it is more difficult
to get CLASSPATH wrong. Its primordial class loader won't allow you to load
the wrong vm-specific classes. It is neither necessary nor desirable to
store a virtual machine and its vm-specific classes in separate files. It
is certainly not desireable to load vm-specific classes through CLASSPATH.

In addition, an executable image is always read-only. There is a critical
advantage in letting a virtual memory manager know what is read-only versus
read-write. Bytecode is read-only, too. Using bytecode as a resource in the
DATA segment reduces the footprint of a virtual machine at runtime.

If that were not enough, it is possible to reduce the size of a virtual
machine further. This enables a file subsystem to be written in bytecode
and then used to load the rest of the standard class library -- as needed
-- from a local storage device. Elsewhere, the rest of the standard class
library can be downloaded -- as needed -- across a network.





From gchii@mindspring.com Mon, 15 May 2000 10:47:37 -0400
Date: Mon, 15 May 2000 10:47:37 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

At 04:46 AM 5/15/00 -0200, "jewel@pixie.co.za" <jewel@pixie.co.za> wrote:
>What is JNI? Are you referring to the Java Native Interface?

Yes, JNI is Java Native Interface.

>What is the JNI design?

The JNI design enables a machine code process to create multiple instances
of a virtual machine, running each virtual machine in a separate machine
code thread. While only one dynamic shared library is loaded, JNI enables
your program to call the JNI_CreateJavaVM() method repeatedly. JNI
enumerates each virtual machine that has already been created with the
JNI_GetCreatedJavaVMs() method.

Each virtual machine has its own primordial class loader and four threads:
main thread, user interface thread, garbage collection thread and finalizer
thread.

For more information, see also the ProcessDiagramJNI article on JOS Wiki.





From gchii@mindspring.com Mon, 15 May 2000 11:40:02 -0400
Date: Mon, 15 May 2000 11:40:02 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [bytecode resource] Update

I am continuing to work on bytecode as a resource. At this point, my
implementation of rc_Bytecode in C++ is able to do the following things:

 - check a magic number,
 - check a version,
 - get number of items in codepool,
 - get each item in a codepool (raw),
 - get the class access,
 - get this class spec, and
 - get super class spec (or NULL).

Next, I will turn my attention to

 - get interface count, and
 - get interface spec.





From jewel@pixie.co.za Mon, 15 May 2000 19:18:48 -0200 (GMT+2)
Date: Mon, 15 May 2000 19:18:48 -0200 (GMT+2)
From: jewel@pixie.co.za jewel@pixie.co.za
Subject: [JOS-Arch] [bytecode resource] Status report

On Mon, 15 May 2000, Gilbert Carl Herschberger II wrote:
> At 11:39 PM 5/14/00 -0200, "jewel@pixie.co.za" <jewel@pixie.co.za> wrote:
> >Forgive me for asking (I haven't been following the list closely), but why
> >do you want to do this?
> 
> Treating bytecode as a C/C++ resource puts the raw data from a .class file
> into the DATA segment. It stores bytecode in the same file with a virtual
> machine.
> 
> I am working toward a primordial class loader that enables a virtual
> machine and its vm-specific classes to be statically linked into a single
> executable image. A single executable image is easier to boot and easier to
> make ROM-able.

Ok, so you are only planning to put vm-specific classes in this image? 
 
> A primordial class loader must load vm-specific classes. It is one of the
> implementation details outlined in the Java Virtual Machine Specification.
> Each virtual machine must implement some kind of primordial class loader.
> 
> IBM's JDK 1.1.6 on OS/400 is a good example of how it should work. This
> virtual machine always knows how to load its vm-specific classes. It never
> puts the standard class library on CLASSPATH. It simplifies the launch of a
> Java application. 

Ok, there is a big difference between the vm-specific classes and the
class library. The class library (including swing, database extensions etc
etc) could run into multiple megabytes, in which case it would definitely
not belong in that image. 

>Compared to other virtual machines, it is more difficult
> to get CLASSPATH wrong. Its primordial class loader won't allow you to load
> the wrong vm-specific classes. It is neither necessary nor desirable to
> store a virtual machine and its vm-specific classes in separate files. It
> is certainly not desireable to load vm-specific classes through CLASSPATH.

I agree with you. The only problem is that you are wasting some space. You
are keeping the bytecode in the image (which is loaded into memory), and
then you are going to build the internal class structure (which will have
a copy of the bytecode again, and the results of resolving the constant
pool). The intial raw class data is going to stay in memory "forever" but
it is only needed for a short period of time (at startup).

> In addition, an executable image is always read-only. There is a critical
> advantage in letting a virtual memory manager know what is read-only versus
> read-write. Bytecode is read-only, too. 

I don't see where this is really an advantage. Once you you've loaded,
linked and resolved a class you don't need the bytecode anymore. You can
flag the actual method code to be interpreted as read-only anyway.

> Using bytecode as a resource in
> DATA segment reduces the footprint of a virtual machine at runtime.

This doesn't follow.

I'm assuming the whole image gets loaded into memory before execution, and
also stays there until parts get paged out. In this case it makes sense to
have the image as small as possible.

> If that were not enough, it is possible to reduce the size of a virtual
> machine further. This enables a file subsystem to be written in bytecode
> and then used to load the rest of the standard class library -- as needed
> -- from a local storage device. Elsewhere, the rest of the standard class
> library can be downloaded -- as needed -- across a network.

This is a very elegant approach. Writing the file-system reader in Java
(as opposed to C/C++) and having it available immediately on startup. 

Another way of doing this would be to compile that file-system reader to
native-code (assuming you have the tools to do this), and then just
firing off that to load whatever is needed from disk to get the VM going.

John Leuner





From gchii@mindspring.com Mon, 15 May 2000 18:30:48 -0400
Date: Mon, 15 May 2000 18:30:48 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [bytecode resource] Status report

At 07:18 PM 5/15/00 -0200, "jewel@pixie.co.za" <jewel@pixie.co.za> wrote:
>Ok, so you are only planning to put vm-specific classes in this image?

I'm planning to put "boot" classes inside this image. This includes some
vm-specific classes and part of the standard class library. I do not intend
to put all java.* and javax.* into the executable image.

>Ok, there is a big difference between the vm-specific classes and the
>class library. The class library (including swing, database extensions etc
>etc) could run into multiple megabytes, in which case it would definitely
>not belong in that image.

I only wanted to provide one example of a virtual machine that conforms to
the Java Virtual Machine Specification and yet does not find rt.jar through
CLASSPATH.

>I agree with you. The only problem is that you are wasting some space. You
>are keeping the bytecode in the image (which is loaded into memory), and
>then you are going to build the internal class structure (which will have
>a copy of the bytecode again, and the results of resolving the constant
>pool). The intial raw class data is going to stay in memory "forever" but
>it is only needed for a short period of time (at startup).

Again, the wasted space you mention doesn't exist (yet). Your idea of an
internal class structure is obviously different than mine. Your idea of
resolving the constant pool is obviously different than mine. Whenever the
original can be used, the original should be used. Hopefully, the raw class
data for boot classes will stay in memory because a virtual machine
interprets the original opcodes, not a copy.

A primordial class loader is an implementation of the findSystemClass()
method of java.lang.ClassLoader. All of this is internal to a virtual machine.

>I don't see where this is really an advantage. Once you you've loaded,
>linked and resolved a class you don't need the bytecode anymore. You can
>flag the actual method code to be interpreted as read-only anyway.

When a method is invoked, the Code attribute will be interpreted. It is
still needed.

Constants in a DATA segment are loaded as needed when an executable image
is mapped by a virtual memory manager. It is easy for a VMM to discard a
constant when it is no longer "used".

>I'm assuming the whole image gets loaded into memory before execution, and
>also stays there until parts get paged out. In this case it makes sense to
>have the image as small as possible.

The whole image does may not load completely before execution. A virtual
memory manager can map an executable image. Then, constant data is loaded
only through page faults.

>This is a very elegant approach. Writing the file-system reader in Java
>(as opposed to C/C++) and having it available immediately on startup. 
>
>Another way of doing this would be to compile that file-system reader to
>native-code (assuming you have the tools to do this), and then just
>firing off that to load whatever is needed from disk to get the VM going.

Yes, it is a clean design. Whatever can be written in bytecode should be
written in bytecode. This part must be written in bytecode because the file
subsystem is a plug-in. Anyone can write a file subsystem. As long as it
implements the well-known interfaces, it can work in this virtual machine.

The start up sequence and boot classes provide a way to load the file
subsystem plug-in. A file subsystem might be specified as a "module" in
GRUB, instead of the boot classes.





From tmiller@haverford.edu Mon, 15 May 2000 19:27:44 -0400 (EDT)
Date: Mon, 15 May 2000 19:27:44 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

>From the JNI spec:

> JDK 1.1 does not support creating more than one VM in a single process. 

	The '1.2 enchancements' page makes no mention of this limitation
being removed, or if it remains.  In the context of the 1.1 spec, I
understand this to mean that a single /calling/ process may not have more
than one VM -- not placing any limits on the VM itself.  The lack of such
a mention in the 1.2 spec would seem to leave open the possibility of a
'dispatch' process and/or IPC on the JVM handle for a single process which
uses JNI to generate > 1 JVM.

> Look at JNI. There is nothing inherent in multiple virtual machines that
> requires more than a single machine code process.

	And there is also nothing inherent in them to support
efficiency.  You said,

> IBM chose to implement multiple Java processes in a single JVM.

	/as do we/.  I do not know how IBM implemented multiple multiple
Java processes, or if it is possible to find out.  Perhaps, since they
(AFAIK) neglected to provide a Java-side API for processes, they are
runnig disjoint JVMs in a single process; your description leads to me to
believe that they have discovered or implemented an efficient method for
sharing class definitions accross those JVMs -- could you confirm this?  
If they have, it is to the loss of the Java community that they neglected
to tell anyone else (AFAIK) how to do this.  If they did (or have released
source to their JVM), I would be very interested in reading it.

	The decision to support multiple Java processes in single JVM was
arrived at because we thought it would be easier to do such a thing than
(a) program multiple /native/ processes and then (b) implement
sufficiently advanced and efficient IPC to allow the efficiencies which
have so concerned us in our discussions.

	JNI is a specification for the interface between a native program
and (in 1.2) one our JVMs.  MPCL is a specification for the implementation
of more than one Java process in an efficient manner.  Ryan's 'os' package
is the standard (albiet informal) interface to this ability.  (That is, it
is like JNI for Java.)  MPCL, in fact, may be an option for the
implementation of JNI.  (Which would be nice, should JOS ever decide to
support JNI.)  It should not be suprising, then, that the two are similar;
however, the critical difference is precisely that MPCL defines how to
share classes.  And quite honestly, MPCL is not of general concern; Ryan's
'os' package is, because it is what everyone will be /using/.*

-_Quinn

* In fact, it ought to be possible to write code for its interface such
that it wrapped calls to a helper app which spawned a new JVM and did
whatever IPC was necessary to support the various calls available in the
interface.  If used with a JVM which supported multiple instances in a
single process, a daemon could be written to respond to Ryan's OS code and
spawn new processes with that JVM, instead.






From ryan@whitewolf.com.au Tue, 16 May 2000 11:56:25 +1000
Date: Tue, 16 May 2000 11:56:25 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

"Todd L. Miller" wrote:

>         /as do we/.  I do not know how IBM implemented multiple multiple
> Java processes, or if it is possible to find out.  Perhaps, since they
> (AFAIK) neglected to provide a Java-side API for processes, they are
> runnig disjoint JVMs in a single process; your description leads to me to
> believe that they have discovered or implemented an efficient method for
> sharing class definitions accross those JVMs -- could you confirm this?
> If they have, it is to the loss of the Java community that they neglected
> to tell anyone else (AFAIK) how to do this.  If they did (or have released
> source to their JVM), I would be very interested in reading it.

I can't find _any_ JavaOS documentation on IBM's website any more, and
unfortunately I can't find the various documents I downloaded when they
were available. I am interested in the specific documentation you are
referring to as well (if it exists), but does anyone know where IBM's
JavaOS documentation is to be found?

> * In fact, it ought to be possible to write code for its interface such
> that it wrapped calls to a helper app which spawned a new JVM and did
> whatever IPC was necessary to support the various calls available in the
> interface.  If used with a JVM which supported multiple instances in a
> single process, a daemon could be written to respond to Ryan's OS code and
> spawn new processes with that JVM, instead.

Yes, this is possible. Whether or not JavaProcess is implemented as a
proxy object or a direct object is not specified. A proxy implementation
of JavaProcess would allow you to create new JVMs per process behind the
scenes.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From tmiller@haverford.edu Mon, 15 May 2000 21:25:14 -0400 (EDT)
Date: Mon, 15 May 2000 21:25:14 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> I can't find _any_ JavaOS documentation on IBM's website any more, and
> unfortunately I can't find the various documents I downloaded when they
> were available. I am interested in the specific documentation you are
> referring to as well (if it exists), but does anyone know where IBM's
> JavaOS documentation is to be found?

	Ah... I was under the quoted impressions from Gilbert's discussion
of IBM's JVM, not JavaOS.  And no, I don't know where their documentation
is to be found online, but I'll send it to you and/or make what I have
available from somewhere.

-_Quinn





From ryan@whitewolf.com.au Tue, 16 May 2000 12:23:33 +1000
Date: Tue, 16 May 2000 12:23:33 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

"Todd L. Miller" wrote:

>         Ah... I was under the quoted impressions from Gilbert's discussion
> of IBM's JVM, not JavaOS.

oops.. I was a bit out of context. I guess it is possible that they used
the same approach for JavaOS, too.

> And no, I don't know where their documentation
> is to be found online, but I'll send it to you and/or make what I have
> available from somewhere.

That would be great. Thanks!

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From tmiller@haverford.edu Tue, 16 May 2000 01:31:40 -0400 (EDT)
Date: Tue, 16 May 2000 01:31:40 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> That would be great. Thanks!

	Try http://students.haverford.edu/tmiller/JavaOS.tar.gz; it has
all the .pdf files (should be all files, but it's been a while) I have
(had) about JavaOS.  Hope it helps.

-_Quinn







From gchii@mindspring.com Tue, 16 May 2000 11:26:07 -0400
Date: Tue, 16 May 2000 11:26:07 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

>> JDK 1.1 does not support creating more than one VM in a single process.

JDK 1.1.x is not equal to Java 1 Platform. JDK 1.1 is a specific product
from Sun Microsystems. Sun Microsystems clearly explained that they -- and
they alone -- chose not to support multiple virtual machines. Other vendors
can and should. If other vendors support multiple virtual machines, they
should comply with the JNI specification. The JNI specification include
support for Java 1 to run more than one virtual machine inside a single
process.





From gchii@mindspring.com Tue, 16 May 2000 12:17:55 -0400
Date: Tue, 16 May 2000 12:17:55 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

At 07:27 PM 5/15/00 -0400, "Todd L. Miller" <tmiller@haverford.edu> wrote:
>In the context of the 1.1 spec, I understand this to mean that a single
>/calling/ process may not have more than one VM -- not placing any limits on
>the VM itself.

In Chapter 13 of "Essential JNI: Java Native Interface" by Rob Gordon,
Prentice Hall PTR, the author demonstrates the use of multiple virtual
machines inside a single machine code process. Each virtual machine is
attached to a different machine code thread.

>I do not know how IBM implemented multiple multiple Java processes, or if it
>is possible to find out. Perhaps, since they (AFAIK) neglected to provide a
>Java-side API for processes, they are runnig disjoint JVMs in a single
>process; your description leads to me to believe that they have discovered or
>implemented an efficient method for sharing class definitions accross those
>JVMs -- could you confirm this? If they have, it is to the loss of the Java
>community that they neglected to tell anyone else (AFAIK) how to do this. If
>they did (or have released source to their JVM), I would be very interested
>in reading it.

The product I'm using is IBM's Java Development Kit 1.1.6 for OS/400. IBM
and others have published many articles to the AS/400 community. IBM has
published many implementation details on their as400.ibm.com website.

Since OS/400 is already running a virtual machine interface similar to a
Java virtual machine, their product translates from one virtual machine
language to another. Most of the Java support is found in the equivalent of
a pre-compiled dynamically shared library.

Java is a natural on OS/400. The virtual machine interface had already been
done. Long before Java, the entire OS/400 has a single garbage collector.
When OS/400 creates an object reference, it is a system-wide object
reference. Objects are stored on the equivalent of a swap partition. It
already does short- and long-term persistence. Everything is tied directly
into a system-wide virtual memory manager.

>MPCL is a specification for the implementation of more than one Java process
>in an efficient manner.

MPCL is a proposed for further modifying the Java Virtual Machine
Specification to enable multiple independent bytecode processes. MPCL is
more of a theory than a specification.

>Ryan's 'os' package is the standard (albiet informal) interface to this
>ability.

Ryan's rheise.os product is one member's implementation. It demonstrates a
small fraction of what is understood about multiple bytecode processes so
far. It is far too premature to adopt rheise.os as a standard for the JOS
Project. It might lead us to a standard. It may be a useful model. It
cannot be taken literally.

Give me something I can use. I can't use rheise.os. Running a Java
application as a subprogram is not equivalent to running a Java application
as a process. If we think of ourselves as finished, we will miss the
greatest opportunity to find the best solution.

For example, a process has no concept of a parent. There is no parent
property inside a process. Only a subprogram has a parent. Only a
subprogram can share real objects with its parent.

And, a basic process has no concept of a user. There is no user property
inside a process. Only a multiple user operating system has a user.

And, a new process must be given its environment. Its entire environment
must be passed to the process manager. A genuine process manager must be
written in machine code, maybe with a bytecode proxy.

The rheise.os product demonstrates many different ideas at the same time.
It is not focused on the bare essentials of creating a bytecode process. We
need a focused, bare essential demonstration of a bytecode process.

We need to create a better test. The test of a genuine bytecode process is
not, as others have said, piping the output from one process to another.
The acid test is far more complicated than that. Piping from one Java
application to another doesn't prove much.

Don't be distracted by rheise.os. It is only a small step along a path that
will lead us to a genuine bytecode process.

-----

Examine the following code. What should happen?

// Demo.java
public class Demo1 {
  public static void main( String[] args ) {
    String cmd = "java Demo2";
    Runtime.getRuntime().exec( cmd );
    System.exit( 0 );
  }
}

If Demo2 defines a static main() method, it must continue running long
after Demo1 is gone. Demo2 is not accidentally destroyed when a Demo1
invokes System.exit(). The java.lang.Process object is always a proxy to
the real process that's running. It might contain a single
ProcessDescriptor field, enabling it to do things with the real process.

In bytecode, a process manager cannot maintain a reference to real
processes or the real process manager. Like a FileDescriptor, a process
manager might return a ProcessDescriptor. The ProcessDescriptor is passed
back to a process manager to invoke methods of a process.

public ProcessDescriptor {
  public ProcessDescriptor( int v ) {
    pid = v;
  }
  :
  int pid;
}





From tmiller@haverford.edu Tue, 16 May 2000 13:03:07 -0400 (EDT)
Date: Tue, 16 May 2000 13:03:07 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> We need to create a better test. The test of a genuine bytecode process is
> not, as others have said, piping the output from one process to another.
> The acid test is far more complicated than that. Piping from one Java
> application to another doesn't prove much.

	No?  Arbitrary piping from non-JOS-specific (legacy) application A
to B can not be done without processes.  System is a static, constant
across every thread in the JVM.  It is impossible for the same static
variables to have different values in different threads (e.g. invocation
of main) at the same time without classloader tricks which amount to an
implementation of bytecode processes.  I can not see how piping is not a
necessary condition, though there may be something I'm missing which
prevents it from being sufficient to prove bytecode processes.

	As for multiple processes in Java being a theory -- every
specification is a theory, usually unproved, which asserts that the Right
Thing (usually undefined) will happen if you maintain certain properties
on (usually loosely defined) certain things.  The MultipleJavaProcesses
wiki page fits this definition quite well: 'If you maintain disjoint
classloaders, with the exception that you may share class definitions so
long as that sharing ..., with the exception that you may share objects as
long as that sharing ..., then you will have multiple java
processes.  (Which have properties ....)'  You could also think of it as
an RFC, I suppose.

	I believe Ryan and I have already discussed making a Process
object wrap a pid as a way around requiring object IPC, though I do not
recall our conclusion.

-_Quinn





From ryan@whitewolf.com.au Wed, 17 May 2000 14:23:22 +1000
Date: Wed, 17 May 2000 14:23:22 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

Gilbert Carl Herschberger II wrote:

> >Ryan's 'os' package is the standard (albiet informal) interface to this
> >ability.
> 
> Ryan's rheise.os product is one member's implementation. It demonstrates a
> small fraction of what is understood about multiple bytecode processes so
> far. It is far too premature to adopt rheise.os as a standard for the JOS
> Project. It might lead us to a standard. It may be a useful model. It
> cannot be taken literally.

I agree with Gilbert that it is not yet a standard. It is more a
proposal and an implementation of that proposal.

> Give me something I can use. I can't use rheise.os. Running a Java
> application as a subprogram is not equivalent to running a Java application
> as a process.

Sorry, but I will not give you something you can use for running your
subprograms. You can do that. rheise.os was not designed to provide that
functionality because subprograms are outside the process framework.

You could be a little less demanding and a little more supportive if you
ask me...

> If we think of ourselves as finished, we will miss the
> greatest opportunity to find the best solution.
> 
> For example, a process has no concept of a parent. There is no parent
> property inside a process. Only a subprogram has a parent. Only a
> subprogram can share real objects with its parent.

- POSIX compliant operating systems have the concept of parent processes
(however, this does not imply anything about object sharing).

- In the process model _Quinn and I have been proposing, any two
processes can share objects independently of parent-child relationships
(ie. a superset)

Given the above object sharing model as a primitive, subprograms can
only be appropriate if it makes sense to run a program in the same
namespace as the parent. Sharing the parent namespace can be desirable
in some instances. However, subprograms are only one way to achieve
this. There are two ways that I know of:

1. subprograms, which are procedural based, and
2. subobjects, which are object-oriented based

Which one a programmer prefers is a matter of taste. For example, I
would always* choose (2) over (1), but others may choose the exact
opposite. Therefore, I do not consider either way a primitive in
rheise.os. Objects themselves are a primitive because this is an
object-oriented operating system, but I do not assume which way a
programmer wishes to run sub-code in-process. That is an application
design issue, and we application writers all come from different design
backgrounds.

(*) I like the object-oriented paradigm.

> And, a basic process has no concept of a user. There is no user property
> inside a process. Only a multiple user operating system has a user.

I have assumed that this is the general direction of operating systems*,
so I built users into the rheise.os model. In fact, the user model was
the prime motivation for starting rheise.os. It turned out later that my
work would be a useful starting point for multiple processes, enabling
higher level JOS developers to contribute something to the project.

(*) In fact the Java specification already relates users to processes
(assuming a JVM instance is a process). A Java process may obtain its
user by reading the user.name system property. This is obviously very
basic at the moment, but their future plans are available at
http://java.sun.com/products/jdk/1.2/docs/guide/security/spec/security-spec.doc8.html#21605

> The rheise.os product demonstrates many different ideas at the same time.
> It is not focused on the bare essentials of creating a bytecode process. We
> need a focused, bare essential demonstration of a bytecode process.

I find I can make better design decisions when I consider how one system
interacts with another, especially when they are interrelated. Consider
the current package structure (with the exclusion of jos.system):

jos
 + process
 + user
 + security

And consider some of the dependencies I have modeled:

- process  -> user
- security -> user
- process  -> security 

(where -> means "depends on")

What I am trying to work out now is the best API for these packages. I
am still not happy with the current API and I am constantly changing it.
If you don't consider how these three systems interact, you will never
arrive at the best solution.

Right now, the process package works well. It is now a matter of API
refinement. The fundamental functionality is in place. I just need to
work out where methods should go and what they should be named.

True, some methods are unimplemented or commented out (or un-thought of)
but they don't seem to be fundamental. This means I can turn my
attention to them later, AFTER I give the user and security packages
their fair share of attention. If you think the process package alone
needs more focus, that will require additional man power since I would
like to make progress in all three packages simultaneously. Rather than
criticising rheise.os for lack of effort in one particular area, why not
help increase the man power and give the process package the amount of
focus you think it needs?

> We need to create a better test. The test of a genuine bytecode process is
> not, as others have said, piping the output from one process to another.
> The acid test is far more complicated than that. Piping from one Java
> application to another doesn't prove much.

I have been working on test cases for rheise.os which demonstrate all
the functionality it provides. They are intended to demonstrate that
processes behave correctly, among other things. The test cases are
incomplete, though. Maybe you could specify the perfect test cases I
should implement? The pipe test alone is a pretty good test because it
demonstrates separate namespaces, the main distinction between plain
threads and processes. But I have other test cases to demonstrate
System.exit() and process.waitFor(). I would welcome your contributions
here (and anywhere else).

> Don't be distracted by rheise.os. It is only a small step along a path that
> will lead us to a genuine bytecode process.

Ok everyone, sorry for distracting you. It was a good try though, don't
you think? You see, rheise.os is not what I pretended it to be. I tried
to make it "appear" as though rheise.os was cleanly designed, and you
fell for it! Now, as Gilbert said, it's time to move on, because
rheise.os (the joke that it is) will never make it as a genuine bytecode
process model. How can it... possibly? I mean, come on! What, with all
the problems Gilbert pointed out which couldn't possibly be fixed, even
if Gilbert himself helped.

If I were actually serious about rheise.os I'd probably be really
discouraged, but that not being the case, I have to laugh at you. Hah!
(suckers :-)

</sarcasm>

PS. is rheise.os really a dead-end project?

> Examine the following code. What should happen?
> 
> // Demo.java
> public class Demo1 {
>   public static void main( String[] args ) {
>     String cmd = "java Demo2";
>     Runtime.getRuntime().exec( cmd );
>     System.exit( 0 );
>   }
> }
> 
> If Demo2 defines a static main() method, it must continue running long
> after Demo1 is gone. Demo2 is not accidentally destroyed when a Demo1
> invokes System.exit().

I agree. This is in fact how rheise.os behaves.

> The java.lang.Process object is always a proxy to
> the real process that's running.

Incorrect. rheise.os proves that a proxy is not necessary.
java.lang.Process does not reflect the need for a proxy, nor does
jos.process.JavaProcess which is a direct subclass.

Of course, in the bridge between the Java layer and the native JVM,
there will need to be some natively usable representation of a
JavaProcess. It doesn't matter to me what that representation is.
Regardless of how the JVM represents it internally, it is quite possible
to represent each process in the Java layer by unique instances of the
JavaProcess class. There is no need to create a proxy of a process in
each process that wishes to reference it, except in the intermediate
stages of getting JOS working before shared object IPC exists.

Evidence suggests that the more common way to do this in Java is through
references to unique instances, not proxies. For example, references to
instances of all of these classes refer to unique instances:

        java.lang.Thread
        java.lang.Class
        java.lang.ClassLoader
        java.lang.Object

Granted, Process is different because we are talking about referencing
it from different processes which are typically meant to be in separate
memory spaces, but with shared object IPC, we are not forced to use
proxies. We can do it either way. I like the direct approach, because
that is the goal of shared object IPC: to allow one process to interact
directly with another process - in the most direct way possible. For
example:

Process otherProcess = getSomeOtherProcess();
otherProcess.destroy(); // may throw SecurityException

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Wed, 17 May 2000 14:27:31 +1000
Date: Wed, 17 May 2000 14:27:31 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

"Todd L. Miller" wrote:
> 
> > That would be great. Thanks!
> 
>         Try http://students.haverford.edu/tmiller/JavaOS.tar.gz; it has
> all the .pdf files (should be all files, but it's been a while) I have
> (had) about JavaOS.  Hope it helps.

Thanks. It looks complete. If not, it's enough to keep me going for a
while :-)

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Wed, 17 May 2000 14:32:30 +1000
Date: Wed, 17 May 2000 14:32:30 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

"Todd L. Miller" wrote:

>         I believe Ryan and I have already discussed making a Process
> object wrap a pid as a way around requiring object IPC, though I do not
> recall our conclusion.

I agree the approach is reasonable (/natural in the absense of object
IPC)

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From gchii@mindspring.com Wed, 17 May 2000 14:11:47 -0400
Date: Wed, 17 May 2000 14:11:47 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

Let's get back to the discussion. The reloading of classes cannot be
ignored. Each process has its own potentially unique CLASSPATH. So, each
process must load its own classes.

All classes must be unique to a bytecode process. None can be shared
without a proxy. Each class in process A must be different than each class
in process B. When the process is garbage collected, all of its classes are
garbage collected.

In a classic design, all classes in a virtual machine are discarded when a
virtual machine dies. In a JNI design, all classes in a virtual machine are
discarded when a virtual machine dies. Sometimes, these classes are not
even finalized.

When a Java application runs inside a MPCL-compatible virtual machine, all
of its classes must be discarded when a process dies. All classes created
by a process are owned by a process. Everything owned by a process is
discarded when the process dies.

A process can share objects with any other process, not just the process
that created it. For more information, see also ParentProcess article on
JOS Wiki.

-----

Here again are processes A and B. Because each process might have its own
CLASSPATH, the superclass of a class can change from one process to another.

In one process, I can have this:

public abstract class AbstractWidget {
}

public class CustomWidget
    extends AbstractWidget {
}

while in another, I can have this:

public abstract class AbstractWidget {
}

public class BasicWidget 
    extends AbstractWidget {
}

public class CustomWidget
    extends BasicWidget {
}

Both are valid and appropriate within their own process. The CLASSPATH of
process A can be different than the CLASSPATH of process B.

-----

A versionless virtual machine is able to adapt at runtime to different
versions of the Java standard class libraries. The class library is plugged
into a versionless virtual machine through CLASSPATH. Within a single
virtual machine, each process is built upon a different platform. One
process can run Java 2 platform while another runs Java 1.





From gchii@mindspring.com Wed, 17 May 2000 14:32:48 -0400
Date: Wed, 17 May 2000 14:32:48 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [bytecode resource] About fields

It took almost no time at all to add the getInterfaceCount() and
getInterfaceSpec() to my implementation of rc_Bytecode. So, I went on to
work on fields.

It took longer than it should to finish the fields; but, it is finished. I
mistakenly did not initialize a unsigned long (in C++) for attribute count,
so an attribute had a length of over 10,000,000 octets. And, I compared an
index to itself (index >= index) rather than with the number of attributes
(index >= iMax).

I reorganized each Java package as a static C++ library. To see a preview
of the output from classdata.exe, here is the link:

<URL:http://www.mindspring.com/~gchii/jos/rc_preview-1.txt>





From tmiller@haverford.edu Wed, 17 May 2000 14:54:42 -0400 (EDT)
Date: Wed, 17 May 2000 14:54:42 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> Let's get back to the discussion. The reloading of classes cannot be
> ignored. Each process has its own potentially unique CLASSPATH. So, each
> process must load its own classes.

	While it's true the each process must load its own classes, it is
not because of a potentially unique CLASSPATH; it is because we cannot
share statics across processes.  CLASSPATH is not particularly relevant to
the JVM specification -- it is an implementation-dependent mechanism for
specifying the location of bytecode payloads.  Only in that those payloads
may differ must we keep them, as class definitions*, separate.

*: class definition is any way in which you may specify a class completely
enough for a JVM to execute it.

> All classes must be unique to a bytecode process. None can be shared
> without a proxy.

	No classes need ever be shared to achieve object sharing.  If the
class definitions matches, the oject may be shared.  I have suggested that
the best way to handle the inevitable conflicts between statics in the
classes of shared objects is for the shared object to simply use the
statics from whichever process/PCL it's currently running in.  I think
this also holds to the principle of least suprise -- some other method
may not know the object it's operating on is shared.  (That is, the static
it gets should be the same as the static the shared object does.)

> Everything owned by a process is discarded when the process dies.

	This may be the useful definition of ownership I've been looking
for -- the set of things which are garbage collected when a process
terminates.  I will think about this.  (Apologies to Ryan if he said this
before and I missed it.)

-_Quinn





From gchii@mindspring.com Wed, 17 May 2000 15:28:02 -0400
Date: Wed, 17 May 2000 15:28:02 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

At 02:54 PM 5/17/00 -0400, "Todd L. Miller" <tmiller@haverford.edu> wrote:
>	While it's true the each process must load its own classes, it is
>not because of a potentially unique CLASSPATH; it is because we cannot
>share statics across processes. CLASSPATH is not particularly relevant to
>the JVM specification -- it is an implementation-dependent mechanism for
>specifying the location of bytecode payloads.  Only in that those payloads
>may differ must we keep them, as class definitions*, separate.

Each process must load its own classes for two reasons: (a) static fields
and (b) multiple primordial class loaders. Each process owns a primordial
class loader. The primordial class loader is garbage collected (or
discarded) when a process dies. Each primordial class loader has some
equivalent of CLASSPATH. Each CLASSPATH is potentially different.

Here is one more test case:

public void example() {
  Runtime.getRuntime().exec( "java0 org.jos.demo.Demo" );
  Runtime.getRuntime().exec( "java1 org.jos.demo.Demo" );
  Runtime.getRuntime().exec( "java2 org.jos.demo.Demo" );
}

On an MPCL-compatible virtual machine, imagine there is a "switch"
statement to select an appropriate Java standard class library for each
primoridal class loader:

  switch( platform ) {
    case 0 :
      return "java0.jar";

    case 1 :
      return "java1.jar";

    case 2 :
      return "java2.jar";

    default :
      return null;

  }

On a foreign operating system, imagine there are three shell scripts:

  java0 starts JDK 1.02 with CLASSPATH=/jdk1.02/classes
  java1 starts JDK 1.1.7 with CLASSPATH=/jdk1.1.7/lib.rt.jar
  java2 starts JDK 1.2.2 with CLASSPATH=/jdk1.2.2/lib/rt.jar

I can already run all three Java class libraries (virtual machines) at the
same time on a foreign operating system. I should be able to run all three
Java class libraries (processes) at the same time on an MPCL-compatible
virtual machine.

-----

It has been mentioned. I'll mention it again. It is possible for a virtual
machine to use Runtime.exec() to launch another virtual machine. It is
possible for a virtual machine to use JNI to launch another virtual
machine. A generic process API should work on all kinds of virtual
machines. It should work on a classic virtual machine. It should work on a
JNI-compatible virtual machine. It should work on decaf, too.

A process API is not limited to a bytecode process. When an application
asks for a process, a process should be created if it is possible. While a
bytecode process is preferred, a new machine code process might be the only
way a process can be created on a foreign virtual machine.

An MPCL-compatible virtual machine should implement an internal "java"
command. When the "java" command is passed to Runtime.exec(), the rest of
the command line should  be parsed as if they were parameters to the java
tool. All other commands may be invalid and return an appropriate error
message.





From gchii@mindspring.com Wed, 17 May 2000 16:20:38 -0400
Date: Wed, 17 May 2000 16:20:38 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [ERIC Project] Goals

The ERIC Project has many goals. One goal is to invoke a second copy of an
eric tool from within the eric tool. Something as simple as this requires
one to write a new virtual machine.

Another goal is to distribute an eric tool that is completely and utterly
self-contained. In other words, the "eric" tool would contain everything:

 - a static implementation of a virtual machine (like decaf!),
 - all of the core packages of the Java standard class library (as bytecode
resources), and
 - custom classes for a particular application.

Such a tool would also be open-ended for dynamic class loading through a
CLASSPATH, ARCHIVEPATH and PACKAGEPATH. When decaf is MPCL-compatible, the
eric tool would support multiple bytecode processes.





From gchii@mindspring.com Wed, 17 May 2000 16:32:56 -0400
Date: Wed, 17 May 2000 16:32:56 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [test case] JDSK

The Java Servlet Development Kit (JDSK) from Sun Microsystems contains a
HTTP service, doesn't it? It contains a servletrunner tool to start this
service. This might make a good test case for a bytecode process.

When a process is terminated, everything that it owns must be garbage
collected (or discarded) -- including its open server sockets.

The main thread of a servletrunner is an endless loop. It listens for a TCP
connection on a server socket. When it is launched as a separate process,
the kill command should be able to kill it -- even when it is performing
blocking I/O. The server socket must be automatically closed when the
process dies. And all open sockets owned by the process must be closed,
too. Immediately after that, the servletrunner can be started again on the
same server socket.

The following test code should run without error.

  public void example() {
    ProcessManager manager = ProcessManager.getManager();
    String cmd = "java servletrunner";
    ProcessDescriptor pid;

    for ( int i = 0; i < 100; i++ ) {
      pid = manager.createProcess( cmd );
      sleep( 10000 );
      manager.kill( pd );
    }
  }





From tmiller@haverford.edu Wed, 17 May 2000 16:39:41 -0400 (EDT)
Date: Wed, 17 May 2000 16:39:41 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [ERIC Project] Goals

>  - a static implementation of a virtual machine (like decaf!),
>  - all of the core packages of the Java standard class library (as bytecode
> resources), and
>  - custom classes for a particular application.

	Such a packaging would be just screaming for use in an active
network, and could be interesting to look into...

-_Quinn





From jewel@pixie.co.za Wed, 17 May 2000 22:08:12 -0200 (GMT+2)
Date: Wed, 17 May 2000 22:08:12 -0200 (GMT+2)
From: jewel@pixie.co.za jewel@pixie.co.za
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> Let's get back to the discussion. The reloading of classes cannot be
> ignored. Each process has its own potentially unique CLASSPATH. So, each
> process must load its own classes.

That seems to be such a waste. Consider the classic use of processes by a
UNIX shell. When the shell executes a 'ls' process and then a 'grep'
process and then a 'wc' process it actually has to start all these 3
processes.

Now in UNIX creating these processes has to be cheap (precisely because of
this), and the executable code for these processes can be shared by many
instances.

The JVM model is different. Before the JVM can execute a "Process", which
for me means the "main" method in some class, it has to load that class.
Loading that class means resolving the constant pool and loading all the
classes that it depends on. These are typically classes like
java.lang.System, java.lang.Thread, java.lang.String,
java.lang.StringBuffer and so on.

This whole loading process is not trivial. Some classes might call native
methods while they are initializing (like setting up the file descriptors
for System.in, System.out etc).

This all takes time, much more time than executing a UNIX process like
"ls".

So if the intention is to model a JOS Process on a UNIX process, we have
to think very carefully about what class definitions we are going to share
across processes.

I think it would be extremely wasteful if each process had to load all
it's own classes from the class library independently of the other
processes.

This makes it difficult to support different class libraries in the
same OS but otherwise has great advantages.

Processes then would also not be able to use a different version of a
class already used by another process.

The solution may be to use ClassLoaders to separate classes that
processes use (but not the class library classes).

John 

> All classes must be unique to a bytecode process. None can
be shared
> without a proxy. Each class in process A must be different than each class
> in process B. When the process is garbage collected, all of its classes are
> garbage collected.
> 
> In a classic design, all classes in a virtual machine are discarded when a
> virtual machine dies. In a JNI design, all classes in a virtual machine are
> discarded when a virtual machine dies. Sometimes, these classes are not
> even finalized.
> 
> When a Java application runs inside a MPCL-compatible virtual machine, all
> of its classes must be discarded when a process dies. All classes created
> by a process are owned by a process. Everything owned by a process is
> discarded when the process dies.
> 
> A process can share objects with any other process, not just the process
> that created it. For more information, see also ParentProcess article on
> JOS Wiki.
> 
> -----
> 
> Here again are processes A and B. Because each process might have its own
> CLASSPATH, the superclass of a class can change from one process to another.
> 
> In one process, I can have this:
> 
> public abstract class AbstractWidget {
> }
> 
> public class CustomWidget
>     extends AbstractWidget {
> }
> 
> while in another, I can have this:
> 
> public abstract class AbstractWidget {
> }
> 
> public class BasicWidget 
>     extends AbstractWidget {
> }
> 
> public class CustomWidget
>     extends BasicWidget {
> }
> 
> Both are valid and appropriate within their own process. The CLASSPATH of
> process A can be different than the CLASSPATH of process B.
> 
> -----
> 
> A versionless virtual machine is able to adapt at runtime to different
> versions of the Java standard class libraries. The class library is plugged
> into a versionless virtual machine through CLASSPATH. Within a single
> virtual machine, each process is built upon a different platform. One
> process can run Java 2 platform while another runs Java 1.
> 
> 
> _______________________________________________
> Arch maillist  -  Arch@jos.org
> http://jos.org/mailman/listinfo/arch
> 





From jewel@pixie.co.za Wed, 17 May 2000 22:15:03 -0200 (GMT+2)
Date: Wed, 17 May 2000 22:15:03 -0200 (GMT+2)
From: jewel@pixie.co.za jewel@pixie.co.za
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> discarded) when a process dies. Each primordial class loader has some
> equivalent of CLASSPATH. Each CLASSPATH is potentially different.
> 
> Here is one more test case:
> 
> public void example() {
>   Runtime.getRuntime().exec( "java0 org.jos.demo.Demo" );
>   Runtime.getRuntime().exec( "java1 org.jos.demo.Demo" );
>   Runtime.getRuntime().exec( "java2 org.jos.demo.Demo" );
> }
> 
> On an MPCL-compatible virtual machine, imagine there is a "switch"
> statement to select an appropriate Java standard class library for each
> primoridal class loader:
> 
>   switch( platform ) {
>     case 0 :
>       return "java0.jar";
> 
>     case 1 :
>       return "java1.jar";
> 
>     case 2 :
>       return "java2.jar";
> 
>     default :
>       return null;
> 
>   }


This looks easy from this point of view. But what about all the native
libraries that vary for each different class library?

I'ld much prefer a standardised class library for all processes running on
the machine. It makes the implementation much simpler.

John






From jewel@pixie.co.za Wed, 17 May 2000 22:24:23 -0200 (GMT+2)
Date: Wed, 17 May 2000 22:24:23 -0200 (GMT+2)
From: jewel@pixie.co.za jewel@pixie.co.za
Subject: [JOS-Arch] [test case] JDSK

> The Java Servlet Development Kit (JDSK) from Sun Microsystems contains a
> HTTP service, doesn't it? It contains a servletrunner tool to start this
> service. This might make a good test case for a bytecode process.
> 
> When a process is terminated, everything that it owns must be garbage
> collected (or discarded) -- including its open server sockets.

Hmm, as I remember one of the initial things about servlets that made them
"cool" was the fact that you didn't need to start a new process to handle
each request.

This was the classic bottleneck in CGI implementations, where the
process-creation time dominated the time taken to service a request.

In a classic UNIX environment you need the protection that a process
provides (because of user rights, ability to access all process memory
etc), but with Java this falls away. 

I don't think Java protects very well against a rogue servlet spawning
many threads and consuming lots of CPU time though.
 
John

> The main thread of a servletrunner is an endless loop. It listens for a TCP
> connection on a server socket. When it is launched as a separate process,
> the kill command should be able to kill it -- even when it is performing
> blocking I/O. The server socket must be automatically closed when the
> process dies. And all open sockets owned by the process must be closed,
> too. Immediately after that, the servletrunner can be started again on the
> same server socket.
> 
> The following test code should run without error.
> 
>   public void example() {
>     ProcessManager manager = ProcessManager.getManager();
>     String cmd = "java servletrunner";
>     ProcessDescriptor pid;
> 
>     for ( int i = 0; i < 100; i++ ) {
>       pid = manager.createProcess( cmd );
>       sleep( 10000 );
>       manager.kill( pd );
>     }
>   }
> 
> 
> _______________________________________________
> Arch maillist  -  Arch@jos.org
> http://jos.org/mailman/listinfo/arch
> 





From ryan@whitewolf.com.au Thu, 18 May 2000 11:09:56 +1000
Date: Thu, 18 May 2000 11:09:56 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

Gilbert Carl Herschberger II wrote:
> 
> Let's get back to the discussion. The reloading of classes cannot be
> ignored. Each process has its own potentially unique CLASSPATH. So, each
> process must load its own classes.

We haven't ignored it. It has already been discussed that each process
has its own CLASSPATH in the form of
System.getProperty("java.class.path").

Reference:

	http://jos.org/pipermail/arch/2000-April/000449.html

> All classes must be unique to a bytecode process. None can be shared
> without a proxy.

Simple composition. Not proxy.

> When a Java application runs inside a MPCL-compatible virtual machine, all
> of its classes must be discarded when a process dies.

There are two options:

1. We can discard the classes when a process dies.
2. We can just let them be discarded when there are no references to any
shared objects inside the process from outside the process (where I am
proposing that not only may there be shared objects within the
application, but the Process object itself is a shared object).

It is irrelevant for me to say which one I think is best here, just that
it is incorrect to say that the classes *must* be discarded when a
process dies. We have two options. One may be better than the other, but
we won't know unless we can consider them BOTH long enough to compare
them equally.

> A process can share objects with any other process, not just the process
> that created it. For more information, see also ParentProcess article on
> JOS Wiki.

You raise an interesting point about the effect that a hard parent link
has on garbage collection. I have not checked the POSIX standard, but
through experimentation on Linux, it appears that when the parent of a
process dies, the parent reference is automatically reassigned to the
init process (which is responsible for killing off child processes when
a runlevel exits).

> A versionless virtual machine is able to adapt at runtime to different
> versions of the Java standard class libraries. The class library is plugged
> into a versionless virtual machine through CLASSPATH. Within a single
> virtual machine, each process is built upon a different platform. One
> process can run Java 2 platform while another runs Java 1.

That would be nice, though maybe it requires that the JVM be carefully
written. It should be possible.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Thu, 18 May 2000 11:21:29 +1000
Date: Thu, 18 May 2000 11:21:29 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

Gilbert Carl Herschberger II wrote:

> An MPCL-compatible virtual machine should implement an internal "java"
> command. When the "java" command is passed to Runtime.exec(), the rest of
> the command line should  be parsed as if they were parameters to the java
> tool. All other commands may be invalid and return an appropriate error
> message.

This is what I do in rheise.os. No rheise.os implementation has yet been
written to bind Runtime.exec() to this functionality, but I have
provided ProcessManager.execExternal() for that purpose. As you
supposed, it supports the "java" command and nothing else.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Thu, 18 May 2000 11:44:43 +1000
Date: Thu, 18 May 2000 11:44:43 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

"Todd L. Miller" wrote:

> I have suggested that
> the best way to handle the inevitable conflicts between statics in the
> classes of shared objects is for the shared object to simply use the
> statics from whichever process/PCL it's currently running in.

There are two proposals for this. Mine is to have a static reference
resolved via the class loader of the caller. So, we have two "best" ways
to do it, and one is more best than the other :-) We can work out which
one later, though, since there seems to be a lot of threads going on at
the moment (hmm, threads... do we constitute a mailing list operating
system?)

> > Everything owned by a process is discarded when the process dies.
> 
>         This may be the useful definition of ownership I've been looking
> for -- the set of things which are garbage collected when a process
> terminates.  I will think about this.  (Apologies to Ryan if he said this
> before and I missed it.)

I know of at least two ways to look at process termination (see my
response to Gilbert's mail). So, depending on which way we look at that,
there are different ways to consider how/when a process and its classes
are discarded. I know there is plenty of discussion to be had over the
two ideas... (if we can sustain two conflicting ideas long enough to
find time to discuss them, I think we will have solved our thread
overload problem. Discarding ideas prematurely can be unfortunate, eg.
proxies, statics, process termination, parent processes, and of course,
rheise.os)

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Thu, 18 May 2000 12:40:58 +1000
Date: Thu, 18 May 2000 12:40:58 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

"jewel@pixie.co.za" wrote:

> I think it would be extremely wasteful if each process had to load all
> it's own classes from the class library independently of the other
> processes.

The goal in this proposal was to minimise waste and at the same time
comply with the spec. The need to resolve symbolic references is a
performance penalty but doing I/O to load class files is a much bigger
one (especially when reading from a jar archive). The second one can be
solved through class definition caching (and to some extent, file level
caching), but the first one remains because the spec requires it.
References:

	http://jos.org/pipermail/arch/2000-April/000449.html
	http://www.metamech.com/wiki/view/Main/?topic=MultipleJavaProcesses

In addition to computational efficiency, class definition sharing (which
is based on class definition caching) minimises memory waste.

Some more memory can be saved by doing more I/O (a tradeoff), as Gilbert
pointed out (references?)

> This makes it difficult to support different class libraries in the
> same OS but otherwise has great advantages.

I'd like to achieve both. True, it does mean not much can be done to
remove the cost of resolution per process, but IMHO conforming with the
spec is better (and the cost is not too great - it is at least much
faster than the class loading process of a typical JVM).

We can only wait and see if it actually works - I suspect the
performance will be significantly faster than a standard JVM.

(An additional note, interaction between 'ls', 'grep' and 'wc' does not
necessarily need to involve multiple processes. The equivalent of this
in an object oriented context might be the interaction of Java beans
which need not be in separate processes. In this case, the same class
loader is used and the resolution process is not an issue)

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From tmiller@haverford.edu Wed, 17 May 2000 22:03:13 -0400 (EDT)
Date: Wed, 17 May 2000 22:03:13 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> That seems to be such a waste. Consider the classic use of processes by a
> UNIX shell. When the shell executes a 'ls' process and then a 'grep'
> process and then a 'wc' process it actually has to start all these 3
> processes.

	We have two things to discuss here -- first, the issue of class
un/re-loading, second, the proper design for a JOS shell.  The classic
UNIX shell had no choice but to spawn a new process; it could not execute
an arbitrary command in any other way.  This reinforced and was reinforced
by the drive to make process creation extremely cheap on UNIX systems.  
(e.g. copy-on-write, etc)  A JOS shell -- and jsh/jshell/others take this
route -- could either (a) spawn a thread to call some code or (b) execute
the code internally, both of which avoid the costs associated with process
creation.  The only reason to use processes is if you don't trust the code
you're calling; this (ought?) may be true generally, but for many things
-- e.g. ls, cd, the other two-letter names -- a shell writer can provide
or borrow perfectly good implementations from elsewhere.  I'm not saying
the UNIX way is not the Right Way, but we do have more options available.


	The spec we've been working toward makes the implicit assumption
that every PCL starts empty.  For processes to work (well?), however, we
need certain classes that truly a system-global -- that the JVM or
java-based process code inserts into a process before it begins to
execute.  One idea I had quite a while ago, and haven't discussed much
because of its complexity, had to do with the normal (a
normal?  I guess microkernel-esque systems don't really do
this...) parent/child relation between processes.  In many cases, it would
extremely advantageous for the child to inherit many or all of its
parent's class definitions.  For instance -- a shell spawning 'ls'
(probably) already has 'ls' loaded somewhere, along with (almost) all of
the support classes.  Why not allow it the shell to specify that its child
will inherit all its class definitions?  Then the only costs left are the
relatively cheap static initialization and (hoopefully) cheap thread
creation.

-_Quinn





From tmiller@haverford.edu Wed, 17 May 2000 22:05:23 -0400 (EDT)
Date: Wed, 17 May 2000 22:05:23 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> This looks easy from this point of view. But what about all the native
> libraries that vary for each different class library?

	One reason that a mixed-platform JVM strikes me as an absolute
nightmare to code/maintain.  But I'm far enough away from a JVM that works
with a single native library (I know, I know...) that I won't waste time
worrying about this.

-_Quinn





From tmiller@haverford.edu Wed, 17 May 2000 22:07:41 -0400 (EDT)
Date: Wed, 17 May 2000 22:07:41 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> > I have suggested that
> > the best way to handle the inevitable conflicts between statics in the
> > classes of shared objects is for the shared object to simply use the
> > statics from whichever process/PCL it's currently running in.
> 
> There are two proposals for this. Mine is to have a static reference
> resolved via the class loader of the caller. So, we have two "best" ways
> to do it, and one is more best than the other :-)

	I think resolving the static reference via the caller amounts to
the same thing as what I suggested -- least suprise -- as the caller is
always the current process, yes?

-_Quinn





From ryan@whitewolf.com.au Thu, 18 May 2000 13:03:05 +1000
Date: Thu, 18 May 2000 13:03:05 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

"Todd L. Miller" wrote:
> 
> > > I have suggested that
> > > the best way to handle the inevitable conflicts between statics in the
> > > classes of shared objects is for the shared object to simply use the
> > > statics from whichever process/PCL it's currently running in.
> >
> > There are two proposals for this. Mine is to have a static reference
> > resolved via the class loader of the caller. So, we have two "best" ways
> > to do it, and one is more best than the other :-)
> 
>         I think resolving the static reference via the caller amounts to
> the same thing as what I suggested -- least suprise -- as the caller is
> always the current process, yes?

Not so. As pointed out in my original example, if you invoke a method on
an object that belongs to another process (ie.
object->class->classLoader->process is different), and that method
internally references a static, the caller is different from the
"current" process which we have defined as the owner of the executing
thread.

It is in this case that I think resolving via the class loader of the
caller makes more sense.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Thu, 18 May 2000 13:21:59 +1000
Date: Thu, 18 May 2000 13:21:59 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [test case] JDSK

Gilbert Carl Herschberger II wrote:

> The main thread of a servletrunner is an endless loop. It listens for a TCP
> connection on a server socket. When it is launched as a separate process,
> the kill command should be able to kill it -- even when it is performing
> blocking I/O. The server socket must be automatically closed when the
> process dies. And all open sockets owned by the process must be closed,
> too. Immediately after that, the servletrunner can be started again on the
> same server socket.

An interesting test case. You might need to write these down somewhere
so we can implement them when we have a TCP/IP stack working on top of
decaf.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Thu, 18 May 2000 14:04:32 +1000
Date: Thu, 18 May 2000 14:04:32 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

"Todd L. Miller" wrote:

> One idea I had quite a while ago, and haven't discussed much
> because of its complexity, had to do with the normal (a
> normal?  I guess microkernel-esque systems don't really do
> this...) parent/child relation between processes.  In many cases, it would
> extremely advantageous for the child to inherit many or all of its
> parent's class definitions.

There is actually a placeholder method in my code,
JavaProcess.reuseClassLoader(). That was based on your original idea of
sharing classes, not class definitions. Perhaps we need one for reusing
class definitions too.

I'm not clear on how to design this cleanly, so reuseClassLoader is
currently unimplemented (which is not a pain since it's not a
fundamental method. We can do without it for at least the next 6
months).


-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Thu, 18 May 2000 18:10:51 +1000
Date: Thu, 18 May 2000 18:10:51 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [test case] JDSK

"jewel@pixie.co.za" wrote:

> Hmm, as I remember one of the initial things about servlets that made them
> "cool" was the fact that you didn't need to start a new process to handle
> each request.

I think he meant just to test the behaviour of the servletrunner
process, not the termination of individual servlets (correct me if I'm
wrong).

> In a classic UNIX environment you need the protection that a process
> provides (because of user rights, ability to access all process memory
> etc), but with Java this falls away.

Not entirely. A process is owned by a user and is granted the
permissions of that user (eg. permission to write to /home/john/*).
Since a servlet engine is a single process, it grants the same
permissions to every servlet running, and ideally you would like to
grant each servlet its own permission set (different users running
different servlets intending to be accessed on the same standard port).

This means it would be useful to invent something to contain a servlet.
It could be a threadless process (contradiction?), or it could be
something else. Perhaps these two things, whatever they are, inherit
from a base class this commonality:

- They are both owned by users.
- They are both restricted by a permission set.
- They can both potentially exist in separate namespaces. 

The third one is interesting because it allows you to run two different
versions of the same servlet in the same servlet engine. My ideas on
this are incomplete at the moment so if you have anything to add, you're
very welcome.

> I don't think Java protects very well against a rogue servlet spawning
> many threads and consuming lots of CPU time though.

Good point. It is the duty of an operating system to place restrictions
on resources like this. For example, max processes per user, max threads
per process, max memory usage per user/per process etc. I haven't worked
out where it fits in yet.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From gchii@mindspring.com Thu, 18 May 2000 12:30:28 -0400
Date: Thu, 18 May 2000 12:30:28 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [bytecode resource] Methods

The classdata tool, which uses bytecode as a resource, is now able to
decode methods. For a preview, here is the most recent output:

<URL:http://www.mindspring.com/~gchii/jos/rc_preview-2.txt>





From tmiller@haverford.edu Thu, 18 May 2000 14:22:02 -0400 (EDT)
Date: Thu, 18 May 2000 14:22:02 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> It is in this case that I think resolving via the class loader of the
> caller makes more sense.

	Ah.  I thought by 'caller' you meant the process/thread which
(called the method which) accessed the static, not the object (whose
method bytecode accessed the static).

	Looking at it from the least-suprise principle, which code do we
want to be the least suprised?  The (potentially legacy) code that doesn't
know it's using a shared object, or the shared object code itself?  I
would think the former; if the latter really needs a static from its
original/owning process, it can always copy it off.  Your thoughts run
counter to this -- why?  (Have we been over this already?)

-_Quinn








From tmiller@haverford.edu Thu, 18 May 2000 14:23:47 -0400 (EDT)
Date: Thu, 18 May 2000 14:23:47 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> There is actually a placeholder method in my code,
> JavaProcess.reuseClassLoader(). That was based on your original idea of
> sharing classes, not class definitions. Perhaps we need one for reusing
> class definitions too.

	I think we've shown that you can't legitimately share whole
classes between processes, but I'm not sure.  And designing it will be a
pain -- and I agree that we can sit on this for six months.

-_Quinn





From ryan@whitewolf.com.au Fri, 19 May 2000 12:18:39 +1000
Date: Fri, 19 May 2000 12:18:39 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

"Todd L. Miller" wrote:

>         Looking at it from the least-suprise principle, which code do we
> want to be the least suprised?  The (potentially legacy) code that doesn't
> know it's using a shared object, or the shared object code itself?  I
> would think the former; if the latter really needs a static from its
> original/owning process, it can always copy it off.  Your thoughts run
> counter to this -- why?

Because I would be least surprised the other way.

My claim is that when an object attempts to access its statics, it
expects to access the statics through object->class->statics.

Since an object only has one ->class, it also strikes me as the easiest
way to implement it. I think you agreed to that once:

	http://jos.org/pipermail/arch/2000-April/000500.html

In the general case, I am proposing:

"Static references are resolved via the class loader of the caller."

That actually sounds very close to something I read in the spec, so it
should create the least surprise. It seems to extend very well to the
shared object case, too.

If we exclude the possibility of shared objects, resolving statics via
the class loader of the caller makes complete sense in that it is how
the spec defines the expected behaviour. When we introduce shared
objects, the only difference is that an object may be seen through two
different classes with the same name (different classes but the same
class definition). Let's look at an example:

class SharedObject
	{
	static int stat;
	}

Process A creates one of these objects through its own class loader. It
now has the SharedObject class loaded, and an instance of that class.

Process B obtains a reference to this object by casting it to its own
version of the SharedObject class. The dynamic type of the object is
still the class loaded in Process A (this is determined by the hard link
object->class).

We both agree that if Process B accesses SharedObject.stat, it will
resolve to its own version of the SharedObject class and therefore
access the statics of its own process. And of course, if Process A
accesses SharedObject.stat, it will also resolve /its/ own version of
the SharedObject class and therefore its own statics. That is a given
because that is what the spec says.

But if the shared object itself tries to access its own statics, how do
you define "its own statics"? My guess is that an object will only
behave correctly if it is what it thinks it is. What an object is, is
made up of the instance, and the class that defined it. When a routine
in the object is purely non-static, it will always behave correctly. But
if the routine involves statics, the routine will have half worked and
half not, assuming that Process B is calling the routine on the shared
object of Process A. It will *think* it has updated the necessary
statics and put itself into a consistent state, but when things return
to normal and process A tries to do stuff with the object, it will find
that it is not in a consistent state (process B has interfered). Process
A will find that the object has changed state without the statics also
changing state, while the programmer could have sworn that it was
programmed to always keep the static and instance variables consistent
with eachother.

In short, an object would be very surprised indeed if when trying to
access its own statics, it actually accessed the statics of a completely
different class to which it has no association.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Fri, 19 May 2000 12:21:58 +1000
Date: Fri, 19 May 2000 12:21:58 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

"Todd L. Miller" wrote:
> 
> > There is actually a placeholder method in my code,
> > JavaProcess.reuseClassLoader(). That was based on your original idea of
> > sharing classes, not class definitions. Perhaps we need one for reusing
> > class definitions too.
> 
>         I think we've shown that you can't legitimately share whole
> classes between processes, but I'm not sure.  And designing it will be a
> pain -- and I agree that we can sit on this for six months.

For now, I'll change the method name to reuseClassDefinitions() so
people don't get the wrong idea. And I'll leave it unimplemented.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From jewel@pixie.co.za Fri, 19 May 2000 02:59:43 -0200 (GMT+2)
Date: Fri, 19 May 2000 02:59:43 -0200 (GMT+2)
From: John Leuner jewel@pixie.co.za
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> "jewel@pixie.co.za" wrote:
> 
> > I think it would be extremely wasteful if each process had to load all
> > it's own classes from the class library independently of the other
> > processes.
> 
> The goal in this proposal was to minimise waste and at the same time
> comply with the spec. The need to resolve symbolic references is a
> performance penalty but doing I/O to load class files is a much bigger
> one (especially when reading from a jar archive). The second one can be
> solved through class definition caching (and to some extent, file level
> caching), but the first one remains because the spec requires it.
> References:
> 
> 	http://jos.org/pipermail/arch/2000-April/000449.html
> 	http://www.metamech.com/wiki/view/Main/?topic=MultipleJavaProcesses

Yes, if you accept that the JVM has to have class loaders (or disjunct
namespaces) and implement multiple processes by use of these class
loaders, then you can't have all processes using the same internal
structures.

But it would beneficial to reuse as many of the classes as possible. For
example, if all the java.lang, java.io etc classes were always loaded by a
specific class loader, we could gain the time otherwise required to load
each system class.

> In addition to computational efficiency, class definition sharing (which
> is based on class definition caching) minimises memory waste.

Yes class definition caching will certainly help, although I don't see how
it has much advantage over a conventional file cache.

What is definition sharing?
 
> > This makes it difficult to support different class libraries in the
> > same OS but otherwise has great advantages.
> 
> I'd like to achieve both. True, it does mean not much can be done to
> remove the cost of resolution per process, but IMHO conforming with the
> spec is better (and the cost is not too great - it is at least much
> faster than the class loading process of a typical JVM).

I can't see any way around the spec. Unless you're going to enforce a
single class for every name in the namespace (ie one classloader, one
version of every class) you have to make provisions for different classes
sharing the same name. Whether this means total separation or partial
sharing is the tricky bit.

 > We can only wait and see if it actually works - I suspect
 > the performance will be significantly faster than a standard JVM.

Not really. If the file system is already caching the .class files, how
will your method be much faster?

But you shouldn't be comparing to a normal JVM, you should be comparing
the native operating environment of other OS'es. Can we compete against
the processes in BeOS, UNIX and Win32?

Will our solution be able to cope when the user starts compiling the whole
class library and spawns hundreds of processes in quick succession?

> (An additional note, interaction between 'ls', 'grep' and 'wc' does not
> necessarily need to involve multiple processes. The equivalent of this
> in an object oriented context might be the interaction of Java beans
> which need not be in separate processes. In this case, the same class
> loader is used and the resolution process is not an issue)

Yes, but if our Processes are emulating what an application expects when
it runs on a normal JVM, then programmers are going to write to this
specification. They are going to expect pipes, their own copy of static
variables for all classes they are using and so on. 

Perhaps it isn't such a good thing to model the traditional UNIX process
so closely?

John 





From ryan@whitewolf.com.au Fri, 19 May 2000 18:08:37 +1000
Date: Fri, 19 May 2000 18:08:37 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

John Leuner wrote:

> But it would beneficial to reuse as many of the classes as possible. For
> example, if all the java.lang, java.io etc classes were always loaded by a
> specific class loader, we could gain the time otherwise required to load
> each system class.

The reuseClassDefinitions() method just discussed (in another email)
would help here somewhat.

The problem with actually reusing Classes (as opposed to class
definitions) is that a program notices the difference, in really
disturbing ways. For example, Process A calls System.setOut(logFile),
and Process B all of a sudden loses its output to some unknown place.

There are at least 114 non-final statics in the JDK 1.1 system classes.
Per package, they are distributed as follows:

[ note: there are certainly more to be found with a smarter algorithm ]

applet          0
awt             23
beans           5
io              6
lang            7
math            5
net             7
rmi             15
security        6
sql             4
text            16
util            20

You would need to check each one to make sure that one process cannot
interfere with another process through manipulation of these statics. It
is possible to work around some of them in this case, but not all of
them. For example, System.in/out/err can be protected by simply sharing
all system classes except for java.lang.System, causing each process to
have their own java.lang.System statics. However, I was lucky* to be
able to do that in this instance because java.lang.System is a purely
static class (there can be no references to instances of that class). If
instances can be passed around, you will not be able to cast the
instance of the per process class to the type that a primordially loaded
class would expect (it can only expect one type, not n different types
for however many processes there are). Did that make sense? I may have
left out a few crucial sentences that I thought rather than wrote...

I think there are many other optimisations we can try before you resort
to breaking the spec. I believe that the range of safe optimisations
discussed so far will actually be sufficient and there will be no need
to look for non-safe ones. I think it is best to wait and see at this
stage.

(*) I actually support a host implementation of rheise.os that works
pretty much as you desired, and it attempts to work around the static
problems on a case by case basis. Of course it is not (and cannot) be
perfect, but it works well enough to be used until the native
implementation is integrated with decaf. If you want to take a look at
it, goto http://www.progsoc.uts.edu.au/~rheise/projects/rheise.os/

> > In addition to computational efficiency, class definition sharing (which
> > is based on class definition caching) minimises memory waste.
> 
> Yes class definition caching will certainly help, although I don't see how
> it has much advantage over a conventional file cache.
> 
> What is definition sharing?

That was discussed in those two links I referred you to in the last
email. Class definition caching is the new term I just invented to avoid
conflict with alternative ideas that do not depend on caching in the
same way I do.

I depend on class definition caching to avoid doing I/O twice when
findSystemClass("java.awt.Button") is called twice. If the modification
date of the archive hasn't changed, I simply use the class definition in
the cache and skip the InputStream.read() and much of the
ClassLoader.defineClass() process. This is a performance optimisation.

Class definition sharing, on the other hand, is a memory optimisation,
and a crucial part of my proposal with respect to IPC:

	http://jos.org/pipermail/arch/2000-April/000449.html

Class definition sharing simply means that if java.awt.Button.class is
loaded twice into two separate processes, they both (ie. the
java.lang.Class objects) can point to the common class definition
structure rather than have their own copy of the data (_Quinn's
insight). So, there end up being two java.lang.Class objects with
references to the same class definition object.

The way I take advantage of this for IPC is, I allow an object to be
casted from one java.awt.Button to another java.awt.Button if those two
classes share the same class definition (and if the two classes were
loaded by primordial class loaders, which is implied in my specific
proposal). It is difficult to grasp the implications of this, but it is
explained in detail in the proposal above (some details are yet to be
added, _Quinn has written a more recent analysis of what are the
necessary "properties" of such a system and I haven't updated my
proposal to explain how they might fit in yet)

>  > We can only wait and see if it actually works - I suspect
>  > the performance will be significantly faster than a standard JVM.
> 
> Not really. If the file system is already caching the .class files, how
> will your method be much faster?

Yes, particularly with jar files (which is where most classes will be
loaded from). You are asking why we need a class definition cache in
addition to a file cache. Besides the fact that it is just as easy to
implement, a class definition cache saves us from:

- reading the class file from a stream. Even if the file is cached, we
must loop over all the bytes via a stream (with memory as its source
rather than disk).

- interpreting the jar file. Even if the jar file is cached, we must
find the class file within it.

- interpreting the class file. This means converting the class file
format into a class definition structure.

And now we have a class definition. Not only did it take longer to
produce, but now we can't share the class definition across different
classes to either save memory or do IPC, unless we do even more work to
compare the newly created class definition with ones we already have in
memory.

In summary, yes, file system caching does speed things up to some extent
(we definately want file system caching), but class definition caching
can easily make it much faster, as well as making shared object IPC a
breeze.

> But you shouldn't be comparing to a normal JVM, you should be comparing
> the native operating environment of other OS'es. Can we compete against
> the processes in BeOS, UNIX and Win32?

In that case, it is VERY important that we do class definition caching
in addition to file system caching :-) 

> Will our solution be able to cope when the user starts compiling the whole
> class library and spawns hundreds of processes in quick succession?

Spawning hundreds of processes in quick succession doesn't sound like
the right way to get a job done to me. In UNIX the program was the item
of reuse, so lots of programs would be spawned in quick succession to
get a job done. But in an object oriented operating system, objects are
the items of reuse, and they usually interact with eachother in the same
address space.

In this example, it doesn't sound like a good idea to spawn hundreds of
separate javac processes one after another. It turns out IDE designers
don't think so either (not just for exec latency though, mainly for
opportunities for optimisation w.r.t. inter-class dependencies). I would
prefer to think of the java compiler as a reusable library/package that
can be used in a number of different contexts, eg. an IDE (so it doesn't
have to spawn hundreds of separate processes), or your own personal
compilation macro or Makefile equivalent which can make use of the java
compiler without having to spawn processes.

All that theory aside, javac can still be executed as a process if you
wish, and you should get good performance with
JavaProcess.reuseClassDefinitions() or maybe even without. Let's wait
and see.

> > (An additional note, interaction between 'ls', 'grep' and 'wc' does not
> > necessarily need to involve multiple processes. The equivalent of this
> > in an object oriented context might be the interaction of Java beans
> > which need not be in separate processes. In this case, the same class
> > loader is used and the resolution process is not an issue)
> 
> Yes, but if our Processes are emulating what an application expects when
> it runs on a normal JVM, then programmers are going to write to this
> specification. They are going to expect pipes, their own copy of static
> variables for all classes they are using and so on.

What I meant was, the 'ls', 'grep' and 'wc' could be rewritten in an
object-oriented context so that they can interact as reusable objects in
the same address space. rheise.os still supports processes in all their
glory. If you wish to write 'ls' as a program that runs in its own
process, it will get its own version of System.in/out/err and it will be
able to do pipes. If you download rheise.os, there is an example that
shows one process piping its output into the input of another.

> Perhaps it isn't such a good thing to model the traditional UNIX process
> so closely?

There is certainly no need to use processes in the same way UNIX forced
programmers to, but we can nevertheless support the basic process model
since it is the foundation for many different uses. You can look at a
process as a perimeter around executing code that should not be able to
interfere with, or be interfered by, anything else. Objects that work
together to achieve a goal can go in the same process*.

(*) Usually. The exceptions should be obvious to the developer.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From donaldp@mad.scientist.com Fri, 19 May 2000 17:41:20 +1000
Date: Fri, 19 May 2000 17:41:20 +1000
From: Peter Donald donaldp@mad.scientist.com
Subject: [JOS-Arch] Re: Arch digest, Vol 1 #185 - 7 msgs

Hi,

Just joined the list if I say something stupid ignore me :P.

At 03:00  19/5/00 -0400, you wrote:
>Not entirely. A process is owned by a user and is granted the
>permissions of that user (eg. permission to write to /home/john/*).
>Since a servlet engine is a single process, it grants the same
>permissions to every servlet running, and ideally you would like to
>grant each servlet its own permission set (different users running
>different servlets intending to be accessed on the same standard port).

There is also an arguement for allowing a single user to have multiple
permission sets depending on a number of factors. For example, source of
code is an important factor in current browsers when they allocate
permissions. ie you can have un-trusted, semi-trusted, trusted applets
running around each with their own security sets. Security could also be
based on the signee of code or various other factors ...

It could be very useful on a OS level. Consider the latest email hijinx.
This could have been stoped if the attatchment had been forced to run in a
secure sandbox. Big corporations may even go to the extreme of only
allowing code that has been signed by them to run with any useful
permissions. 

>This means it would be useful to invent something to contain a servlet.
>It could be a threadless process (contradiction?), or it could be
>something else. 

How about something like unix su command that changes the permissions of
running process to appropriate individual. The permissions could then be
changed back after that particular servlet had serviced it's client.

>Subject: Re: [JOS-Arch] [vm efficiency] "Reloading" classes
>> > There is actually a placeholder method in my code,
>> > JavaProcess.reuseClassLoader(). That was based on your original idea of
>> > sharing classes, not class definitions. Perhaps we need one for reusing
>> > class definitions too.
>> 
>>         I think we've shown that you can't legitimately share whole
>> classes between processes, but I'm not sure.  And designing it will be a
>> pain -- and I agree that we can sit on this for six months.

This could cause problems in two cases that I can see. 

* Accessing statics as you said means that each process has to own it's own
copy of the static

* JIT either is forced to only optimise code that is inside class but can
never inline code from other classes. For instance if in class A you use
String objects. The method calls can never be inlined because another
process may load a different version of String.

Thus you only really end up sharing the raw bytecode and constant pool
which could and you have to make sure that when it is shared the source
.class files are identical.

Another thing in a single process is defined by it's classloader + class. I
once tried to write a builder program (think GUI builder but not) and had
to juggle classloaders to make sure that .class files could be loaded even
if there was a class with tthe same name.


Cheers,

Pete

*------------------------------------------------------*
| "Nearly all men can stand adversity, but if you want |
| to test a man's character, give him power."          |
|       -Abraham Lincoln                               |
*------------------------------------------------------*




From ryan@whitewolf.com.au Fri, 19 May 2000 21:28:08 +1000
Date: Fri, 19 May 2000 21:28:08 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Re: Arch digest, Vol 1 #185 - 7 msgs

Peter Donald wrote:
> 
> Hi,
> 
> Just joined the list if I say something stupid ignore me :P.

not stupid on all points!

> There is also an arguement for allowing a single user to have multiple
> permission sets depending on a number of factors. For example, source of
> code is an important factor

We think alike here. I have experimented with a number of security ideas
with rheise.os, most derived from research I did a year ago. I see two
ways of controlling running code:

1. Privileges based on what code is running. Permissions are associated
with code through a policy file.

2. Privileges based on what thread is running.

(1) is introduced by Sun in JDK 1.2. (2) is provided by rheise.os and
depends on (1). For a description of (2), you might want to check out:

	http://www.progsoc.uts.edu.au/~rheise/jos/jos-security.html

which is my original paper, way out of date now with respect to
rheise.os. The terminology is certainly different, so please make any
comments based on the rheise.os source code. UserDomain is now called
UserThreadGroup, per thread permission sets are now granted through
UserTokens which are associated with a user and a permission set.

Since that paper is out of date, I will try to explain the main concepts
as they exist today.

At the most basic level, a process and all threads within it are
associated with what I call a UserToken. That UserToken gives threads a
set of permissions based on the User for that UserToken. You can request
a UserToken from the system for a particular user and start executing
code on behalf of that user. There are two ways to ask for a UserToken:

UserToken SecuritySystem.assumeUser(User user)
UserToken SecuritySystem.assumeUser(User user, Credentials credentials)

In the first approach, no credentials are given, so the extent of what
you can do as that new user is limited to what the policy file says your
code is able to do as that user without knowing that user's password.

In the second approach, valid credentials mean that the resulting
UserToken will have the full privileges of that User. This is the method
you would use to implement the login program, for example.

When you create a new process, by default the UserToken for that process
is inherited from the parent process. When you create a new Thread
within a process, the UserToken is inherited from the parent
ThreadGroup. In fact, the implementaiton details are such that
UserTokens are only associated with ThreadGroups (only they have the
parent/child concept).

When all threads inherit the UserToken from the main thread group, what
you have is a standard process. When you create a subthread with a new
UserToken, you have a powerful way to implement servers such as mail
transfer agents, ftp servers, and anything else that needs to be able to
write to certain files owned by each user. Sendmail needs to be able to
write to /var/spool/mail/ryan, but it should not be able to write to
/home/ryan/.bashrc. On UNIX, Sendmail must be root so that it can do
everything, even though it should only be able to do a little bit as
each user. Not surprisingly there have been many security holes in
Sendmail over the years that allow people to gain unauthorised access to
the root account!

The goal of the UserToken is that a process can only gain the subset of
permissions of another user it needs to do its job.

(For an explanation of why threads running as different users in the
SAME process is safe, please read the out of date paper)

> >This means it would be useful to invent something to contain a servlet.
> >It could be a threadless process (contradiction?), or it could be
> >something else.
> 
> How about something like unix su command that changes the permissions of
> running process to appropriate individual. The permissions could then be
> changed back after that particular servlet had serviced it's client.

Ideally, different code or threads running as different users could
coexist without having to switch back and forth. With threads it's
actually necessary because two threads run at the same time - su will
require state information per thread. With "different code", su could
handle that so long as it switched back on exiting, but a more elegant
solution exists which is provided by sun (ProtectionDomains) so we don't
need to think about that aspect. The other issues to do with these
threadless processes(?) remain.

A point about su (well, setuid()), it useful in its own right, and there
is an equivalent of this in rheise.os called setUserToken().

> * JIT either is forced to only optimise code that is inside class but can
> never inline code from other classes. For instance if in class A you use
> String objects. The method calls can never be inlined because another
> process may load a different version of String.

This comment is relevant to the implications of sharing class
definitions between processes (correct?)

I think you have stumbled across something very important here. We made
a similar oversight with superclasses where if the superclass
definitions were different, interprocess object sharing would be
invalid. We discovered that when we share class definitions between
processes, we must also ensure that the corresponding super class
definitions are also shared with eachother (thanks Matt Albrecht!).

If we ensure a similar thing for all symbolic references, then we can
ensure that it is safe to inline code from other classes. HOWEVER,
ensuring this for all symbolic references is something I was hoping to
avoid because if just one class definition is different, a whole
interconnection of classes (probably the entire process) will not be
able to share their class definitions (all or nothing) meaning we lose
the advantage of saving memory. Instead I was hoping such
incompatibilities could be detected on the fly rather than ensuring they
are ok at link time.

So, we have two options:

1. Ensure all symblic references share class definitions, or no class
definitions may be shared. This /may/ be ok if it turns out that it is
only rarely the case that the interconnection of classes don't entirely
match another process. In this case, we can live with the small loss in
memory saving opportunity.

2. Check these referenced class definitions on the fly. If we want to
inline code, invent some way to maintain different inlined versions for
each process (more specifically, each (primordial) class loader).
Difficult... That is a generic statement of the problem so there will be
many ways to achieve the desired result. Some focused on performance,
and some focused on memory. In the end (if we pursue this direction) we
may fuse the best ideas developed on both sides.

Are there any other options? If we ignore inlining in the short term,
either way is just as easy to implement, and just as effective. This
means we have plenty of time to work out how to do (2) with inlining. If
we haven't worked anything out by then, (1) will always work.

(_Quinn, how do things look from down in the JVM trenches? You'd
probably have the best idea of how this inlining problem can be solved)

> Thus you only really end up sharing the raw bytecode and constant pool

This is one solution for option (2) to support inlining. It's advantages
include that it has optimal runtime performance. It's disadvantages
include that it requires much more memory.

Thanks for pointing this out!

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Fri, 19 May 2000 22:22:57 +1000
Date: Fri, 19 May 2000 22:22:57 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Re: Arch digest, Vol 1 #185 - 7 msgs

I wrote:

> not stupid on all points!

And naturally I'm using Java operator precedence, here.

(not-stupid) on... 

-naturally. ;-)

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From gchii@mindspring.com Fri, 19 May 2000 08:51:12 -0400
Date: Fri, 19 May 2000 08:51:12 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [subprogram] Definition

Both a subprogram and process API are necessary. A subprogram should be
used when a subprogram is needed. A process should be used when a process
is needed. A subprogram is not a process.

We can further refine the definition of a subprogram. We can compare and
contrast a subprogram with a process. We can learn more about processes by
comparing it to what we can already do with subprograms.

We already have subprograms. Subprograms are easy to use. Subprograms load
more quickly than process because it automatically shares the bulk of the
Java standard class library. Subprograms come in many forms.

1. Within the same class loader. A subprogram can use all classes and
static fields loaded by its parent program. A subprogram can be called to
alter the system properties of the parent program (like cd, su). A
subprogram can be called to write to standard out and err streams. A
subprogram can be called to read from standard in. Or both. Such a
subprogram's classes are loaded once and cannot be unloaded. Typically, the
Program Browser loads and runs any arbitrary subprogram without a custom
class loader.

2. With a custom class loader. A custom class loader provides a way to
garbage collect its classes when a subprogram dies. A subprogram's classes
can be loaded, unloaded and reloaded with a custom class loader. This is
how a browser typically loads applets. This is how a servlet runner
typically loads servlets. An advanced custom class loader can provide a
substitute for java.lang.System to run a standard Java application as a
subprogram.

Any subprogram can run inside the same thread; the parent program has to
wait. Any subprogram can be run inside a separate thread; the parent
program does not have to wait.

Any subprogram can be run inside a separate process. A separate process
gets a whole new instance of the Java standard class library. A new process
has a new primordial class loader. With a new primordial class loader, a
new process gets all new static fields. Static fields are not maintained on
a class by class basis.

A new process can reused the class definitions of another process -- if the
details are worked out to maintain the illusion of a separate virtual
machine. An old process has probably already loaded the Java standard class
library from rt.jar. An old process has probably already converted each
class file into a platform-dependent class definition. An old process has
probably already verified the bytecode and/or compiled some of it into
machine code.

While the order of archives on "CLASSPATH" must be perfectly preserved,
some optimization is possible. These optimizations may increase the
performance (size and speed) of a virtual machine. Assuming a mechanism to
remember where each class file came from, class files can be cached.
Assuming a file subsystem, archive files can be cached. If some mechanism
can guarantee that a class file or archive has not changed, additional I/O
may not be required. Each class file already loaded from an archive, a
class file can be reused. If the raw class file has already been converted
to a class definition, a class definition can be reused. If it has already
be compiled into machine code, the compiled code can be reused.

-----

Many kinds of subprograms are already possible.

A. Applet - By extending java.lang.Applet, your custom class can run as a
subprogram in an applet environment, like Applet Browser.

B. Servlet - By extending javax.servlet.Servlet, your custom class can run
as a subprogram in a servlet environment.

C. Runnable - By implementing java.lang.Runnable, java.lang.Thread,
jose.Application and/or program.Program, your custom class can run as a
subprogram in Program Browser.

D. Component - By extending java.awt.Component, your custom class can run
as a subprogram in Program Browser. Any component is automatically wrapped
in a frame. All visual beans are components, too. If a component is a
dialog box or frame or applet, it is used directly.

E. URL - Any stringified URL can be converted to a java.net.URL and run as
a subprogram in Universal Browser. This includes a JDBC URL for an SQL
connection, along with the classic World Wide Web schemes.

-----

If you want to write a custom program for the JOS Project, you should write
it as a subprogram, not a Java application. A Java application is only for
backward compatibility. Compatibility with the Java application model is
only for programs that others have already written and continue to write.
Many applications, like javac, can be run successfully as a subprogram. No
bytecode process is needed.





From gchii@mindspring.com Fri, 19 May 2000 09:16:16 -0400
Date: Fri, 19 May 2000 09:16:16 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

At 06:08 PM 5/19/00 +1000, Ryan Heise <ryan@whitewolf.com.au> wrote:
>Spawning hundreds of processes in quick succession doesn't sound like
>the right way to get a job done to me.

When you don't understand why someone needs to spawn hundreds of processes,
you should ask questions. They are likely to either (1) have a very good
reason, or (2) not know of any other way.

An operating system needs to help all kinds of people get their work done.
Each person is unique and has custom requirements. The right way for some
might be to spawn hundreds of processes. The right way for others might be
to run one process at a time. An operating system should be able to do
either one efficiently and effectively. The choice up to other people.

At start-up, an operating system might spawn quite a few processes. Maybe
or maybe not "hundreds". System configuration determines how many and which
ones. A process might be used for some device drivers. A device driver can
be launched as a subprogram or process. A device driver that needs its own
process should run in its own process. If a file subsystem or JEPS or JADE
needs its own process, it should run in its own process.

A process might be used for each system service, like the classic system
services on Linux. FTP and HTTP might not run in the same process. Killing
FTP shouldn't kill HTTP. To upgrade a service, you should not be required
to restart a virtual machine.

Many processes on a laptop, desktop and server system sounds like the right
thing to do. It doesn't make sense to me to develop a multiple-process
operating system and then encourage people not to use its multiple-process
features.





From gchii@mindspring.com Fri, 19 May 2000 09:40:01 -0400
Date: Fri, 19 May 2000 09:40:01 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

At 02:59 AM 5/19/00 -0200, John Leuner <jewel@pixie.co.za> wrote:
>Will our solution be able to cope when the user starts compiling the whole
>class library and spawns hundreds of processes in quick succession?

Yes, it will. With a simple bytecode cache, it is possible to recompile the
Java standard class library and launch a new process without restarting a
virtual machine. All processes loaded after the library is installed will
use the new library. Older processes will continue to use the older library.

As a wild guess, a virtual machine with a 32MB swap partition and bytecode
cache should be able to support many more bytecode processes than the
equivalent JNI design. The JNI design already supports 10X more bytecode
processes than the classic design. The "space" required by read-only
bytecode does not consume any swap space.

Write a program/script that launches a simple Java application repeatedly.
How many can be loaded before your foreign operating system fails to create
a new process?

  public void example() {
    int iMax = 1000;
    for ( int i = 0; i < iMax; i++ ) {
      String cmd = "java org.jos.demo.Demo";
      Runtime.getRuntime().exec( cmd );
      Thread.sleep( 2000 );
    }
  }

You might be surprised how little overhead is required to run a classic
virtual machine, even without a system-wide bytecode/class definition
cache. Your operating system will runs out of swap space eventually. With
each virtual machine, part of the Java standard class library is reloaded.
Here is an example of this Demo application:

package org.jos.demo;
public class Demo {
  public static void main( String[] args ) {
    for (;;) {
    }
  }
}

Of course, your application is intended to do something. As it requires
more and more of the Java standard class library, more and more swap space
is required. As it loads more and more custom classes, more and more swap
space is required.





From tmiller@haverford.edu Fri, 19 May 2000 10:21:11 -0400 (EDT)
Date: Fri, 19 May 2000 10:21:11 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Re: Arch digest, Vol 1 #185 - 7 msgs

> (_Quinn, how do things look from down in the JVM trenches? You'd
> probably have the best idea of how this inlining problem can be solved.)

	Quite honestly, I haven't looked at optimizations at all.  This
particular problem, however strikes me in two ways -- first, how often
will we be trying to inline method calls across processes?  (That is, how
much of a worry is this going to be?  We may just be able to ignore it
without much of a penalty.)  Second, having symbolic references mismatch
across processes will not be a problem if a a shared object does lookups
in the executing process's classloader; the JVM will throw a LinkError
(IIRC) if/when the shared class tries to do something it can't because the
calling process is improperly set up.

	OTOH, you've made good points about where the statics for a shared
object's method ought to be.  One question I do have, though, looking at
this from a UNIXy point of view.  I share two things -- a memory location
(my static variable) and a function pointer (the method in question).  The
function referenced by the pointer reads and writes from that global
variable.  At no time should two simultaneous executions of the function
find different things in that global variable -- it being shared, they're
reading/writing to the same place.  (With the obvious caveats about
synchronity.)  At no time should the two different processes be able to
execute a read on that memory location and get a different value.  (Again,
with the obvious caveats about synchronity.)  This would suggest to me
that we need, in fact, to share the statics of a class (only) when an
object of that type is shared.  If this proves to be unworkable, we may be
forced to restrict shared objects to those whose classes (and parents) do
not have statics.

-_Quinn






From ryan@whitewolf.com.au Sat, 20 May 2000 00:23:43 +1000
Date: Sat, 20 May 2000 00:23:43 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [subprogram] Definition

Gilbert Carl Herschberger II wrote:

> Both a subprogram and process API are necessary.

A process API is necessary, yes.
Your subprogram API is useful, but not necessary*.

Don't get me wrong, I have nothing against people using your subprogram
API, but I hope you see why I decided not to implement it in rheise.os.
It is only designed to contain things which are necessary from an
operating system's point of view. On top of the operating system, there
may be other libraries like your subprogram API. Is your subprogram API
really an operating system facility? I didn't think so. It's a library
that certain application developers will choose to use.

(*) it cannot be argued that it is necessary because there are always
alternatives. And alternatives are good.

> Many kinds of subprograms are already possible.

The existing set of embedded program APIs will do me just fine. So,
maybe a better way to say what you're saying is "Hey, I'm developing a
subprogram API, I hope some of you find it useful in your application
development."

rather than saying that we should use it and it's necessary (and that I
should give you the functionality in rheise.os, otherwise you can't use
it! By the way, do I get an apology for that remark, or do you still
maintain that rheise.os is a dead-end project?)

> If you want to write a custom program for the JOS Project, you should write
> it as a subprogram, not a Java application. A Java application is only for
> backward compatibility. Compatibility with the Java application model is
> only for programs that others have already written and continue to write.

If you want to replace the well established main() method, I think we'll
need a vote. The main reason I chose not to use your program API is that
it doesn't reuse existing standards (ie. main()) when you could have
implemented all of that functionality using existing standards. If you
did so, it would be possible to run any existing application as a
subprogram, without the need of a wrapper class.

> Many applications, like javac, can be run successfully as a subprogram. No
> bytecode process is needed.

That is true. If you know what you're doing you can be sure in some
cases that it won't matter if you reuse the class loader of the parent.
Not that it's entirely elegant to be executing legacy applications
counter to the way they were intended. What I was trying to say in my
last email was that a new and improved javac tool could be written that
could be used in this way naturally. That is, rather than writing javac
as a program, it could be written as a library, and there could be a
simple javac program that interfaces to that library if you wish to run
it as a program. Otherwise, your application can invoke methods on the
library directly (which is reusing the class loader just as you're
reusing the class loader - only this time, it was intended to be used
that way).

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From gchii@mindspring.com Fri, 19 May 2000 11:09:53 -0400
Date: Fri, 19 May 2000 11:09:53 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] Re: Arch digest, Vol 1 #185 - 7 msgs

At 10:21 AM 5/19/00 -0400, "Todd L. Miller" <tmiller@haverford.edu> wrote:
>This would suggest to me that we need, in fact, to share the statics of a
>class (only) when an object of that type is shared.  If this proves to be
>unworkable, we may be forced to restrict shared objects to those whose
>classes (and parents) do not have statics.

Exactly. It has proven to be unworkable. Static fields of a class include
those fields that are hidden and/or vm-specific. All classes have static
fields. Since all classes have static fields, we can share no classes.

With a single primordial class loader, the class loader property (a static
field) is null -- implying THE primordial class loader. With multiple
primordial class loaders, the primordial class loader property (a static
field) contains a reference to its primordial class loader. Someone
suggested and I concur that the class loader property cannot be used for
the primordial class loader property, so that getClassLoader() returns null
for "system" classes.

Even final static fields cannot be shared. Final is shallow and applies to
only the direct object reference. For example, a hashtable can be final and
yet objects added to it, like this:

public interface Demo {
  public static final Hashtable cache = new Hashtable();
}

  public void example1() {
    Demo.cache.put( "name-1", "value-1" );
    Demo.cache.put( "name-2", "value-2" );
    Demo.cache.put( "name-3", "value-3" );
  }

And therefore, it is possible to do something like this:

  public void example2() {
    int iMax = 1000;
    for ( int i = 0; i < iMax; i++ ) {
      Thread t = new CustomThread();
      t.start();
      Demo.cache.put( "thread." + i, t );
    }
  }

If Process A starts 1000 threads and adds them to a hashtable owned by
Process B, all of the threads are stopped() when Process A dies. That is
another reason why Process B cannot own an object created by Process A,
except by proxy.

Therefore, the easiest object sharing may be performed by subprograms, not
processes. With what we know so far, it might be possible to share objects
across custom class loaders (with limitations). It is definitely possible
to share raw bytecode. It is possible to share class definitions within a
virtual machine. This kind of intra-process object sharing may be important
and goes beyond the Java Virtual Machine Specification.





From gchii@mindspring.com Fri, 19 May 2000 15:22:32 -0400
Date: Fri, 19 May 2000 15:22:32 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [subprogram] Definition

At 12:23 AM 5/20/00 +1000, Ryan Heise <ryan@whitewolf.com.au> wrote:
>A process API is necessary, yes.
>Your subprogram API is useful, but not necessary*.

Excuse me; but, applets, applications, components, runnable's and servlets
are not mine. They are part of Java subprogram API. I said, "A subprogram
API is necessary." I did not say, "My subprogram API is necessary."

A subprogram API is always necessary for a new process to invoke some kind
of code. You cannot have a useful process without a subprogram. Of all the
subprogram APIs, the Java application is the weakest model.





From ryan@whitewolf.com.au Sat, 20 May 2000 01:44:42 +1000
Date: Sat, 20 May 2000 01:44:42 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Re: Arch digest, Vol 1 #185 - 7 msgs

"Todd L. Miller" wrote:
> 
> > (_Quinn, how do things look from down in the JVM trenches? You'd
> > probably have the best idea of how this inlining problem can be solved.)
> 
>         Quite honestly, I haven't looked at optimizations at all.  This
> particular problem, however strikes me in two ways -- first, how often
> will we be trying to inline method calls across processes?

My feeling is that class archives will not be changed on disk very often
and so most of the time class definitions will always match and inlining
will not need to be done more than once in each case.

The question is, when it does happen, will the model (whatever that is)
be efficient or not?

>  (That is, how
> much of a worry is this going to be?  We may just be able to ignore it
> without much of a penalty.)

It depends on whether the model/solution we choose affects performance
even if you are not executing a cross process inlined method.

> Second, having symbolic references mismatch
> across processes will not be a problem if a a shared object does lookups
> in the executing process's classloader. OTOH, you've made good points
> about where the statics for a shared object's method ought to be.

Statics aren't the only things involved here. If you call
sharedObject.someMethod() and that method tries to interact with other
classes, it should interact with the classes in its own process, and not
the currently executing process (for the same reasons I stated for
statics).

>  One question I do have, though, looking at
> this from a UNIXy point of view.  I share two things -- a memory location
> (my static variable) and a function pointer (the method in question).  The
> function referenced by the pointer reads and writes from that global
> variable.  At no time should two simultaneous executions of the function
> find different things in that global variable -- it being shared, they're
> reading/writing to the same place.

Why must the static variable be shared (considering that I have
explained in detail why I think it should not be)? Am I missing
something in your explanation? (forgive me, it's 1:30am here :-)

> If this proves to be unworkable, we may be
> forced to restrict shared objects to those whose classes (and parents) do
> not have statics.

An interesting idea, but consider that that shared object is an
interface to what's going on in another process. If you call a method on
it, it might do some talking with some objects or classes in its own
process. When it talks, to those classes, it should be talking to the
classes it thinks it's talking to (same argument for statics). This is
important if only the shared object requires shared class definitions
but the classes it depends on do not require shared class definitions.
The shared object really does belong to that other process (it was
created by that process) so whenever it is executing, it should behave
as though it is linked with that process.

(although I'm not giving this as much thought as I usually do. A few
more emails and I'll be off to sleep)

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Sat, 20 May 2000 01:12:06 +1000
Date: Sat, 20 May 2000 01:12:06 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

Gilbert Carl Herschberger II wrote:
> 
> At 06:08 PM 5/19/00 +1000, Ryan Heise <ryan@whitewolf.com.au> wrote:
> >Spawning hundreds of processes in quick succession doesn't sound like
> >the right way to get a job done to me.
> 
> When you don't understand why someone needs to spawn hundreds of processes,
> you should ask questions. They are likely to either (1) have a very good
> reason, or (2) not know of any other way.

And when I do understand why someone needs to spawn hundreds of
processes, I give an interesting theory on the use of processes in an
object oriented operating system.

Yours and my statements are pretty much true statements, but they have
little point, unless you were trying to teach me manners. If so, as list
adminstrator I should advice you that that is inappropriate for
discussion on this list.

Note to John, please interpret last email as theory on process usage for
the purposes of discussion. Your input in the discussion has been
excellent, so I hope I did not discourage you in any way.

> Many processes on a laptop, desktop and server system sounds like the right
> thing to do. It doesn't make sense to me to develop a multiple-process
> operating system and then encourage people not to use its multiple-process
> features.

You misunderstood. I am not encouraging people not to use its
multiple-process features. I am merely theorising that while 'ls' was a
process in UNIX, it probably makes more sense for it not to be in an
object-oriented operating system. That doesn't mean I don't think we
should use processes for applications or servers. If I may quote myself:

> There is certainly no need to use processes in the same way UNIX forced
> programmers to, but we can nevertheless support the basic process model
> since it is the foundation for many different uses. You can look at a
> process as a perimeter around executing code that should not be able to
> interfere with, or be interfered by, anything else. Objects that work
> together to achieve a goal can go in the same process*.
> 
> (*) Usually. The exceptions should be obvious to the developer.

That is, I think applications and servers should generally be processes
because they generally meet the above criteria for having a process
(another reason for having a process might be to run standard programs
that read from stdin and write to stdout). So, I do like processes.

Does this make sense now?

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From tmiller@haverford.edu Fri, 19 May 2000 12:31:59 -0400 (EDT)
Date: Fri, 19 May 2000 12:31:59 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Re: Arch digest, Vol 1 #185 - 7 msgs

> Why must the static variable be shared (considering that I have
> explained in detail why I think it should not be)? Am I missing
> something in your explanation? (forgive me, it's 1:30am here :-)

	My apologies -- if a static is a global, as I've postulated, then
it is nothing more than a particular location in memory.  Then, you
share this particular piece of memory by giving another process
r(w) access to it.  It then follows that both processes are using the same
memory location -- otherwise, they would /not/ be performing IPC.  The
question is then if my first steps are correct -- are statics isomorphic
to globals, and therefore to a location in memory?

	I am attempting to answer the question of what to do about or with
statics more or less by analogy, and it is where the analogy breaks down
that the interesting cases appear.  Continuing the analogy, if a function
(pointer) is shared between two different processes, then when it follows
its pointer to the global, it will be changing it for both
processes.

-_Quinn





From tmiller@haverford.edu Fri, 19 May 2000 12:56:47 -0400 (EDT)
Date: Fri, 19 May 2000 12:56:47 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Re: Arch digest, Vol 1 #185 - 7 msgs

> Exactly. It has proven to be unworkable.

	Must have missed that proof; could you run it by me again?

> All classes have static fields.

	The only static fields that are of any import are the Java ones
-- the JVM can manage the others on its own -- and it's trivial to write a
class without static fields.  java.lang.Object, AFAIK, does not have
statics, so subclassing it is not a problem.

> With what we know so far, it might be possible to share objects across
> custom class loaders (with limitations).

	From what we know, sharing objects across custom class loaders
breaks the specification horribly, which is why Ryan and I required that
any such sharing take place between primordial loaders.  A custom
classloader will /never/ have the same class as any other classloader,
because its classloader property will always be different; using only
primordial loaders allows us the fiction that all primordial loaders are
the same, more or less.  If I create two custom classloaders that don't
use findSystemClass() to fetch a particular class, then that particular
class must have its own statics in each classloader.  Furthermore, objects
of that type can't be shared between the classloaders because their
class's classloader property is different.

	That is, what makes object sharing across processes possible is
that an object's class definition may be safely shared between those
processes, and that is only because the each primordial classloader looks
like the /only/ primordial classloader to each process.  We have been
trying to decide what the proper thing to do with the /class itself/ of
each shared object -- the shell around a class definition containing the
statics.  (As an object is a shell around the class containing its
instance variables.)  Sharing a class in this case does not appear to
break the spec, again because we're dealing with the primordial
loader(s) -- there's no way an application could tell from whence the
class of its object came -- unless we allow it.  Ryan thinks the proper
thing to do is for a shared object to retain its originator's statics; I
have given one contention the other way, and have a second -- transparency
-- which could be negated by the need for a specific sharing API.  (That
is, if we're not being transparent there, perhaps we don't need to be
elsewhere, as well.)

	One way of looking at the question -- 

/* previous use of type SO up here, to
   make sure the class is loaded */
a = getSharedObjectOfTypeSO();
b = new SO();

a.setSOStaticD( 3 );
b.setSOStaticD( 4 );

if ( a.getSOStaticD() == b.getSOStaticD() ) {
	println( "Shared classes." );
	} else
	println( "Unshared classes." );
	}
/* end code fragment */

	In a normal virtual machine, which it is our job to emulate, what
happens?  It will return "Shared classes.", unless gSOOTSO() uses a custom
classloader to redefine SO.  If it does that, I'm not actually sure what
will happen -- if it's something useful, then this is probably the
behaviour we want to go with for true SharedObjects.

-_Quinn





From ryan@whitewolf.com.au Sat, 20 May 2000 03:36:37 +1000
Date: Sat, 20 May 2000 03:36:37 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [subprogram] Definition

Gilbert Carl Herschberger II wrote:
> 
> At 12:23 AM 5/20/00 +1000, Ryan Heise <ryan@whitewolf.com.au> wrote:
> >A process API is necessary, yes.
> >Your subprogram API is useful, but not necessary*.
> 
> Excuse me; but, applets, applications, components, runnable's and servlets
> are not mine. They are part of Java subprogram API. I said, "A subprogram
> API is necessary." I did not say, "My subprogram API is necessary."

So, if I can translate, you're saying that subprogram APIs (plural) are
useful, and not that "A" subprogram API is necessary. Is my
understanding correct now? Are you simply encouraging people to use
existing subprogram APIs, so then, before you were not trying to point
out any flaws rheise.os for not having subprograms?

Then I don't understand your criticism of rheise.os:

> It is far too premature to adopt rheise.os as a standard for the JOS
> Project. It might lead us to a standard. It may be a useful model. It
> cannot be taken literally.
> 
> Give me something I can use. I can't use rheise.os. Running a Java
> application as a subprogram is not equivalent to running a Java application
> as a process.
> ...
> Don't be distracted by rheise.os.

Soon after, you told me that "rheise.os is a dead-end project".

Why? Because it doesn't have subprograms? You certainly didn't give any
other reasons. If it wasn't subprograms, then you gave no reasons at
all, and your remark was completely uncalled for. Such remarks are
counter-productive to the project, and that sort of attitude that cannot
be tolerated.

However, if I am misunderstanding you, please explain:

- Why is rheise.os a dead-end project, if not because of no subprograms?
- If it is because of no subprograms, why are you now implying that
rheise.os need not implement subprograms (when they already exist in
Sun's API)?

My misunderstanding of the importance of subprograms definately lies
within. Last week I thought you had one opinion. Now it seems you have
another. If you have changed your opinion, have you also changed your
opinion about rheise.os?

-- 
Ryan Heise < arch@jos.org list administrator >

http://www.progsoc.uts.edu.au/~rheise/





From gchii@mindspring.com Fri, 19 May 2000 11:50:45 -0400
Date: Fri, 19 May 2000 11:50:45 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] Picture this.

If raw bytecode is managed by a system-wide bytecode cache...

If vm-specific class definitions are cached by a virtual machine...

If a process manager is able to create a new process, with a new primordial
class loader, new thread group, etc...

If more than one virtual machine can exist within a single machine code
process (like JNI design)...

Each primordial class loader is linked to the class definition cache within
a virtual machine. The class definition cache is linked to the system-wide
bytecode cache. The picture might look something like this:

<URL:http://www.mindspring.com/~gchii/jos/image/mpcl-1.gif>





From gchii@mindspring.com Fri, 19 May 2000 17:50:54 -0400
Date: Fri, 19 May 2000 17:50:54 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [static property] Fields

A static field is a property of a class. It is accessable as an L-value. It
is assignable by the assignment operator (=). It may or may not be public.
It may or may not be final. It must be static.

public interface Demo {
  static int n;
}

n is accessable as an L-value, as in the following expression:

int x = ( n + n ) - ( n * n ) / n

n is assignable by the assignment operator (=), as in the following
expression:

n = 0;

The static field is closely associated with an instance of java.lang.Class.
Its name, type and value may be discovered at runtime through reflection.





From gchii@mindspring.com Fri, 19 May 2000 18:02:54 -0400
Date: Fri, 19 May 2000 18:02:54 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [static property] Runtime

The getRuntime() method is an accessor to the Runtime property of
java.lang.Runtime.

RunFinalizersOnExit is a static property of java.lang.Runtime. It has a
modifier, but no accessor.





From gchii@mindspring.com Fri, 19 May 2000 18:33:20 -0400
Date: Fri, 19 May 2000 18:33:20 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [subprogram] Definition

At 03:36 AM 5/20/00 +1000, Ryan Heise <ryan@whitewolf.com.au> wrote:
>So, if I can translate, you're saying that subprogram APIs (plural) are
>useful, and not that "A" subprogram API is necessary. Is my
>understanding correct now? Are you simply encouraging people to use
>existing subprogram APIs, so then, before you were not trying to point
>out any flaws rheise.os for not having subprograms?

As I explained before, a subprogram API is critical to a process API. At
least one subprogram API is necessary in order to create a process. Any
subprogram API will do. A subprogram API is not optional. It is more than
useful; it is required.

Otherwise, a process would have nothing to do. In the fix-up code for a
machine code process, there is a lot of CPU cycles that must be used before
the call to main(). In the fix-up code for a bytecode process, there is
also a lot of CPU cycles that must be used before a call to whatever. There
must be a subprogram API so that a generic process fix-up code "knows" what
to do with a custom subprogram. There must be some API defined.

In a C program, fix-up code looks for a method called _main(...). In a Java
application, fix-up code inside the java/jre tool looks for a method called
main(). The java/jre tool is only an example of one way of doing it. The
Java Native Interface does not require a C/C++ program to look for main(),
nor exclusively use a primordial class loader, nor to invoke a static main().

I am not encouraging or discouraging the use of a subprogram API. I am
pointing out that the Java application uses a subprogram API. Both the
generic fix-up code for a process and a custom Java application must agree.
On the one hand, fix-up code creates four threads, sets up
System.properties (etc), requires a static main() and passes additional
parameters through args. And, a Java application must implement a method
called "main". Main must have a method access of public and static. Main
must have a method descriptor equal to "(L[java.lang.String;)V".

This is one way of doing it. It is not the only way.

>Then I don't understand your criticism of rheise.os:
This thread is not about rheise.os.





From gchii@mindspring.com Fri, 19 May 2000 17:56:13 -0400
Date: Fri, 19 May 2000 17:56:13 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [static property] Accessor/Modifier

Static methods are used to encapsulate a static property. Accessor and
modifier methods are static for a static property. Accessors can be used as
an L-value. Modifiers are used instead of the assignment operator (=)
because, in the Java programming language, the assignment operator cannot
be overridden. Here is a simple example.

public class Demo {
  private static int n;

  int getN() {
    return n;
  }

  void setN( int v ) {
    n = v;
  }
}

Accessors can be used as an L-value, like this:

int x = ( getN() + getN() ) - ( getN() * getN() ) / getN();

Modifiers are used instead of the assignment operator (=), like this:

setN( 0 );

To encapsulate a static property, use static methods.





From gchii@mindspring.com Fri, 19 May 2000 19:41:40 -0400
Date: Fri, 19 May 2000 19:41:40 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] Re: Arch digest, Vol 1 #185 - 7 msgs

At 12:56 PM 5/19/00 -0400, I wrote:
>> All classes have static fields.

Did I make a mistake? Each class has a superclass. The superclass property
is an instance property, not static. Each class may implement an interface.
The interface[] property is also an instance property, not static. Each
method of a class may throw an exception. The exception[][] property is
also an instance property, not static. Methods of a class may invoke other
classes. From codepool, the class[] property is also an instance property,
not static.

What's left?

Even when there is only one primordial class loader, I believe objects can
be shared as long as their bytecode is identical or their class definitions
are equivalent. If not, why not?

A primordial class loader is-a class loader. So if there's a problem
sharing objects between class loaders in general, there is a problem
sharing objects between primordial class loaders. The object-sharing
mechanism, which is yet to-be-defined, might provide a way to share objects
between two class loaders. In fact, I have experimented with this approach:

public interface Shareable {
  public Object getShare();
  public void setShare( Object v );
}

public class SharedObject
    implements Shareable {
  public SharedObject() {
  }
  public Object getShare() {
    return share;
  }
  public void setShare( Object v ) {
    share = v;

    if ( v instanceof Shareable ) {
      System.out.println( "shareable" );
    }
    else {
      System.out.println( "not shareable" );
    }
  }
  private Object share;
}

The Shared interface is loaded with a primordial class loader. I then have
two class loaders, A and B. One instance of SharedObject class is loaded
with classloader A. Another instance of SharedObject class is loaded with
class loader B.

And then, drum roll...

  public void example() {
    ClassLoader loaderA = new CustomClassLoader();
    Shareable t = loaderA.getInstanceOfSharedObject();

    ClassLoader loaderB = new CustomClassLoader();
    t.setShare( loaderB.getInstanceOfSharedObject() );
  }

This works because t knows ObjectB through the Sharable interface, which is
a system class. But what if it weren't?





From jewel@pixie.co.za Fri, 19 May 2000 23:31:12 -0200 (GMT+2)
Date: Fri, 19 May 2000 23:31:12 -0200 (GMT+2)
From: John Leuner jewel@pixie.co.za
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> disturbing ways. For example, Process A calls System.setOut(logFile),
> and Process B all of a sudden loses its output to some unknown place.
> 
> There are at least 114 non-final statics in the JDK 1.1 system classes.
> Per package, they are distributed as follows:
> 
> [ note: there are certainly more to be found with a smarter algorithm ]
> 
> applet          0
> util            20
> ...

> You would need to check each one to make sure that one process cannot
> interfere with another process through manipulation of these statics. 

A quick and dirty optimisation might be to share classes that have no
static variables (don't know how many of those there are).

> is possible to work around some of them in this case, but not all of
> them. For example, System.in/out/err can be protected by simply sharing
> all system classes except for java.lang.System, causing each process to
> have their own java.lang.System statics. However, I was lucky* to be
> able to do that in this instance because java.lang.System is a purely
> static class (there can be no references to instances of that class). If
> instances can be passed around, you will not be able to cast the
> instance of the per process class to the type that a primordially loaded
> class would expect (it can only expect one type, not n different types
> for however many processes there are). Did that make sense? I may have
> left out a few crucial sentences that I thought rather than wrote...

No I understand exactly what you mean.
 
> (*) I actually support a host implementation of rheise.os that works
> pretty much as you desired, and it attempts to work around the static
> problems on a case by case basis. Of course it is not (and cannot) be
> perfect, but it works well enough to be used until the native
> implementation is integrated with decaf. If you want to take a look at
> it, goto http://www.progsoc.uts.edu.au/~rheise/projects/rheise.os/

Will have a look.
 
> > > In addition to computational efficiency, class definition sharing (which
> > > is based on class definition caching) minimises memory waste.
> > 
> > Yes class definition caching will certainly help, although I don't see how
> > it has much advantage over a conventional file cache.
> > 
> > What is definition sharing?
> 
> That was discussed in those two links I referred you to in the last
> email. Class definition caching is the new term I just invented to avoid
> conflict with alternative ideas that do not depend on caching in the
> same way I do.
> 
> I depend on class definition caching to avoid doing I/O twice when
> findSystemClass("java.awt.Button") is called twice. If the modification
> date of the archive hasn't changed, I simply use the class definition in
> the cache and skip the InputStream.read() and much of the
> ClassLoader.defineClass() process. This is a performance optimisation.

Ok I see. But I think you have to be careful. A cache will make sure it
doesn't hold unneeded stuff in memory. If you duplicate the cache (the
file cache and your own 'cache'), you might end up not using available
memory optimally (you will duplicate info in both caches).
 
> Class definition sharing, on the other hand, is a memory optimisation,
> and a crucial part of my proposal with respect to IPC:
> 
> 	http://jos.org/pipermail/arch/2000-April/000449.html
> 
> Class definition sharing simply means that if java.awt.Button.class is
> loaded twice into two separate processes, they both (ie. the
> java.lang.Class objects) can point to the common class definition
> structure rather than have their own copy of the data (_Quinn's
> insight). So, there end up being two java.lang.Class objects with
> references to the same class definition object.

I don't quite understand. Each process will have an internal class
definition (a C or C++ structure) with a pointer to the java.lang.Class
object. These will be in different heaps. What exactly will the two
java.lang.Class objects be sharing?
 
> The way I take advantage of this for IPC is, I allow an object to be
> casted from one java.awt.Button to another java.awt.Button if those two
> classes share the same class definition (and if the two classes were
> loaded by primordial class loaders, which is implied in my specific
> proposal). It is difficult to grasp the implications of this, but it is
> explained in detail in the proposal above (some details are yet to be
> added, _Quinn has written a more recent analysis of what are the
> necessary "properties" of such a system and I haven't updated my
> proposal to explain how they might fit in yet)

Ok, so is the "class definition" separated from the static variables for
that class?


> >  > We can only wait and see if it actually works - I suspect
> >  > the performance will be significantly faster than a standard JVM.
> > 
> > Not really. If the file system is already caching the .class files, how
> > will your method be much faster?
> 
> Yes, particularly with jar files (which is where most classes will be
> loaded from). You are asking why we need a class definition cache in
> addition to a file cache. Besides the fact that it is just as easy to
> implement, a class definition cache saves us from:
> 
> - reading the class file from a stream. Even if the file is cached, we
> must loop over all the bytes via a stream (with memory as its source
> rather than disk).
> 
> - interpreting the jar file. Even if the jar file is cached, we must
> find the class file within it.

Ok these two I understand.
 
> - interpreting the class file. This means converting the class file
> format into a class definition structure.

This one bothers me. You're saying that you can cache the class definition
structure. But the class definition structure points to other classes,
which may have to be loaded. (Possibly by different class loaders?). 

It's difficult to explain, but basically when you create the class
definition structure, you're loading a whole lot of other stuff and thus
creating dependencies. How do we now the dependencies are valid for the
next time that the definition is used?

This isn't clear in my mind, but do you see what I'm getting at?
 
> > But you shouldn't be comparing to a normal JVM, you should be comparing
> > the native operating environment of other OS'es. Can we compete against
> > the processes in BeOS, UNIX and Win32?
> 
> In that case, it is VERY important that we do class definition caching
> in addition to file system caching :-) 
> 
> > Will our solution be able to cope when the user starts compiling the whole
> > class library and spawns hundreds of processes in quick succession?
> 
> Spawning hundreds of processes in quick succession doesn't sound like
> the right way to get a job done to me. In UNIX the program was the item
> of reuse, so lots of programs would be spawned in quick succession to
> get a job done. But in an object oriented operating system, objects are
> the items of reuse, and they usually interact with eachother in the same
> address space.
> 
> In this example, it doesn't sound like a good idea to spawn hundreds of
> separate javac processes one after another. It turns out IDE designers
> don't think so either (not just for exec latency though, mainly for
> opportunities for optimisation w.r.t. inter-class dependencies). I would
> prefer to think of the java compiler as a reusable library/package that
> can be used in a number of different contexts, eg. an IDE (so it doesn't
> have to spawn hundreds of separate processes), or your own personal
> compilation macro or Makefile equivalent which can make use of the java
> compiler without having to spawn processes.
> 
> All that theory aside, javac can still be executed as a process if you
> wish, and you should get good performance with
> JavaProcess.reuseClassDefinitions() or maybe even without. Let's wait
> and see.
> 
> > > (An additional note, interaction between 'ls', 'grep' and 'wc' does not
> > > necessarily need to involve multiple processes. The equivalent of this
> > > in an object oriented context might be the interaction of Java beans
> > > which need not be in separate processes. In this case, the same class
> > > loader is used and the resolution process is not an issue)
> > 
> > Yes, but if our Processes are emulating what an application expects when
> > it runs on a normal JVM, then programmers are going to write to this
> > specification. They are going to expect pipes, their own copy of static
> > variables for all classes they are using and so on.
> 
> What I meant was, the 'ls', 'grep' and 'wc' could be rewritten in an
> object-oriented context so that they can interact as reusable objects in
> the same address space. rheise.os still supports processes in all their
> glory. If you wish to write 'ls' as a program that runs in its own
> process, it will get its own version of System.in/out/err and it will be
> able to do pipes. If you download rheise.os, there is an example that
> shows one process piping its output into the input of another.
> 
> > Perhaps it isn't such a good thing to model the traditional UNIX process
> > so closely?
> 
> There is certainly no need to use processes in the same way UNIX forced
> programmers to, but we can nevertheless support the basic process model
> since it is the foundation for many different uses. You can look at a
> process as a perimeter around executing code that should not be able to
> interfere with, or be interfered by, anything else. Objects that work
> together to achieve a goal can go in the same process*.

Ok, agreed and understood.

Doesn't this imply that we should start thinking about new constructs that
might be useful to the programmer. We've implemented the Process for
backwards compatibility (and its useful properties), but we should offer
an alternative so that programmers don't gravitate to this model
automatically.

It could be that Java itself provides programmers with natural constructs
/ paradigms / patterns to use instead of Processes, but maybe we should
just highlight them and see how a typical application program is going to
use JOS.

For example, where a traditional FTP daemon might spawn processes to
service requests, a Java one would naturally create threads.

But undex UNIX the kernel allows you to control the resources used by that
process, to account for how much CPU time it has used etc. 

Do we have an analogue in JOS, do we need one?

John
 





From tmiller@haverford.edu Sat, 20 May 2000 08:33:58 -0400 (EDT)
Date: Sat, 20 May 2000 08:33:58 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Re: Arch digest, Vol 1 #185 - 7 msgs

> A primordial class loader is-a class loader. So if there's a problem
> sharing objects between class loaders in general, there is a problem
> sharing objects between primordial class loaders.

	This is not true; a PCL can share with another PCL only because
the sharing can be done in a fashion transparent to the JVM
specification, and therefore the running application.  Sharing
between non-primordial classloaders is a problem because the spec does not
allow it.

> This works because t knows ObjectB through the Sharable interface, which is
> a system class. But what if it weren't?

	Then it wouldn't, and in fact couldn't, work.  There are -- as you
have demonstrated -- programattic ways to share objects.  However, you
wouldn't be able to cast from Shareable to SharedObject, because SO was
/not/ loaded by the PCL (== is a system class).  Reflection, OTOH, may
work, but if you're going to need to use reflection for IPC, serialization
is probably going to be more effective.

-_Quinn





From tmiller@haverford.edu Sat, 20 May 2000 08:38:33 -0400 (EDT)
Date: Sat, 20 May 2000 08:38:33 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> What exactly will the two java.lang.Class objects be sharing?

	A java.lang.Class object, from the native side, is a collection of
static variables and method definitions, the constant pool, etc -- the
vast majority of the bulk of the .class file.  Everything but the static
variables can be shared across java.lang.Class objects.

> Ok, so is the "class definition" separated from the static variables for
> that class?

	Yes -- that's how we distinguish between a class and its
definition.  I thought we had made that clear. :)

> This isn't clear in my mind, but do you see what I'm getting at?

	Yes.  We're beginning to look into it now.  It's already clear
that parent classes must be the same, but we need to determine what to do
about symbolic references...

> Do we have an analogue in JOS, do we need one?

	Not yet, and yes.

-_Quinn





From donaldp@mad.scientist.com Sun, 21 May 2000 20:38:11 +1000
Date: Sun, 21 May 2000 20:38:11 +1000
From: Peter Donald donaldp@mad.scientist.com
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

Hi,

>> What exactly will the two java.lang.Class objects be sharing?
>
>	A java.lang.Class object, from the native side, is a collection of
>static variables and method definitions, the constant pool, etc -- the
>vast majority of the bulk of the .class file.  Everything but the static
>variables can be shared across java.lang.Class objects.

Here's my current thoughts on sharability of JIT generated code,
specifically inlining.

A method (P) from class (Q) can be inlined if Q is in same archive (R)
(where archive is a JAR/Zip/War/cab file) and the package Q resides in is
"sealed" (as in from the Jar specification). Anytime a R is changed and a
process is using it, an extra copy must be maintained. Else corruption
could occur by mistakenly loading a class from "new" archive that was
supposed to loaded from "old" archive. 

This still leaves a large number of methods not inlined that should be (ie
most of Math.* and String.*). So interpackage inlining could be made
available if;
* it is part of base java install. ie java.* or javax.* 
* the calling code's archive (S) specified a dependancy on R (as per the
Jar standard) either directly or indirectly (via depending on another
archive that depends on S)

Interpackage inlining means the new process has to use the same archive and
dependent archives if they want to use cached copy.

While the above approach is fairly course it should get most regular apps
that use standard jars/libraries. It will however bite for applications
that keep .class files on filesystem so there may need to be extra steps
taken in this case ???

Thoughts ?

Cheers,

Pete

*------------------------------------------------------*
| "Nearly all men can stand adversity, but if you want |
| to test a man's character, give him power."          |
|       -Abraham Lincoln                               |
*------------------------------------------------------*




From ryan@whitewolf.com.au Sun, 21 May 2000 23:30:31 +1000
Date: Sun, 21 May 2000 23:30:31 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

Apoligies for the late reply, I have been taking time off and giving
rheise.os long deserved attention.

John Leuner wrote:

> Ok I see. But I think you have to be careful. A cache will make sure it
> doesn't hold unneeded stuff in memory. If you duplicate the cache (the
> file cache and your own 'cache'), you might end up not using available
> memory optimally (you will duplicate info in both caches).

Fortunately, we are not using up any additional memory at all. Decaf
needs an internal data structure to store the code that it is executing,
and the class definition is that structure (ordinarily this structure
would be called "class" but the class/definition split allows us to do
amazing things).

> For example, where a traditional FTP daemon might spawn processes to
> service requests, a Java one would naturally create threads.

Naturally :-) Check out my ftp server written in Java:

	http://www.progsoc.uts.edu.au/~rheise/projects/jftpd/

It is sensible that an ftp server be one process rather than 20. The old
UNIX model forced the programmer to make more processes than intended.
Not only do threads make things easier, but new concepts such as
JavaBeans help too.

> But undex UNIX the kernel allows you to control the resources used by that
> process, to account for how much CPU time it has used etc.

Right. Sensible process usage (eg. a process per application) would
allow sensible tracking. Whether or not we want finer control is an
interesting question. Of course, accounting per thread is definately
something to consider, but maybe there's not much more we will need.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Sun, 21 May 2000 23:34:52 +1000
Date: Sun, 21 May 2000 23:34:52 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Re: Arch digest, Vol 1 #185 - 7 msgs

"Todd L. Miller" wrote:
> 
> > Why must the static variable be shared (considering that I have
> > explained in detail why I think it should not be)? Am I missing
> > something in your explanation? (forgive me, it's 1:30am here :-)
> 
>         My apologies -- if a static is a global, as I've postulated, then
> it is nothing more than a particular location in memory.  Then, you
> share this particular piece of memory by giving another process
> r(w) access to it.  It then follows that both processes are using the same
> memory location -- otherwise, they would /not/ be performing IPC.  The
> question is then if my first steps are correct -- are statics isomorphic
> to globals, and therefore to a location in memory?

Ok, I understand you now. My take on it is that it is the object that is
shared, and not the class. This means that the class may still be used
within your process as a separate entity without any interference from
the IPC that is going on with a particular instance of that class.

When talking about the shared object, there is only one memory location
for that static. However, when talking about the class (which is not
shared due to complexities discussed in another email to John), the
static you find is the one that belongs to your process.

If when we share an object, we also share the class, the issue
disappears. BUT, I don't think the class should be shared for two
reasons:

- there are complexities to do with class loader references (ie. it
doesn't make sense conceptually)
- a process should be able to carry on IPC with two different processes
simultaneously using the same the same class type for both shared
objects. However, IPC with one process should not interfere with IPC
with the other. If the Class is shared it cannot be avoided (when
statics are involved).

In your original email you wrote:

>         Quite honestly, I haven't looked at optimizations at all.  This
> particular problem, however strikes me in two ways -- first, how often
> will we be trying to inline method calls across processes?  (That is, how
> much of a worry is this going to be?  We may just be able to ignore it
> without much of a penalty.)  Second, having symbolic references mismatch
> across processes will not be a problem if a a shared object does lookups
> in the executing process's classloader; the JVM will throw a LinkError
> (IIRC) if/when the shared class tries to do something it can't because the
> calling process is improperly set up.

Unfortunately, it is not a matter of ignoring it and throwing
LinkageErrors when it happens, because this will affect applications
even if they are not using shared objects.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Sun, 21 May 2000 23:37:16 +1000
Date: Sun, 21 May 2000 23:37:16 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Re: Arch digest, Vol 1 #185 - 7 msgs

Gilbert Carl Herschberger II wrote:

> If Process A starts 1000 threads and adds them to a hashtable owned by
> Process B, all of the threads are stopped() when Process A dies. That is
> another reason why Process B cannot own an object created by Process A,
> except by proxy.

I think you mean to say that Process B cannot "refer" to an object
created by Process A, except by proxy (It can "own" it simply by
reassigning ownership as we have discussed before).

That cleared, I am unsettled by your use of the word "cannot".

I don't see that proxies are required, as you are claiming them to be.
We also discussed this with Process objects which need to be shared
between processes in much the same way. In that thread, you claimed that
Process objects must also be shared via a proxy.

I have said this before, but if the project is to be successful, we need
to learn to consider two conflicting ideas long enough to compare them
equally. If I may quote myself:

>> (if we can sustain two conflicting ideas long enough to
>> find time to discuss them, I think we will have solved our thread
>> overload problem. Discarding ideas prematurely can be unfortunate, eg.
>> proxies, statics, process termination, parent processes, and of course,
>> rheise.os)

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Mon, 22 May 2000 00:07:31 +1000
Date: Mon, 22 May 2000 00:07:31 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [subprogram] Definition

Gilbert Carl Herschberger II wrote:

> As I explained before, a subprogram API is critical to a process API. At
> least one subprogram API is necessary in order to create a process.

You have to understand that there are different ways of looking at it.
For example, you /could/ consider a program defined using the main
method (Sun's API for Java Applications) generically as a subprogram,
but I don't. You seem to be requiring that I see things the way you do,
but there are other ways of looking at it.

I will explain why I don't see a Java application as a subprogram, but I
do not require that you see things my way. In fact, Sun explains it best
themselves:

http://java.sun.com/docs/books/tutorial/getStarted/application/anatomy.html

"Remember that a Java application is a standalone Java program-- a
program written in the Java language that runs independently of any
browser. "

"standalone" implies a lot of things, including that it is not a "sub"
program, but also that if application developers assume that
applications are standalone (which should be safe to assume since Sun
tells you this is so) then applications may not work at all as sub
programs.

Now, you could say that some programs that use this API are subprograms,
and some are Java applications, but do you think it is right to use the
same API for two different types of programs*? That would be the
opposite of strongly typed. Personally, I don't think this API is a
subprogram API (which explains why I do not think subprogram APIs are
necessary to invoke an Application in a process)

{ * If you want to use it as a subprogram API for specific programs that
are subprograms, please do. But since Sun says that this is the API you
use for writing applications, it is incorrect to say a subprogram API is
needed to run a process. }

> Any
> subprogram API will do. A subprogram API is not optional. It is more than
> useful; it is required.

Again, it is only required for your way of looking at it. To say it is
required, period, is to force your views upon others. And this is
especially unfortunate when you claim someone else's project as a
dead-end project (ie. that rheise.os can never become a "genuine"
bytecode process) simply because it does not meet "your" requirements.

> The
> Java Native Interface does not require a C/C++ program to look for main(),
> nor exclusively use a primordial class loader, nor to invoke a static main().

I did not consider it important that I support the calling of any
method, not just main, because Sun tells us that the standard way to do
it is the "main" method.

However, if you would like me to support different method names, that is
doable. But please make it as a suggestion rather than handling it the
way you did.

> On the one hand, fix-up code creates four threads, sets up
> System.properties (etc), requires a static main() and passes additional
> parameters through args. And, a Java application must implement a method
> called "main". Main must have a method access of public and static. Main
> must have a method descriptor equal to "(L[java.lang.String;)V".
> 
> This is one way of doing it. It is not the only way.

I can allow the name of the method to be invoked to be passed in, but
maybe you can give useful examples of this before I implement it. I am
trying to keep the API simple, this being something that can always be
added at a later stage, I'd like to know if it is worth adding it first
before I add it.

As for the other subprogram APIs (what I consider the "genuine"
subprogram APIs, but you are not required to see things this way) I
discussed on this list quite a while ago my desire to be able to run
servlets (which are sub programs) in an environment that gives you much
of the benefits of processes:

	http://jos.org/pipermail/arch/2000-May/000554.html

This was before you started complaining that my process API did not take
subprograms into account. The fact is I had started considering it even
before you brought it up. Sure, I haven't worked out the perfect way to
do it yet, but do you claim you have?

My thoughts so far have been along different lines from yours, but
that's allowed, no? The differences include:

1. I do not attempt to handle different program APIs generically, but
let user code (which knows how to deal with the specific API) deal with
it.

2. My reason for supporting subprograms in rheise.os is to give them
some of the advantages processes provide (separate namespaces, and
security).

For (1), I achieve this by casting the specific subprogram interface to
a java.lang.Object and storing that in the container (whether it is a
JavaProcess or something else I haven't yet decided). The container will
have its own class loader (to provide separate namespaces) and UserToken
(to provide security). I won't go into the details of how the first
object is constructed, but it is made available to the client code which
knows what methods to call on it to make it do its stuff.

For (2), I believe that running subprograms without giving them a
process-like environment is something that can be achieved outside the
framework.

> >Then I don't understand your criticism of rheise.os:
> This thread is not about rheise.os.

It is related.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From clemens@informatik.tu-muenchen.de Sun, 21 May 2000 17:52:23 +0000
Date: Sun, 21 May 2000 17:52:23 +0000
From: Claudio Clemens clemens@informatik.tu-muenchen.de
Subject: [JOS-Arch] What is JOS actually (fwd)

It's seams that there is noone reading general... so I repost it here.

-- 
+-----| http://linux.brasileiro.net - Seu site de informaes |-----+
|     Claudio Clemens at Home   -   Informatik   -   TU-Mnchen     |
|         clemens@in.tum.de         http://www.in.tum.de/~clemens   |
Eu no entendi nada, mas concordo com voc!

---------- Forwarded message ----------
Date: Thu, 11 May 2000 20:35:18 +0200 (CEST)
From: Claudio Clemens <clemens@informatik.tu-muenchen.de>
To: general@jos.org
Subject: What is JOS actually

So I read already a lot, but seams not enought. From the FAQ and
JOSWiki.Main.JOS there is
1.Kernel
2.JVM
3.J API
4.OS Services
5.UI
6.Utilities

There is also a listing of some projects, whith _I_ think they are
Kernel-JJOS
JVM-decaf
J API-Classpath
OS Services- JOSCore
UI-Jade
Utilities-Jext and everything else.

So now, what of this is JOS? Alltogether? Or just JOSCore? Or maybe
classpath, joscore, an jade?

Thanx for the support. I'm trying to write a digested report about JOS for
my university, and I could translate that to be one of the introducings
_missing_ tutorials. But for that I need your help. Hope to get some...

At

Claudio

-- 
+-----| http://linux.brasileiro.net - Seu site de informaes |-----+
|     Claudio Clemens at Home   -   Informatik   -   TU-Mnchen     |
|         clemens@in.tum.de         http://www.in.tum.de/~clemens   |
Digite algo para continuar ou outra tecla p/ abortar...






From clemens@informatik.tu-muenchen.de Sun, 21 May 2000 17:52:19 +0000
Date: Sun, 21 May 2000 17:52:19 +0000
From: Claudio Clemens clemens@informatik.tu-muenchen.de
Subject: [JOS-Arch] Correctness

Hi,

just a little question. Are the Schemes from
http://www.metamech.com/wiki/view/Main/JOSArchitectureDiscussion correct
and up to date ?

Thanx

Claudio

-- 
+-----| http://linux.brasileiro.net - Seu site de informaes |-----+
|     Claudio Clemens at Home   -   Informatik   -   TU-Mnchen     |
|         clemens@in.tum.de         http://www.in.tum.de/~clemens   |
Eu no entendi nada, mas concordo com voc!





From tmiller@haverford.edu Sun, 21 May 2000 13:56:53 -0400 (EDT)
Date: Sun, 21 May 2000 13:56:53 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] What is JOS actually (fwd)

	JJOS is a kernel written to support decaf; AFAIK, JJOS and decaf
are the only (JOS) active projects of their types (kernel & JVM).  I will
use an extant (open source/free software) class library with
decaf; maybe classpath, maybe not.  (I have yet to get classpath to work,
so...)  I can't speak for anything at a higher level than this,
though.  The question of what is JOS? is a difficult one to answer, for
the same reasons it is sometimes unclear what the answer to what is
Linux?  Linux is a kernel; many people also refer to distributions
including the Linux kernel (and almost always, GNU software) as 'Linux' as
well.  (This is where the demand to use the name GNU/Linux comes
from.)  Similarly, JOS could be as little as JOSCore and whatever happens
to be necessary to run it, or as much as a full distribution, much of
whose software will have been written by or for the JOS project.

-_Quinn





From tmiller@haverford.edu Sun, 21 May 2000 14:05:07 -0400 (EDT)
Date: Sun, 21 May 2000 14:05:07 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

	The main problem with inlining is resolving symbolic
references.  Normally, this is done in the context from which the method
originates, because that's where it would normally operate.  When inlining
a method from a shared object, we face the same question of resolving
symbolic references as we do when calling that method, a question for
which we have not come to an answer.  Bytecode is shared when class
definitions are shared; while there are potential issues with symbolic
references (et al) when dealing with other forms of code, I think the
mechanism(s) of definition sharing will work for them also.

-_Quinn






From tmiller@haverford.edu Sun, 21 May 2000 14:15:08 -0400 (EDT)
Date: Sun, 21 May 2000 14:15:08 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Re: Arch digest, Vol 1 #185 - 7 msgs

> When talking about the shared object, there is only one memory location
> for that static. However, when talking about the class (which is not
> shared due to complexities discussed in another email to John), the
> static you find is the one that belongs to your process.

	I'm missing something here.  A shared object's static is in its
class.  If there is a single memory location for that static, how can the
class find something other than the object?  It makes no sense to me that
one object of type A could be shared, and another not, and that this
difference would cause them to find different values in their statics.  
(As an aside, I'm reasonably sure that this would violate spec.)

> - a process should be able to carry on IPC with two different processes
> simultaneously using the same the same class type for both shared
> objects. However, IPC with one process should not interfere with IPC
> with the other. If the Class is shared it cannot be avoided (when
> statics are involved).

	This is a very good point.  Unfortunately, it opens an enourmous
can of worms dealing with point I mentioned above; how many different
statics for one class can you have?  I would think one!  But in this
scenario, you need at least three -- one for the process-local class, one
for A-B share, and one for the B-C share.  If C and A share another object
of the same type, what happens?  If they share the object shared with B?

	OTOH, looking at the *nix-equivalent scenario, if I share a global
with one process, and then another, it /must/ be share between the two
other processes as well; that is, sharing is transitive in conventional
systems.  (Which is not to say it must be in JOS, but...)

> Unfortunately, it is not a matter of ignoring it and throwing
> LinkageErrors when it happens, because this will affect applications
> even if they are not using shared objects.

	Urg.  You're right.

-_Quinn





From ryan@whitewolf.com.au Mon, 22 May 2000 11:25:23 +1000
Date: Mon, 22 May 2000 11:25:23 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Re: Arch digest, Vol 1 #185 - 7 msgs

"Todd L. Miller" wrote:
> 
> > When talking about the shared object, there is only one memory location
> > for that static. However, when talking about the class (which is not
> > shared due to complexities discussed in another email to John), the
> > static you find is the one that belongs to your process.
> 
>         I'm missing something here.  A shared object's static is in its
> class.  If there is a single memory location for that static, how can the
> class find something other than the object?  It makes no sense to me that
> one object of type A could be shared, and another not, and that this
> difference would cause them to find different values in their statics.

Not would, but could. If a process creates two objects of type A, they
both share the same class, and therefore the same statics.

If a process creates one object of type A, and obtains another object of
type A from a different process, then that object will be defined by a
different class and will therefore have different statics.

If a process obtains one object of type A from one process, and another
object of type A from another process, then each of those shared objects
will be defined by different classes (from different processes) and
therefore will have different statics. This allows a process to do IPC
with two servers without any interference.

> (As an aside, I'm reasonably sure that this would violate spec.)

You must have an misunderstanding. I am not interested in cutting
corners, and I believe this solution is the only solution presented so
far that _does_ meet the spec (apart from the fact that we are doing
object IPC).

Perhaps you are thinking of the case where one process creates two
objects of type A and attempts to share them individually with two other
processes. In this case, the statics are shared. It is ok (and right) to
share statics between objects that were created in the same process and
therefore defined by the same class (well, we're talking specifically
about primordial class loaders here). However, it is not ok to share
statics between objects that were created in different processes. This
causes static interference. One process should not be able to affect
another process *except* through a shared object.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From gchii@mindspring.com Mon, 22 May 2000 09:28:09 -0400
Date: Mon, 22 May 2000 09:28:09 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] Correctness

At 05:52 PM 5/21/00 +0000, Claudio Andre Till Clemens
<clemens@informatik.tu-muenchen.de> wrote:
>Are the Schemes from
>http://www.metamech.com/wiki/view/Main/JOSArchitectureDiscussion correct
>and up to date ?

If the "schemes" are the parts of JOS and their descriptions, I believe
this information is up-to-date. As currently under discuession, they but
contain many unresolved issues.

For more information, see also the DiagramPages article on JOS Wiki.





From gchii@mindspring.com Mon, 22 May 2000 12:03:44 -0400
Date: Mon, 22 May 2000 12:03:44 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [subprogram] Definition

At 12:07 AM 5/22/00 +1000, Ryan Heise <ryan@whitewolf.com.au> wrote:
>You have to understand that there are different ways of looking at it.
>For example, you /could/ consider a program defined using the main
>method (Sun's API for Java Applications) generically as a subprogram,
>but I don't. You seem to be requiring that I see things the way you do,
>but there are other ways of looking at it.

In this thread, I am focused on the definition a subprogram and illustrate
a subprogram through its API. If you would like to contribute to the
definition of a subprogram, please do so.

>I will explain why I don't see a Java application as a subprogram, but I
>do not require that you see things my way. In fact, Sun explains it best
>themselves:

Sun Microsystems has done a fine job describing a Java application. They
have clearly defined a standard subprogram API for Java applications. Here
is how the classic JDK works:

1. The top-most program is usually a BIOS. It might always be a form of
BIOS, even when it is microcode.

2. The BIOS uses a subprogram API to launch a foreign operating system
kernel. As we have seen, the start-up sequence for an IBM PC is tedious. It
is this subprogram API which defines a boot sector format. A boot sector
wouldn't work at all without a subprogram API.

3. By whatever means necessary, an end user launches the java tool as a
kernel subprogram. It is this subprogram API which defines an executable
image format, like ELF. A java tool could not be launched without a
subprogram API.

4. The java tool creates a virtual machine. Starting with JDK 1.1.x, the
java tool uses the Java Native Interface (JNI) to run a virtual machine as
a dynamic shared library. By design, a dynamic shared library usually
shares the subprogram API of an executable image format. On Windows, the
java tool and virtual machine share a single machine code process. On
Linux, the java tool and virtual machine might share memory across many
machine code processes, one process for each Java thread.

5. In turn, the classic java tool launches a Java application as a
subprogram. By ignoring how the Java application runs inside a machine code
process, one might think the Java application is the first program running
when, in fact, it is not. Inthe classic model, a Java application is hardly
comparable to a BIOS or kernel.

>Now, you could say that some programs that use this API are subprograms,
>and some are Java applications, but do you think it is right to use the
>same API for two different types of programs*? That would be the
>opposite of strongly typed. Personally, I don't think this API is a
>subprogram API (which explains why I do not think subprogram APIs are
>necessary to invoke an Application in a process)

In the context of a subprogram, all programs that use the Java application
API are subprograms. The definition of a Java application is weak. Any
class that implements static main() is-a Java application.

A subprogram is not a process. In the context of a process, it is something
like what you have said. Most Java applications are designed to run in
their own process. Others are not.

As for using the same API for two different types of programs, we have
talked about this before. When Java programmers write a subprogram, they
should have lots of base classes to choose from. Implement an interface or
extend a base class for that kind of subprogram. This is already true for
applets and servlets. It should be true for daemons, services, etc..

By implementing a well-known interface, a subprogram manager can invoke the
right environment for a subprogram automatically.

For example, the Java application API could be extended to match the
MPCL-compatible virtual machine. Any Java application that does not need a
new process could implement static main() /and/ the subprogram interface.
Then, we can safely assume that every Java application that does not
implement the subprogram interface requires a new process.

>{ * If you want to use it as a subprogram API for specific programs that
>are subprograms, please do. But since Sun says that this is the API you
>use for writing applications, it is incorrect to say a subprogram API is
>needed to run a process. }

A foreign operating system cannot create a machine code process without a
subprogram API. A subprogram API is the defining moment in the life of a
kernel. Without a subprogram API, programmers wouldn't know how to build an
executable image. Without a subprogram API, a kernel would not know how to
fix-up an executable image or what method to invoke after the executable
image had been loaded. A subprogram API determines what method(s) will be
invoked after a new process is created.

In a C program on Linux, there is no mystery. The Linux kernel uses fork()
to "load" an executable. A new process/thread structure is created first,
which affects the kernel's scheduler. Then, a process/thread loads a
subprogram. When oversimplified, a new subprogram seems to load itself. The
kernel expects executables to use the ELF format, fixes up the executable
image, looks for a method called _main() and invokes it.

In contrast, a single-process operating system might create a new process
without creating a new thread. A new "process" is created and a subprogram
is loaded. Here, the equivalent exec() method is a blocking I/O call. The
calling process does not resume until the called process dies.

When Sun Microsystems defined the subprogram API for Java applications,
they made a few well-known assumptions.

1. With a partnership between a virtual machine and a java tool, a virtual
machine would create an environment for a Java application. The environment
of a virtual machine would be equal to the environment of a Java
application. Sun Microsystems created a rule that there must be exactly one
Java application per virtual machine. Also, Sun created a rule that there
must be exactly one primordial class loader per virtual machine.

2. A java tool would expect an arbitrary class name as a command line
parameter. Additional parameters to a java tool would be passed to the
arbitrary class as an array of strings.

3. A java tool would load the arbitrary class and look for a static main()
method. Finally, we get to the subprogram API from the Java programmer's
point of view. When oversimplified, a static main() method of an arbitrary
class is the "first" method invoked by the java tool.

Of course, we know that this oversimplification is not entirely true.
Behind the scenes, the "static" method (<clinit>) for every related class
would be invoked before the first statement inside static main() is invoked.

>Again, it is only required for your way of looking at it. To say it is
>required, period, is to force your views upon others. And this is
>especially unfortunate when you claim someone else's project as a
>dead-end project (ie. that rheise.os can never become a "genuine"
>bytecode process) simply because it does not meet "your" requirements.

Something is required. Something must sit between a process and an
arbitrary subprogram. What else would you have us call it? How would you
explain it? The purpose of this thread is to define it. We need to define
it well enough so that when a programmer writes a JOS-compatible
subprogram, it will run on any implementation of JOS.

Across 50+ years, from the earliest work in machine code to extreme
object-oriented programming of today, "program" and "subprograms" have
become widely accepted terms. Most of the time, precision is not required
and they are used interchangeably. In a "kind-of" relationship, a program
is a kind of subprogram. A Java application is a kind-of program, which is
a kind-of subprogram.

In a structural relationship, a subprogram is "part of" a program. In turn,
that program, as a subprogram, is part of some other program.

A Java application is a subprogram, typically part of a virtual machine. In
turn, a virtual machine is a subprogram, typically part of a java tool. In
turn, a java tool is a subprogram, typically part of a machine code
process. In turn, a machine code process is a subprogram, typically part of
an OS kernel.

A Java applet is a subprogram, typically part of a virtual machine. In
turn, a virtual machine is a subprogram, typically part of a HTML browser.
In turn, an HTML browser is a subprogram, typically part of a machine code
process. In turn, a machine code process is a subprogram, typically part of
an OS kernel.

A Java servlet is a subprogram, typically part of a virtual machine. In
turn, a virtual machine is a subprogram, typically part of an HTTP service.
In turn, an HTTP service is a subprogram, typically part of a machine code
process. In turn, a machine code process is a subprogram, typically part of
an OS kernel.

Now, the structural relationship between a program and subprogram are often
recursive. In theory, a virtual machine simulator and/or prototype can be
written in bytecode. Hang on. It gets weird.

If I write one virtual machine (MC) in machine code and another virtual
machine (BC) in bytecode, I can use MC to invoke BC. In turn, since BC is
written in bytecode, BC can invoke another instance of BC. And so on.

>I did not consider it important that I support the calling of any
>method, not just main, because Sun tells us that the standard way to do
>it is the "main" method.

Sun Microsystems describes how their java tool works. It is a standard way
for a tool called "java" to work.

Within the Java Native Interface Specification, Sun describes this as an
important feature of JNI: the ability to define any method of any class as
the starting point of your JNI-compatible program. Most importantly, this
method does not have to be static.

>I can allow the name of the method to be invoked to be passed in, but
>maybe you can give useful examples of this before I implement it.

There are plenty of examples shown on this mailing list and JOS Wiki. Here
are my favorites.

1. java.lang.Runnable. The simplest instance method for a Java subprogram
is run(). Run is a blocking call. Any class that implements the Runnable
interface can be arbitrarily invoked as a subprogram. In the Java
programming language, it is something like this:

  public void example( String className ) {
    Runnable r = Class.forName( className ).newInstance();
    r.run();
  }

2. java.lang.Component. In a extensive library of components, any class
that extends Component can be arbitrarily invoked as a subprogram. In the
Java programming language, it is something like this:

  public void example( String className ) {
    Component c = Class.forName( className ).newInstance();
    if ( c instanceof Applet ) {
      ShowApplet( (Applet) c );
      return;
    }
    if ( c instanceof Window ) {
      ((Window) c).show();
      return;
    }

    :

    ShowComponent( c );
  }

3. The classes in my subprogram APIs have been explicitly designed with
subprograms in mind. My subprogram APIs has been plugged into the Smart
API, so that any shell can invoke many different kind of subprograms,
including foreign OS subprograms and Java applications. All this and more
is documented on the Smart API pages of JOS Wiki.

A subprogram is not a process. A subprogram API is separate from a process
API, and should be. Subprogram APIs can be used even without new threads,
new class loaders and a new virtual machine.

A process API should create a process first and then invoke any arbitrary
subprogram. A process API should use a subprogram API to invoke any kind of
subprogram once a process has been created. It is my goal to define a
subprogram and sometimes contrast a subprogram and process.

Here are examples of what I would like to do with a process:

  public void example() {
    Runtime.exec( "jrew -classpath ~/debug:$CLASSPATH MyApp" );
    Runtime.exec( "java.awt.Button" );
    Runtime.exec( "MyCustomApplet height=10 width=60" );
    Runtime.exec( "http://www.jos.org/" );
    Runtime.exec( "ftp://mindspring.com/" );
  }

Runtime.exec() might always create a new bytecode process and pass a
command line (a string) to the new process. A "command line" can load any
kind of arbitrary subprogram. When oversimplified, a subprogram would seem
to load itself.





From jewel@pixie.co.za Tue, 23 May 2000 03:40:02 -0200 (GMT+2)
Date: Tue, 23 May 2000 03:40:02 -0200 (GMT+2)
From: John Leuner jewel@pixie.co.za
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> > What exactly will the two java.lang.Class objects be sharing?
> 
> 	A java.lang.Class object, from the native side, is a collection of
> static variables and method definitions, the constant pool, etc -- the
> vast majority of the bulk of the .class file.  Everything but the static
> variables can be shared across java.lang.Class objects.

It's difficult for me to distinguish between the java.lang.Class objects
(which are real java objects), and the native code used to handle
structures.

It sounds like you're putting the native info into the java.lang.Class
object in decaf? This is probably why I'm a bit confused, in my JVM the
native structure (a tClass structure) has an optional pointer to a
pstClassObject, but it isn't neccessary to have such an object.
  
> > Ok, so is the "class definition" separated from the static variables for
> > that class?
> 
> 	Yes -- that's how we distinguish between a class and its
> definition.  I thought we had made that clear. :)
> 
> > This isn't clear in my mind, but do you see what I'm getting at?
> 
> 	Yes.  We're beginning to look into it now.  It's already clear
> that parent classes must be the same, but we need to determine what to do
> about symbolic references...

Because basically they just point to other classes, which have
undetermined origins ...
 
John






From tmiller@haverford.edu Mon, 22 May 2000 23:39:56 -0400 (EDT)
Date: Mon, 22 May 2000 23:39:56 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> It sounds like you're putting the native info into the java.lang.Class
> object in decaf? This is probably why I'm a bit confused, in my JVM the
> native structure (a tClass structure) has an optional pointer to a
> pstClassObject, but it isn't neccessary to have such an object.

	decaf has a class called JavaClass (misnamed) which is the
VM-specific representation of a .class file; that is, it is a java class
definition.  Every JavaClassInstance points to one of these (its class
definition) and to a ClassVariables (?) C++ class which manages the
statics.  Because decaf has not been integrated with a class library as
yet, I don't have a native class which explicitly represents the Java
class java.lang.Class.  When I do, it will be linked in some fashion to
the appropriate JavaClassInstance instance.  (Boy, I /really/ need some
better names.)

> Because basically they just point to other classes, which have
> undetermined origins ...

	Exactly.  Where do symbolic references resolve to for a shared
object?

-_Quinn





From ryan@whitewolf.com.au Tue, 23 May 2000 14:47:39 +1000
Date: Tue, 23 May 2000 14:47:39 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

"Todd L. Miller" wrote:

> > Because basically they just point to other classes, which have
> > undetermined origins ...
> 
>         Exactly.  Where do symbolic references resolve to for a shared
> object?

For the problem of 'where' they resolve to, we have two proposals, so
that shouldn't be hard to solve. But the other issue is much more
difficult: symbolic references in a class definition can be interpreted
differently depending on the particular class that is using that class
definition, and this will make inlining difficult to do.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From tmiller@haverford.edu Tue, 23 May 2000 09:21:59 -0400 (EDT)
Date: Tue, 23 May 2000 09:21:59 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Re: Arch digest, Vol 1 #185 - 7 msgs

> However, it is not ok to share statics between objects that were
> created in different processes. This causes static interference. One
> process should not be able to affect another process *except* through
> a shared object.

	OK.  So our contention is that statics are /always/
process-private?  (e.g. the only objects which can write to a PCL's
statics are the ones 'owned' by it?)

-_Quinn





From tmiller@haverford.edu Tue, 23 May 2000 09:31:34 -0400 (EDT)
Date: Tue, 23 May 2000 09:31:34 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> For the problem of 'where' they resolve to, we have two proposals, so
> that shouldn't be hard to solve. But the other issue is much more
> difficult: symbolic references in a class definition can be interpreted
> differently depending on the particular class that is using that class
> definition, and this will make inlining difficult to do.

	I think we're talking about the same thing.  Every symbolic
reference depends on the classloader it's being resolved in.  I don't
think there's a way around this.  That is, we'd need unique inlines per
process. -- However, in general, because we're sharing class definitions,
the resolution varies only for pointers to statics, which, IIRC, are
resolved not to pointers but to indices into the static table -- which
means the lookup procedure is exactly the same.  (And if I didn't recall
correctly, decaf can be changed to make this the case.  Yes, it's another 
level of indirection, but one that can be cached in most cases.)

-_Quinn






From ryan@whitewolf.com.au Wed, 24 May 2000 00:34:44 +1000
Date: Wed, 24 May 2000 00:34:44 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [subprogram] Definition

Gilbert Carl Herschberger II wrote:

<snipped: 4 examples of programs launching other programs>

> 5. In turn, the classic java tool launches a Java application as a
> subprogram. By ignoring how the Java application runs inside a machine code
> process, one might think the Java application is the first program running
> when, in fact, it is not. Inthe classic model, a Java application is hardly
> comparable to a BIOS or kernel.

A subprogram is a program within a program. This is not implied by a
program launching another program. It seems somewhere along the line you
"extended" your definition of the term to fit your current idea on how
to implement a process API (*)

The distinction between Application and subprogram is necessary to
distinguish programs that are designed to be in other programs. If you
use the term subprogram to refer to them both generically (which you
have (**) ), then you lose that distinction.

(*) ie. to treat everything as a subprogram, and have processes just
execute subprograms. You have already stated that rheise.os does not cut
it in this respect, and that a new process API is needed. If you believe
this, please go ahead and start your own one from scratch.

(**) you mention in this email (to which I am replying) that "a program
is a kind of subprogram. A Java application is a kind-of program, which
is a kind-of subprogram."

> >Again, it is only required for your way of looking at it. To say it is
> >required, period, is to force your views upon others. And this is
> >especially unfortunate when you claim someone else's project as a
> >dead-end project (ie. that rheise.os can never become a "genuine"
> >bytecode process) simply because it does not meet "your" requirements.
> 
> Something is required. Something must sit between a process and an
> arbitrary subprogram. What else would you have us call it? How would you
> explain it? The purpose of this thread is to define it. We need to define
> it well enough so that when a programmer writes a JOS-compatible
> subprogram, it will run on any implementation of JOS.

I call it a mechanism for executing programs inside a process.
[Mis]Defining what a subprogram is gives you a basis for such a
mechanism. I have also invented such a mechanism, different from yours
because of fundamentally different design influences. You can refer to
my past email for the details, but an additional remark I would like to
make is that the mechanism I use considers two types of program APIs,
those that require an instance of a class, and those that don't. The
second category covers Java Applications (and can easily be extended to
support different static method names if that turns out to be useful).
The first category covers servlets and applets (among others), which
incidentally both happen to be subprograms. Unlike in your approach, the
process API does not need to know anything about the object-based
program API (*). Instead, the parent process is given the responsibility
of dealing with the specific program API (eg. applet or servlet). This
is based on the fact that the parent process always knows what type of
program API it is dealing with because it launched it (the interaction
then becomes strongly typed). A tool that can generically launch any
process (eg. SmartAPI) can be built on top of this model.

I'm sure that if you misdefine subprogram, it will work just as well.
Although IMHO it is a way of achieving the same result by
overgeneralising and becoming weakly typed (because of the nature of the
model, not just because of the "subprogram" terminology). But as I said,
I fully understand that your idea will work if you choose to implement
it.

(*) It is probably the case that all object-based program APIs are
subprograms because of the nature of objects (who interacts with them).

> Within the Java Native Interface Specification, Sun describes this as an
> important feature of JNI: the ability to define any method of any class as
> the starting point of your JNI-compatible program. Most importantly, this
> method does not have to be static.

For starters, I don't know whether we are supporting the Java Native
Interface because we are focusing on a pure Java environment. But let's
look at your examples:

> >I can allow the name of the method to be invoked to be passed in, but
> >maybe you can give useful examples of this before I implement it.
> 
> There are plenty of examples shown on this mailing list and JOS Wiki. Here
> are my favorites.
> 
> 1. java.lang.Runnable. The simplest instance method for a Java subprogram
> is run(). Run is a blocking call.

This fits the category of object-based program API. The reason (a
reason) I made the distinction is that object-based APIs can be handled
without reflection and don't need special support within the process
framework. The client can invoke methods directly on the object (whereas
it cannot do that as easily with a static method).

I was asking specifically about invoking static methods other than
'main'. While there are many examples of object-based APIs with all
sorts of methods (applet.start(), applet.stop(), servlet.service()),
there is only one example I can think of for static methods: main. There
is one other example of a static entry point I am aware of (used in the
Javadoc system) but even it does not need the support from the process
framework. However, it opens up the possibility that there "might" be
examples. Can you think of any?

> 2. java.lang.Component.

Another object-based API (which can be interacted with "directly" in
order to remain strongly typed).

> 3. The classes in my subprogram APIs have been explicitly designed with
> subprograms in mind. My subprogram APIs has been plugged into the Smart
> API, so that any shell can invoke many different kind of subprograms,
> including foreign OS subprograms and Java applications. All this and more
> is documented on the Smart API pages of JOS Wiki.

They too are object-based, are they not? However this is the closest we
have come yet to a static entry point. I could imagine you doing certain
of your subprogram types as static APIs. IN THE CASE where you wished to
run those subprograms as processes, then it would be useful to specify a
method name (and arg types) other than main. But then again, why not use
"main" as the method name? In this example, your subprogram is
effectively a "Java Application" anyway. OTOH, you may wish to define
different argument types. Still, perhaps if you wanted to do this,
you're program API would already start diverging from the standard
command-line API (procedural/static entry) that it may as well be an
object..

> Here are examples of what I would like to do with a process:
> 
>   public void example() {
>     Runtime.exec( "jrew -classpath ~/debug:$CLASSPATH MyApp" );
>     Runtime.exec( "java.awt.Button" );
>     Runtime.exec( "MyCustomApplet height=10 width=60" );
>     Runtime.exec( "http://www.jos.org/" );
>     Runtime.exec( "ftp://mindspring.com/" );
>   }

These weakly typed examples can be implemented on-top-of the simpler
mechanism I have proposed (and it makes sense to have the strongly typed
API underly the weakly typed one).

However, since we fundamentally disagree, you may as well roll your own
process API. I never claimed rheise.os to be the standard JOS one. It
can be used by JOS if JOS wants to use it. Choice is good.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Wed, 24 May 2000 09:51:48 +1000
Date: Wed, 24 May 2000 09:51:48 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Re: Arch digest, Vol 1 #185 - 7 msgs

"Todd L. Miller" wrote:
> 
> > However, it is not ok to share statics between objects that were
> > created in different processes. This causes static interference. One
> > process should not be able to affect another process *except* through
> > a shared object.
> 
>         OK.  So our contention is that statics are /always/
> process-private?  (e.g. the only objects which can write to a PCL's
> statics are the ones 'owned' by it?)

I believe so.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Wed, 24 May 2000 09:58:18 +1000
Date: Wed, 24 May 2000 09:58:18 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

"Todd L. Miller" wrote:

> However, in general, because we're sharing class definitions,
> the resolution varies only for pointers to statics,

Can you explain this? I thought that a non-static method call across
class definitions would be resolved differently depending on the
particular class of that class definition. (I admit, I'm getting to the
limits of what I think I know about JVMs)

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From jewel@pixie.co.za Wed, 24 May 2000 13:00:03 -0200 (GMT+2)
Date: Wed, 24 May 2000 13:00:03 -0200 (GMT+2)
From: John Leuner jewel@pixie.co.za
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes


On Tue, 23 May 2000, Todd L. Miller wrote:

> > For the problem of 'where' they resolve to, we have two proposals, so
> > that shouldn't be hard to solve. But the other issue is much more
> > difficult: symbolic references in a class definition can be interpreted
> > differently depending on the particular class that is using that class
> > definition, and this will make inlining difficult to do.
> 
> 	I think we're talking about the same thing.  Every symbolic
> reference depends on the classloader it's being resolved in.  I don't
> think there's a way around this.  That is, we'd need unique inlines per
> process. -- However, in general, because we're sharing class definitions,
> the resolution varies only for pointers to statics, which, IIRC, are
> resolved not to pointers but to indices into the static table -- which
> means the lookup procedure is exactly the same.  (And if I didn't recall
> correctly, decaf can be changed to make this the case.  Yes, it's another 
> level of indirection, but one that can be cached in most cases.)

A bit off-topic, but does the class definition sharing include the
bytecode for the methods?

Reason being that when you overwrite instructions in the bytecode with
_quick variants you might also run into trouble with sharing.

John





From gchii@mindspring.com Wed, 24 May 2000 08:57:20 -0400
Date: Wed, 24 May 2000 08:57:20 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [class types] Proposal

Here is a proposal that might make it easier to discuss classes and their
different types. What is a class? What is a class definition?

Raw bytecode is written by a javac tool and other assemblers/compilers. It
is well-known as an inert collection of octets in a byte array.

BClass - 'B' is for bytecode. This C++ class encapsulates raw bytecode. The
C++ class makes it easy to decode raw bytecode. Instances of BClass can
easily be cached in a bytecode cache and easily shared across class
loaders. This is the type of class that results after loading a class file
into memory. This is the type of class that works with bytecode as a
resource. BClass is stand-alone and cannot be linked to any other BClass.

DClass - 'D' is for definition. This C++ class further refines a BClass.
DClass uses a BClass. Unlike BClass, DClass converts a codepool into
internal structures. If necessary, a constant integer is converted to its
platform-specific form. DClass is stand-alone and cannot be linked to any
other DClass. Without links, a DClass can only be partially compiled into
machine code. Compiled code would depend upon class loader lookup functions
to find other classes.

LClass - 'L' is for Link. This C++ class further refines a DClass. LClass
uses a DClass. Unlike DClass, LClass resolves references to other classes.
An LClass provides Java's "static" fields, since it is fully resolve-able.
It respects the graph of class loaders and uses a lookup function to find
other instances of LClass. With such links, a LClass can be fully compiled
into machine code. Methods of an LClass are actually invoke-able. An LClass
is well-known as the internal, vm-specific form of a class.

JClass - 'J' is for Java. This is a C++ class equivalent to
java.lang.Class. It provides a well-known interface into an LClass. This
class further refines LClass with additional support for the reflection API.

java.lang.Class - This bytecode class is an interface through JClass to an
LClass.

jclass - A jclass is well-known as the exposed, vm-independent form of a C
structure/C++ class found in a native interface, like JNI.

-----

These are class types. Which one is equivalent to a "class definition"?

Understanding a class definition is critical to understanding what can and
cannot be done with a class definition. If a class definition has links to
other class definitions, it interacts with a class loader to look up other
class definitions. In my opinion, a class definition with links (LClass)
cannot be reused by multiple primordial class loaders. A class definition
without links ( DClass) can.

-----

In my opinion, there is great value in caching BClasses because of their
great size and frequent reuse.

In my opinion, BClass and LClass are the most significant. DClass does not
have to be separated out; it can be folded into an LClass. A class
definition without links (DClass) might as well be a base class for a class
definition with links (LClass). The difference between a DClass and LClass
is negligible. Here, I would optimize for size and never actually create a
DClass. Neither LClasses nor JClasses can be shared among multiple class
loaders.





From gchii@mindspring.com Wed, 24 May 2000 09:10:00 -0400
Date: Wed, 24 May 2000 09:10:00 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

At 01:00 PM 5/24/00 -0200, John Leuner <jewel@pixie.co.za> wrote:
>A bit off-topic, but does the class definition sharing include the
>bytecode for the methods?

This is an important part of the discussion about reloading classes.
Understanding a class definition is critical to understanding if class
definitions need to be reloaded and, if so, how often. What is a class
definition? We need to know more.

A bytecode cache includes all the raw bytecode. Therefore, a bytecode cache
shares the original bytecode for methods.

>Reason being that when you overwrite instructions in the bytecode with
>_quick variants you might also run into trouble with sharing.

A virtual machine is not required to implement the _quick variants.  A
_quick variant must never be stored in raw bytecode, like in a class file.

In addition, a "copy-on-write" premise means that each class might convert
the original bytecode into a class-specific form one method at a time. For
a basic implementation of a bytecode interpreter or ahead-of-time compiler,
_quick variants may not be used at all. There are other mechanisms to
optimize methods.

When a class is resolved, it can do whatever conversion it finds necessary.
In MPCL, the original bytecode is never thrown away. It is preserved so
that the same class in another class loader can convert original bytecode
into its class-specific form. It is also preserved so that raw bytecode can
be intern'd for many class loaders. Even while bytecode is shared, a class
is unique. It must be resolved for each class loader.





From tmiller@haverford.edu Wed, 24 May 2000 15:57:13 -0400 (EDT)
Date: Wed, 24 May 2000 15:57:13 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> A bit off-topic, but does the class definition sharing include the
> bytecode for the methods?

	Yes, it does.

> Reason being that when you overwrite instructions in the bytecode with
> _quick variants you might also run into trouble with sharing.

	I'm not doing any _quick rewriting right now; does Sun
(still?) hold the patent on that?  (The first rev of the JVM spec, IIRC,
said that Sun had a patent pending on the technique, and I haven't looked
at it since.)

-_Quinn





From tmiller@haverford.edu Wed, 24 May 2000 19:06:10 -0400 (EDT)
Date: Wed, 24 May 2000 19:06:10 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> Can you explain this? I thought that a non-static method call across
> class definitions would be resolved differently depending on the
> particular class of that class definition. (I admit, I'm getting to the
> limits of what I think I know about JVMs)

	The only thing different between classes sharing class definitions
is their statics; the method code remains in exactly the same place.  If a
class definition A has a call to method M in class B, the method offset
will be the same every time it's called (the rationale behind the _quick
opcodes, IIRC).  The only difference is if class B doesn't share a
definitions everywhere class A shares definitions -- that is, if class B
is class B' in some other process.

-_Quinn






From ryan@whitewolf.com.au Thu, 25 May 2000 09:56:50 +1000
Date: Thu, 25 May 2000 09:56:50 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

"Todd L. Miller" wrote:
> 
> > Can you explain this? I thought that a non-static method call across
> > class definitions would be resolved differently depending on the
> > particular class of that class definition. (I admit, I'm getting to the
> > limits of what I think I know about JVMs)
> 
>         The only thing different between classes sharing class definitions
> is their statics; the method code remains in exactly the same place.  If a
> class definition A has a call to method M in class B, the method offset
> will be the same every time it's called (the rationale behind the _quick
> opcodes, IIRC).  The only difference is if class B doesn't share a
> definitions everywhere class A shares definitions -- that is, if class B
> is class B' in some other process.

That was my point, actually. Have we already assumed that class
definition networks are shared?

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From scribbs@ens.utulsa.edu Thu, 25 May 2000 10:48:27 -0500 (CDT)
Date: Thu, 25 May 2000 10:48:27 -0500 (CDT)
From: Sean D Cribbs scribbs@ens.utulsa.edu
Subject: [JOS-Arch] Static fields/object sharing

Hey guys,

I've followed some of your discussion on sharing objects and the
implications of static fields.  For perspective, one might look at
Serialization, which is, in a way, a method of sharing
objects.  Serialization disregards all static and transient fields of an
object.  This prevents the serialized object from changing the static
fields of other instances when it is deserialized.  So shared objects
could basically have their static fields dependent on the current
process.  This essentially treats shared objects as deserialized objects.

How one gets an instance of a shared object is another story. IMO, the
most elegant way is through an object broker of some kind (whether an ORB
or subscription of some kind).  That way, the broker could manage the
sharing and synchronization problems. The broker could exist outside of
"processes" per se, and could be accessed through JNDI or some other
interface.  I don't know if these last comments apply, they're just some
random speculation on my part.  Since I am not intimately familiar with
the kernel and VM, I cannot make a precise judgement.

------------------------------------
Sean Cribbs <sean-cribbs@utulsa.edu>
Computer Science and Mathematics
University of Tulsa
------------------------------------







From gchii@mindspring.com Thu, 25 May 2000 18:53:00 -0400
Date: Thu, 25 May 2000 18:53:00 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] Static fields/object sharing

At 10:48 AM 5/25/00 -0500, Sean D Cribbs <scribbs@ens.utulsa.edu> wrote:
>I've followed some of your discussion on sharing objects and the
>implications of static fields.  For perspective, one might look at
>Serialization, which is, in a way, a method of sharing
>objects.  Serialization disregards all static and transient fields of an
>object.  This prevents the serialized object from changing the static
>fields of other instances when it is deserialized.  So shared objects
>could basically have their static fields dependent on the current
>process.  This essentially treats shared objects as deserialized objects.

Excellent point. Serialization can be used to pass objects from one
bytecode process to another -- especially in MPCL.

>How one gets an instance of a shared object is another story. IMO, the
>most elegant way is through an object broker of some kind (whether an ORB
>or subscription of some kind).  That way, the broker could manage the
>sharing and synchronization problems. The broker could exist outside of
>"processes" per se, and could be accessed through JNDI or some other
>interface.  I don't know if these last comments apply, they're just some
>random speculation on my part.  Since I am not intimately familiar with
>the kernel and VM, I cannot make a precise judgement.

This is well-known and mature approach to object sharing. Like you said, an
object broker is responsible for managing sharing. I understood a primary
domain (THE system process, known as process 0) would launch a service, a
standard object broker like rmiserver. With this service running, objects
can be shared between bytecode processes and JOS machines.

We've going to have a protocol stack, right? I see no compelling reason to
invent yet another sharing mechanism (YASM). Besides, MPCL was invented to
/prevent/ accidental or automatic sharing of objects.





From ryan@whitewolf.com.au Fri, 26 May 2000 14:00:11 +1000
Date: Fri, 26 May 2000 14:00:11 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Approaches to Object Sharing

Sean D Cribbs wrote:

> For perspective, one might look at
> Serialization, which is, in a way, a method of sharing
> objects.

There are some differences. Consider that object sharing is intended as
a means of collaboration between two or more processes. In the OO sense,
the ultimate in collaboration is the interaction between objects (where
an object groups methods and data). Unfortunately, serialization focuses
only on the data part of an object, and is therefore closer to message
passing where you can pass data objects between two processes by
serializing them. Once an object is deserialized, invoking a method on
it does not allow you to interact with the other process, it only allows
you to access or operate on the data that was sent to you.

This doesn't mean message passing hasn't been proven to be useful. It
has. But in an object-oriented operating system we can aim much higher.

That said, you're right in that serialization may give us some
perspective on the matter. The interesting thing is what to do with
statics and method calls. Serialization means to restrict the full use
of statics and method calls, focussing only on the data in the object.
As a result, we have message passing. Interestingly, we found exactly
the same restrictions in the discussion on how to resolve symbolic
references in true shared objects (in the case that we use the class
loader of the calling thread). More interestingly, in both cases this
restriction occurred because we were trying to pretend that the shared
object belonged to the borrowing process.

There are typically two ways to overcome these restrictions. One is
through direct sharing (with proper object ownership), and the other is
through proxies (RMI uses proxies to provide "almost" complete method
interaction support across processes, and serialization to pass data
arguments to those methods, although RMI could use direct sharing as
well (on a single machine) if we implemented that as a primitive in the
operating system (*) ).

Both direct sharing and proxies have advantages. In terms of elegance,
direct sharing allows true object interaction, meaning that standard OO
programming techniques are not affected in any way. Proxies can provide
a solution that looks "close" to true object interaction, but anyone who
has used RMI will have noticed certain visible difference with proxies
that are hard to ignore.

On the other hand, proxies provide an easy way to deal with process
termination and cleanup because processes are completely separated from
each other. This is not to say that cleanup after termination cannot be
done with a direct sharing model (I have several incomplete ideas), but
proxies certainly provide a way not to have to deal with the problem at
all.

I don't want to discourage further research on proxies, but I should at
least make those interested aware of some of the issues I found when I
was researching proxies.

Simply adding a level of indirection (like weak references) is not
sufficient to ensure that processes remain separate. So things like this
won't work:

class SharedObject
	{
	Object get();
	void put(Object o);
	}

This would work if the client always called
sharedObject.get().someMethod() to maintain the indirection, but a
programmer can always call sharedObject.get() and keep a hold of the
value.

What we can conclude from this is that for proxies to work, the client
process MUST NOT be able to obtain a reference to the real object in the
server process. This means that a proxy class must redefine all the
public methods of the real class, and have them forward method
invocations to the corresponding object in the server process. This is
what RMI does, although it makes it easier by providing a compiler that
can generate the proxy classes for you. It is conceivable that such
proxies could even be generated at runtime in our case by constructing
the byte array on the fly according to the class file format, and
defining a runtime class from it. Still, you have the same problem with
method arguments that you do with RMI. If you serialize them, it does
the client no good if the server updates the state of the method
argument objects. If you want complete object-oriented style
interaction, you need to even generate proxies for these method
arguments.

Since about a month ago, I diverted my attention to using direct object
sharing instead. It has its own share of issues, but they are more
subtle. Restricting access to shared objects is fairly easy to deal
with. Process cleanup is quite complicated (note that the host
implementation of rheise.os intentionally handles process cleanup the
wrong way because it cannot do it the right way. This not a problem with
my design - the native implementation will do things the/a right way).
The more difficult issue has to do a process not being able to be
cleaned up and garbage collected until all other processes let go of its
shared objects. One approach which I have already mentioned is to
reassign ownership of shared objects to a third party (a shared object
broker) so that the initial process can terminate freely. There are also
subtle issues with this (which I think I may have worked out, but I'm
still thinking on it), but my latest thoughts lead me to believe that a
third party may not be required at all (although it would be a good
design choice in many applications).

I hope now I have made clear that proxies are not required, or at least
they have not been proven to be required yet. There are many issues
surrounding shared objects, but there is much to be gained from them if
we can overcome these issues, and that means being able to consider
possibilities that at first seem impossible.

(*) since the behaviour of such an implementation of RMI would be
different from a proxy based one (it would allow you to do more things),
the side effects should probably be clearly documented for that
implementation, ie. you get faster object sharing, but remember that
this is real object interaction - clients are not dealing with a copy,
they are dealing with the real thing. While normal software applications
are designed with this in mind, existing RMI applications might not be.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From gchii@mindspring.com Fri, 26 May 2000 08:37:52 -0400
Date: Fri, 26 May 2000 08:37:52 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] Static fields/object sharing

At 10:48 AM 5/25/00 -0500, Sean D Cribbs <scribbs@ens.utulsa.edu> wrote:
>I've followed some of your discussion on sharing objects and the
>implications of static fields.  For perspective, one might look at
>Serialization, which is, in a way, a method of sharing
>objects.  Serialization disregards all static and transient fields of an
>object.  This prevents the serialized object from changing the static
>fields of other instances when it is deserialized.  So shared objects
>could basically have their static fields dependent on the current
>process.  This essentially treats shared objects as deserialized objects.

The lengthy studies of CORBA and RMI have come to the same conclusion.
Object sharing /is/ the sharing of object properties, not behavior. The
behavior of an object is up to an implementation. Implementations vary from
one platform to another. A class can be implemented in Basic, C, COBOL,
Pascal, etc..

When an "object" is serialized, its properties are copied. The properties
have no behavior in this state. It's inert. An object's data is prepared in
such a way that it can pass through a persistence barrier.

Through CORBA and RMI, a bytecode process can share "objects" with Basic,
C, COBOL, Pascal and other Java applications -- even on other machines.

Bytecode-based agents are the next step in "object" sharing. When an agent
is serialized, both its properties and class files are copied. The
properties and class files have no behavior in this state. It's inert. With
a virtual machine on both ends of a pipe, an agent can be copied from one
virtual machine to another -- without the class files previously installed
on the target machine.

When serialization is complete, there are two copies of an object. The
original object continues to maintain its state. Serialization is like a
photograph, a snapshot. After an object is serialized, its state (data) can
change.

>How one gets an instance of a shared object is another story. IMO, the
>most elegant way is through an object broker of some kind (whether an ORB
>or subscription of some kind).  That way, the broker could manage the
>sharing and synchronization problems. The broker could exist outside of
>"processes" per se, and could be accessed through JNDI or some other
>interface.  I don't know if these last comments apply, they're just some
>random speculation on my part.  Since I am not intimately familiar with
>the kernel and VM, I cannot make a precise judgement.

A process starts out with no access to a shared object. There must be some
mechanism, like an object broker, to provide an isolated process with a
reference to a shared object.

When looking at a traditional file subsystem, a real "file" is always owned
by a system process. A real file is never owned by a user process. When a
process "opens" a file, it is given a proxy for the real "file" in the form
of a file handle. Through the handle, the process can read, write and close
the real file.

If 100+ user processes read from the same file, a system process only needs
one copy of the real file in memory. The user process and system process
must interact in consisten and predictable ways.

When looking at a protocol stack, a real "socket" is always owned by a
system process. A real socket is never owned by a user process. Just like a
file, a user process gets a proxy for the real socket, to read, write and
close it.

Likewise, a bytecode process in an MPCL-compatible virtual machine would
use a ProcessDescriptor as a proxy for all processes. The real process is
owned by the system process (or its agent). When a system process runs an
RMI service, the RMI service owns the real "shared" object. All other
processes interact with a shared object through the service mechanism.
Within an MPCL-compatible virtual machine, a proxy for a shared object
might have a unique handle, just like files, sockets and other system objects.

A bytecode process does not need to know when a CORBA/RMI service is
running in the same or different virtual machine. It does not need to know
when a virtual machine is running locally or across the network. It does
not need to know about an implementation's platform. All of the semantics
(rules) of CORBA/RMI are preserve-able and should be preserved. In the need
for speed, a local service is used exactly the same way -- it only runs faster.





From gchii@mindspring.com Fri, 26 May 2000 09:00:56 -0400
Date: Fri, 26 May 2000 09:00:56 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] Approaches to Object Sharing

At 02:00 PM 5/26/00 +1000, Ryan Heise <ryan@whitewolf.com.au> wrote:
>Both direct sharing and proxies have advantages.

Direct sharing has no advantage at all because it can't be done
predictably, reliably or safely. Nobody really wants rogue objects to cross
the persistence barrier. Nobody really wants that kind of security risk.
After you work out all of the "complexities" of direct sharing, you'll find
that (a) you'll have to introduce some form of proxy to get past the
persistence barrier, and (2) at first, you won't recognize it as a proxy at
all (so that you can continue to claim direct sharing).

It cannot be done predictably because high complexity is full of surprises.
It can't be done reliably because such complexities cannot be fully tested.
It cannot be done safely because the design must be fundamentally changed
with each surprise.

The greatest minds in the software industry have been working on it for 50+
years. It has been tried before. Many distributed computing experts agree
with the proxy and protocol stack approach illustrated by the Internet:
TCP/IP, "serialization" and CORBA/RMI services. It is predictable, reliable
and safe because of its simplicity.





From gchii@mindspring.com Fri, 26 May 2000 09:36:51 -0400
Date: Fri, 26 May 2000 09:36:51 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [JOS Wiki] Articles

JOS Wiki has articles about conserving memory, primordial class loaders and
MPCL. The ProcessPages article is a good starting point for more
information on processes.

Personally, I'm comfortable with researching JOS Wiki articles, arch and
kernel mailing lists. I spend a lot of time reading about what other
members think. What is important? What's not? While we might not always see
eye-to-eye, the JOS Project is an important part of software history.
Without our research, a post-Java platform might make mistakes similar to
Java.

Java's primative data types have clearly demonstrated the folly of pure
object-oriented environments like SmallTalk and Eiffel. Java's class file
format, extreme dynamic linking, interfaces and exception handling are
great. Java's virtual machine approach clearly demonstrates that people
want compatibility with "foreign" platforms (hardware, processors and
operating systems).

1. Java's assumption about one primoridial class loader per virtual machine
is costly; it completely missed the potential of MPCL.

2. Java's assumption about one virtual machine per machine code process is
costly; it completely missed the potential of custom class loaders.

3. Java's assumption about programming in place, jars and "acceptable"
incompatibility is costly; it completely missed Java's ability to write
once and run anywhere. People still want to write once and run anywhere.

This mailing list discussion has contributed three additional things:

1. A virtual machine can take far less memory resources than a classic
virtual machine if it caches bytecode, not classes.

2. A primordial class loader is a cornerstone of a bytecode process.

3. A virtual machine can provide more than one primordial class loader. The
Java Virtual Machine Specification must be modified based on the
implications of MPCL.





From jewel@pixie.co.za Fri, 26 May 2000 16:56:53 -0200 (GMT+2)
Date: Fri, 26 May 2000 16:56:53 -0200 (GMT+2)
From: John Leuner jewel@pixie.co.za
Subject: [JOS-Arch] [vm efficiency] "Reloading" classes

> > A bit off-topic, but does the class definition sharing include the
> > bytecode for the methods?
> 
> 	Yes, it does.
> 
> > Reason being that when you overwrite instructions in the bytecode with
> > _quick variants you might also run into trouble with sharing.
> 
> 	I'm not doing any _quick rewriting right now; does Sun
> (still?) hold the patent on that?  (The first rev of the JVM spec, IIRC,
> said that Sun had a patent pending on the technique, and I haven't looked
> at it since.)

I really don't think you'll run into patent problems. The technique is so
obvious and if you don't use Sun source they will have a hard time
arguing. 

But it helps a lot for speed.

John






From jewel@pixie.co.za Fri, 26 May 2000 17:10:23 -0200 (GMT+2)
Date: Fri, 26 May 2000 17:10:23 -0200 (GMT+2)
From: John Leuner jewel@pixie.co.za
Subject: [JOS-Arch] Static fields/object sharing

> I've followed some of your discussion on sharing objects and the
> implications of static fields.  For perspective, one might look at
> Serialization, which is, in a way, a method of sharing
> objects.  Serialization disregards all static and transient fields of an
> object.  This prevents the serialized object from changing the static
> fields of other instances when it is deserialized.  So shared objects
> could basically have their static fields dependent on the current
> process.  This essentially treats shared objects as deserialized objects.

It is of course possible to use existing Java IPC methods such as TCP/IP
streams with Serialization or RMI, but these mechanisms are much slower
than sharing a class directly in the JVM.

> How one gets an instance of a shared object is another story. IMO, the
> most elegant way is through an object broker of some kind (whether an ORB
> or subscription of some kind).  That way, the broker could manage the
> sharing and synchronization problems. The broker could exist outside of
> "processes" per se, and could be accessed through JNDI or some other
> interface.  

That's the problem, you need quite a bit of complexity to support it, and
the speed won't be great.

>I don't know if these last comments apply, they're just some
> random speculation on my part.  Since I am not intimately familiar with
> the kernel and VM, I cannot make a precise judgement.

John






From gchii@mindspring.com Fri, 26 May 2000 12:05:24 -0400
Date: Fri, 26 May 2000 12:05:24 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] [object sharing] Proof

The state of an object is data, separate from its behavior. The state of an
object can be modified. A class is required to modify the behavior of an
object. An object cannot modify its own behavior.

If O1 is the state of an object, it is not possible for O1 to act upon O1.
Another object is always required. Therefore, if O2 -> O1 then O2 != O1.

The state of an object has a structure. The structure is compatible with
(1) one class or (2) more than one class. If state structure is compatible
with one class, state cannot be modified safely by any other class. If
state structure is compatible with more than one class, the number of
compatible classes is limited. In general, most classes are not compatible
with an object. An object has far more incompatible classes than compatible
classes. Incompatible classes are likely to corrupt the state of an object.

If O1 is the state of an object, C1 and C2 are classes, and C1 is the only
compatible class, then C2 -> 01 is likely to corrupt the state of O1.

If O1 is the state of an object and C1 is an unknown class, then C1 -> O1
is likely to corrupt the state of O1.

When the state structure of an object is compatible with more than one
class, we can use this to copy an object from one platform to another.

If O1 is the state of an object and both C1 and C2 are known to be
compatible with O1, then C1 -> O1, C2 -> O1.

If O1 is the state of an object and only C1 is known to be compatible with
O1, then C2 -> O1 if an only if C1 ~= C2.

C1 and C2 are known to be equivalent if C1 and C2 implement the same
interface. C2 implements the same interface as C1 if C2 extends C1. C2 also
implements the same interface as C1 if both C1 and C2 extend C3.

-----

In Java, C1 and C2 are known to be equivalent if the bytecode for C1 and C2
are identical, equal or equivalent. If C1.bc == C2.bc, their bytecode is
identical. If C1.bc.equals( C1.bc ) but C1.bc != C2.bc, their bytecode is
equal, not identical. (It is a little more difficult to measure equivalence
in bytecode and nearly impossible in machine code.)

Therefore, objects can be safely shared safely across custom class loaders,
and should be. If C1 and C2 are unknown classes, CL1 and CL2 are custom
class loaders, if C1 and C2 are loaded by CL1 and CL2 respectively, then C1
and C2 are known to be equivalent if their bytecode is identical, equal or
equivalent. Since C1 -> O1 is safe and C2 -> O1 is safe, an object O1 can
be safely shared by two class loaders. In this case, the class loader is
irrelevant.

In an applet viewer which runs each applet through a custom class loader,
applets share system classes. This proof shows that applets can safely
share custom classes.

In a servlet runner which runs each servlet through a custom class loader,
servlets shared system classes. This proof shows that servlets can safely
share custom classes.

On the other hand, the purpose of creating multiple primordial class
loaders is to prevent the sharing of any objects between independent
processes. If O1 and O2 are objects, C1 and C2 are their respective
classes, P1 and P2 are bytecode processes, if O1 and O2 are owned by P1 and
P2 respectively, then neither C1 -> O2 nor C2 -> 01 is safe -- even if C1
and C2 are known to be equivalent.

In an MPCL-compatible virtual machine which runs each process through a
primordial class loader, processes do not share system classes. This proof
shows that processes can safely share neither system nor custom classes.

-----

Any bytecode process can copy a primative value to any other bytecode
process. Primative types in Java are sharable across all virtual machines
and all bytecode processes because the machine code "classes" for primative
types are known to be compatible. When object state is broken down into
primative values, an object can be copied from one bytecode process to
another in a mechanism much like serialization. Within a vm, this would be
superfast.

Since a message is always a collection of primative types and any call to a
method can be converted into a message, an object in one process can invoke
a method in another process by simple message passing. Any user process
passes a message to the system process. In turn, the system process passes
a message to any user process. And that is how object state is shared.





From tmiller@haverford.edu Fri, 26 May 2000 14:12:26 -0400 (EDT)
Date: Fri, 26 May 2000 14:12:26 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Approaches to Object Sharing

> Direct sharing has no advantage at all because it can't be done
> predictably, reliably or safely.

	It would make discussion much more pleasant if you'd avoid
sweeping pronouncements like this.  Within certain limits, we've already
shown that direct sharing will work predictably and safely.  (I won't
address reliably because I'm not sure what you mean by it.)  Predictably
-- the shared object functions identically to shared memory.  Safely --
our focus from the first has been safety (specifically, type safety).  We
can adopt more stringent standards as necessary, in particular requiring
byte-for-byte equivalance between the class definitions in two different
processes.  If necessary, we can require that there be no statics.  The
safety of the system is ensured by the exact same mechanism that secures
it without sharing, via the object broker.  (That is, if you ask for a
system object, the broker will perform certain security checks; a shared
object generated in some other process and accessed via that broker will
be indistinguishable from a system object generated by the broker itself.)

> The greatest minds in the software industry have been working on it
> for 50+ years.

	And they came up with Smalltalk and its relatives, which do direct
object sharing without any problems.  Smalltalk, obviously, is much more
flexible than Java.  (So much so that I tend to think of Smalltalk more as
goo-oriented programming than object-oriented -- but that's another
story.)  The other reason to avoid direct object shares in distributed
systems is that shared memory doesn't scale.  However, our target
enviroment is a shared-memory architecture.  (From this POV, the # of
processors is irrelevant; just that N processes share the same physical
memory space.)


	More in the next mail.

-_Quinn





From tmiller@haverford.edu Fri, 26 May 2000 20:42:26 -0400 (EDT)
Date: Fri, 26 May 2000 20:42:26 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] processes & properties vs behaviors

[This will take a while.]

Processes/

	Processes exist to protect concurrent sequences of operations
('executing programs') from each other, the most significant process(es)
of all being the operating system.  The primary model/method of
concurrency in Java is threading.  When properly initiated, threads may
not interfere with each other except via static methods or variables.

	Threads & Interference/
	
	Consider your generic Runnable Object as a node in a dataflow
	graph.  We will examine only instance methods and
	variables.  Looking at Runnable, we see the void method
	run().  Nothing can escape there.  Looking at Object, the only
	possible problem is getClass(), which returns an object generated
	by the VM.  (The java.lang.Class instance of the class of the
	Runnable Object we're examining.)  Since we're ignoring statics,
	we can assume that whatever changes may be made to the Class
	do not escape.  (That there are no other references to this
	particular Class instance.)  Clearly, this Runnable Object and
	it branch in the graph can not interfere with a Runnable Object
	elsewhere in the graph.  If it generates a Runnable Object,
	it could, but that's the programmer's problem, not ours.  (Unless
	that Runnable Object is designated as a process, which we'll
	address later.)

	To continue: it is necessary and sufficient that for statics to be
ignored to protect from threads from themselves.  Furthermore, it is
necessary and sufficient for statics to be ignored to meet the definition
of 'process.'  (This is the basis of of our discussion about processes so
far.)  That is, aside from statics, example A is sufficient for the
concurrency and protection required in an operating system.

	Example A/
	
	public class RunMain implements Runnable extends Object {
		Class c;
	
		public void run() {
			/* execute main() method from class c,
			   generating the arguments locally. */
			} /* end run() */
		} /* end class RunMain */

	public class OS {
		public static void main( String[] argv ) {
			while( true ) {
				RunMain rm = new RunMain();
				rm.c = getNextRequest();
				Thread.start( rm );
				}
			} /* end main() */
		} /* end class OS */


Statics/

	Statics, of course, may not be ignored.  The simplest solution is
to modify the OS class to spawn a new classloader for each request; that
way, every thread not started by an application will have its own set of
statics.  This, to my understanding, is the esssence of rheise.os; it can
also be terribly inefficient.  With a variety of methods we've described,
the non-static portions of classes (the class 'definition', in whatever
form) -- that is, the ones which are redundant across processes, which is
equivalent to saying read-only -- can be shared, reducing that redundancy
to the bare minimum.

Shared Objects/

	Sharing objects between threads is a well-defined operation; a
reference is simply copied from one variable to another.  The reference
takes care of sharing the /properties/ of an object; the runtime system is
responsible for sharing the object's /behaviors/ -- performing the lookup
of its class and that class's symbolic reference.  On occasion, the class
of an object will compared to the type of a variable.  (For instance,
assignment to a field, or usage as a method parameter.)  It is in these
cases that the runtime system (JVM) can look up the class of a shared
object and discover that it doesn't match, having been loaded by another
classloader.  An exception is thrown, and we move on.

	However, threads in different processes will always have different
classloaders, leading the JVM to conclude that the classes are different,
even if their bytecode definitions are identical.  Here we come to our
current controversy.

Properties and Behaviors/

	We have already established the ability to share object
properties.  The equivalance of mechanisms for 'common-value' IPC are well
understood, so I will take the position that we are using shared memory to
communicate the properties of an object.  What we are attempting to
establish is something very basic to Java -- the ability to share object
behaviors.  There are three approaches.  The first is to hope that the
other process* has the 'right' behavior, and just send the properties
over.  The Serializable protocol takes this approach.  RMI, to my
understanding, takes the opposite approach and ensures behavior
compatability at compile-time.  Finally, you can ensure behavior by
sending the behavior -- the classfile** -- along with the properties.

	Footnotes/

	*  Which could be separated in space or in time == orthogonal
	   persistence/serialization.

	** Incidentally, since the classfile doesn't store the 'current'
	   value of its static variables, you could take the position
	   that static variables are a (shared) /property/ of an object.  
	   This supports Ryan's position, which I think I agree with now.

	A shared object, then, always references its original static
variables, as they are a (shared) part of its properties.  If we ensure
that the class definitions are identical (as a precondition for sharing),
it doesn't actually matter which set of behaviors (which have been reduced
to be defined as to methods) we use; in fact, if the JVM utilises sharing,
it will only have one (shared) set to use.

	(That is, shared objects depart from the other two types of IPC in
both implementation and in kind, which is what makes it worth discussion.)

	Clearly, if the class definitions are identical, properties will
be maintained, so long as statics (e.g. the classloader) are (is)  
considered a property of the object.  Clearly, if the class definitions
are identical, the behaviors (as we've reduced to and then defined as the
methods) will be identical.  Clearly, the interpreter itself will be
unable to distinguish between a shared object and one solely belonging to
the current process (thread) under these conditions; so it is clearly safe
to share them.  Our sole bending of the specification would be to consider
identical classes to be the same despite classloader differences in the
sole instance where they were loaded in different processes.

However/

	In the previous discussion, I have considered 'the methods' and
'the fields' of a class as a lump unit.  This is not exactly the case,
which has caused some discussion on this list.  In short, the logic above
requires that 'the methods' and 'the fields' include super classes and
interfaces to be recursively identical as well.  In general, this
requirement should not be hard to satisfy; a parent is identical if and
only if all of its parents are also identical, so we won't have to do very
deep searches.  Furthermore, the normal flow of starting a new process
will generate sharing data at all of the leaves of the inheritance graph
as it goes.  (In fact, we should be able to install a further optimization
-- in most cases the loader and the classpath will be the same, which
means we won't even have to check before start sharing.)

Further concerns/

	Each archive-version pair has its own tree of shared / shareable
class definitions, which can freely inline code from each other.  Even
just this amount of inlining will allow us to optimize the vast majority
of code; Java class libraries are or can be distributed as archives, and
likewise for the JOS class libraries, and most applications.  Where you
get hurt it is in separate classfiles (whose directory could be considered
an archive?) doing development work, where you don't expect performance
anyway.

	In general, adaptive and JIT compiling systems can only optimize
on a per-process basis.  Where there might be an opportunity to optimize
in the application/OS interaction may not exist in another
combination.  It may be well worth it to optimize these interactions even
at the cost of maintaining multiple codebases in memory.  (Strictly, since
JIT is compiling, it can operate on a per-program basis; we just happen to
be running the compiler/optimizer much later than is conventional.  This
is why sharing code between processes will work at all.  However, the
dynamic linking can only be optimized as it happens, which means on a
per-process basis.)

-_Quinn






From donaldp@mad.scientist.com Sat, 27 May 2000 15:20:39 +1000
Date: Sat, 27 May 2000 15:20:39 +1000
From: Peter Donald donaldp@mad.scientist.com
Subject: [JOS-Arch] rheise.os-0.1.4-pre4 on java2 ?

Hi,

this could be a stupid question but how do I actually get the environment
to run under java2 ? I figured I would just have to make the bootclass
prefix the path to rheise.os classes but that doesn't seem to work (It
gives stack error) because I suspect loading from filesystem and a sealed
jar archive made it go awry ??

I tried un-jaring bootclasses (like rt.jar) but I still get a stack fault
while loading classes (specifically java.lang.Object).

I tried it on 1.2/1.3 on win32 (Both sun vms) and 1.2/1.3 on linux (sun and
ibms vms). Any hints ?


Cheers,

Pete

*------------------------------------------------------*
| "Nearly all men can stand adversity, but if you want |
| to test a man's character, give him power."          |
|       -Abraham Lincoln                               |
*------------------------------------------------------*




From ryan@whitewolf.com.au Sat, 27 May 2000 15:55:15 +1000
Date: Sat, 27 May 2000 15:55:15 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] rheise.os-0.1.4-pre4 on java2 ?

Peter Donald wrote:

> this could be a stupid question but how do I actually get the environment
> to run under java2 ? I figured I would just have to make the bootclass
> prefix the path to rheise.os classes but that doesn't seem to work (It
> gives stack error) because I suspect loading from filesystem and a sealed
> jar archive made it go awry ??

The rheise.os/classes should always appear in your classpath *after* the
system classes. With jdk 1.2 you can actually exclude the system classes
from your classpath and the JVM will make sure the system classes are
always loaded first. I recommend doing this since the currently released
version of rheise.os assumes that your system classes are called
classes.zip (as in jdk1.1). If you want to have rt.jar in your
classpath, you will need to fix your copy of
src/josp/process/host/HostProcessClassLoader.java as instructed in the
readme file.

Note that I have only tested this on Linux. I can verify that jdk 1.1
works fully, and jdk 1.2 works partially (no graphics support). I
haven't yet sorted out the issues with ibm's jdk 1.3, which are
apparently similar to the issues people have been having with windows
(security related errors), but it will be a while before I look at those
(and there's no guarantee I can get it working on Windows since I don't
have a copy of any of microsoft's operating systems)

So, try those two suggestions, and if that doesn't work maybe you can
copy and paste the actual error messages.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From jewel@pixie.co.za Sat, 27 May 2000 12:27:44 -0200 (GMT+2)
Date: Sat, 27 May 2000 12:27:44 -0200 (GMT+2)
From: John Leuner jewel@pixie.co.za
Subject: [JOS-Arch] processes & properties vs behaviors

> 	Threads & Interference/
> 	

Just want to mention that we should think about synchronisation too. What
happens when two threads from different processes try to enter a monitor
on a shared object.

What implications for MP machines, or for distributed processes / threads
etc ...

John






From tmiller@haverford.edu Sat, 27 May 2000 16:34:34 -0400 (EDT)
Date: Sat, 27 May 2000 16:34:34 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] processes & properties vs behaviors

> Just want to mention that we should think about synchronisation too. What
> happens when two threads from different processes try to enter a monitor
> on a shared object.

	I think they just act as two threads from the same process
would...

-_Quinn





From ryan@whitewolf.com.au Tue, 30 May 2000 00:30:01 +1000
Date: Tue, 30 May 2000 00:30:01 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Extending the type system

* Part II *

"Todd L. Miller" wrote:

>         ** Incidentally, since the classfile doesn't store the 'current'
>            value of its static variables, you could take the position
>            that static variables are a (shared) /property/ of an object.
>            This supports Ryan's position, which I think I agree with now.

This is part of a broader observation that classes should not be shared.
I have spent most of the weekend trying to justify this conceptually
because as it stands, what I am proposing seems to undermine Java's type
system. I think that is part of what Gilbert was trying to get across
(although I didn't quite understand the rest).

Firstly, why shouldn't classes be shared? One would think that the most
straightforward approach to direct object sharing is to share the
object's Class between the participating processes (or even just
programs) so that type equivalence is done without undermining the type
system. This can be done by having shared classes loaded by a common
class loader. This is the UNIX shared memory model _Quinn was mentioning
earlier (both the object and class (ie. statics) are shared in memory in
a 'single' location).

To see how such a solution might work, let's look at an old design I
posted a while ago:

=====
I could imagine a server process that corresponds to an ORB (Object
Request Broker), and a findSharedClass(domain, class) method that defers
loading to the ORB's class loader for the specified domain*. Once
loaded, the class still cannot be redefined in that class loader, but
you can then call orb.reload(domain) which will cause the ORB to replace
its class loader for your particular domain.

{*} domains would correspond to the individual uses of IpC. For example,
you could define a domain for doing IPC between the window manager and
processes that wish to draw to a window.
=====

The general design here is fine (although I'd improve orb.reload() now).
The concept of domains allows for two separate IPC channels to coexist
using different versions of the same classes since each domain has its
own class loader. But what is wrong with this particular implementation?
(that is, assuming you understand the benefits of direct object
sharing?)

It turns out that sharing classes to ensure proper type equivalence when
sharing objects does not work in practice (or at least that seems to be
the case). A single process is unable to do IPC with two server
processes where both server processes are of the same type, but are
being used for different purposes. In this case, each server process
will set up a different domain with the ORB, and therefore each server
process will load its own class for the shared object. When my
application wants to do IPC with both of those server processes, it is
only able to load a single class to reference both shared objects. It
needs two, but it can only use a certain class name once. Using Java's
type system, we are unable to achieve direct object sharing with the two
servers this way.

By allowing two classes that share the same class definition to be
treated as the same for shared objects, we get around this problem (the
exact semantics of this have already been discussed). What we are aiming
for is a way to keep processes separate with their own classes (as in
CORBA) but to provide an efficient interface to server objects in a
server process. Because of Java's type system, the Class the client uses
to interface with the server object should not be the same as the Class
in the server (as demonstrated in the above example). However, we want
to treat both classes as the same *type*.

And here we come to the point of this email. My original goal was to
justify our bodgy type equivalence based on class definitions. I am
proposing that we extend Java's type system as follows: two classes may
(*) be of the same type (**) if they both share the same class
definition. The same type may be used in different processes but the
same class may not. An object may be cast between two classes of the
same type.

(*) The exact semantics are left to discussion. Hint: what type do you
assign to classes loaded by custom class loaders?
(**) The word "type" is open to debate. Upon first glance of the
relevant section of the vm spec (chapter 5), my use of the term seems to
fit in without any confusion. If you find there is some confusion, it is
entirely possible to select a different word.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From Matt.Albrecht@trilogy.com Mon, 29 May 2000 09:34:49 -0500
Date: Mon, 29 May 2000 09:34:49 -0500
From: Matt.Albrecht@trilogy.com Matt.Albrecht@trilogy.com
Subject: [JOS-Arch] Static fields/object sharing

Gilbert Carl Herschberger II wrote:
>
>We've going to have a protocol stack, right? I see no compelling reason to
>invent yet another sharing mechanism (YASM). Besides, MPCL was invented to
>/prevent/ accidental or automatic sharing of objects.

Just a small point regarding this.  Yes, we need a protocol stack, but
that's a shared resource for the OS.  How will we share the protocol stack
between processes, when we need a shared protocol stack to share objects?

Maybe I'm missing something, but it seems to me that there needs to be a
bare minimum object sharing mechanism built into the kernel / process
system, so that more robust sharing models can be built up from that.  We
can always make that low-level object sharing mechanism highly protected so
only "process 0" can have access to it.  But still, there needs to be a
basic, built-in system to start everything out right.


Matt

Colonel Edwards: This is the most fantastic story I've ever heard.
Jeff Trent: And every word of it's true, too.
Colonel Edwards: That's the fantastic part of it.
-- Plan 9 From Outer Space









From ryan@whitewolf.com.au Tue, 30 May 2000 12:15:20 +1000
Date: Tue, 30 May 2000 12:15:20 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Approaches to Object Sharing

Gilbert Carl Herschberger II wrote:
> 
> At 02:00 PM 5/26/00 +1000, Ryan Heise <ryan@whitewolf.com.au> wrote:
> >Both direct sharing and proxies have advantages.
> 
> Direct sharing has no advantage at all

>From a language perspective, direct sharing makes things easier for the
programmer than proxies (Java itself uses direct sharing rather than
proxies because it is more useful. It should at least be worth
considering the same level of usefulness in shared objects). A "direct"
approach is also more efficient (suppose you wanted to share an instance
of java.awt.Graphics?)

> because it can't be done predictably, reliably or safely.

Direct sharing involves:

- extending the type system
- distributed memory management

We have almost completely specified the first so that it behaves
predictably, reliably and safely.

I have been working on completely specifying the second to behave just
as predictably, reliably and safely. If this "cannot" be done, I may as
well give up. Is this what you are suggesting?

> Nobody really wants rogue objects to cross the persistence barrier.

If you want to break the "persistence barrier" it helps to think of it
in different ways. As long as you think of it as a "persistence barrier"
it is going to remain a barrier.

> After you work out all of the "complexities" of direct sharing, you'll find
> that (a) you'll have to introduce some form of proxy to get past the
> persistence barrier, and (2) at first, you won't recognize it as a proxy at
> all (so that you can continue to claim direct sharing).

I'm not convinced.

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From ryan@whitewolf.com.au Tue, 30 May 2000 12:36:37 +1000
Date: Tue, 30 May 2000 12:36:37 +1000
From: Ryan Heise ryan@whitewolf.com.au
Subject: [JOS-Arch] Static fields/object sharing

Gilbert Carl Herschberger II wrote:

> When looking at a traditional file subsystem, a real "file" is always owned
> by a system process. A real file is never owned by a user process. When a
> process "opens" a file, it is given a proxy for the real "file" in the form
> of a file handle. Through the handle, the process can read, write and close
> the real file.

In the past I once made a comment that both proxies and direct sharing
are useful to the programmer. Proxies are often inherent in the design
of some applications. However, it would be unfortunate to be forced into
using proxies when a design suggests they are not ideal. Why should we
have to always use proxies?

-- 
Ryan Heise

http://www.progsoc.uts.edu.au/~rheise/





From gchii@mindspring.com Tue, 30 May 2000 11:15:27 -0400
Date: Tue, 30 May 2000 11:15:27 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] Static fields/object sharing

At 09:34 AM 5/29/00 -0500, Matt.Albrecht@trilogy.com wrote:
>Just a small point regarding this.  Yes, we need a protocol stack, but
>that's a shared resource for the OS.  How will we share the protocol stack
>between processes, when we need a shared protocol stack to share objects?

Let's clarify the difference between data sharing and object sharing. Data
sharing is the sharing of (in Java) primative values. Both primatives and
primative arrays can be shared among virtual machines with impunity. Why?
Because the well-known "classes" for primatives are written in machine
code. Data sharing is very easy. Data sharing is akin to shared memory.

A protocol stack needs a mechanism of shared data. It uses the same model
that already exists in a classic virtual machine. A user process sends data
to the protocol stack through the native methods of java.net. A unique copy
of java.net is owned by each bytecode process. A "packet" is an array of
bytes. It is easy to send a packet within a MPCL-compatible virtual
machine. A packet is copied from a user process to the system process, from
the system process to a user process. The implementation of a function like
arraycopy() of the java.lang.System class is implemented the same way no
matter how many primordial class loaders there are.

Data sharing (shared memory) is easy. Object sharing is not so easy.

Objects can be shared by proxy. A proxy mechanism reduces the puzzle to
data sharing again. State informaiton is "shared" -- just like
serialization -- by encoding and decoding primatives. By proxy, the object
"type" remains the same even though the "class" can be different. A class
is an implementation of a type. Each class must be compatible with its
type. A proxy always uses a primative, like an int or long, as a handle to
the real object.

>Maybe I'm missing something, but it seems to me that there needs to be a
>bare minimum object sharing mechanism built into the kernel / process
>system, so that more robust sharing models can be built up from that.  We
>can always make that low-level object sharing mechanism highly protected so
>only "process 0" can have access to it.  But still, there needs to be a
>basic, built-in system to start everything out right.

The protocol stack is a bare minimum data sharing mechanism. Once you have
data sharing, you automatically get object sharing by proxy. We can run a
standard CORBA or RMI service on top of a protocol stack. Nothing else is
needed.





From gchii@mindspring.com Tue, 30 May 2000 12:09:16 -0400
Date: Tue, 30 May 2000 12:09:16 -0400
From: Gilbert Carl Herschberger II gchii@mindspring.com
Subject: [JOS-Arch] Approaches to Object Sharing

At 12:15 PM 5/30/00 +1000, Ryan Heise <ryan@whitewolf.com.au> wrote:
>If you want to break the "persistence barrier" it helps to think of it
>in different ways. As long as you think of it as a "persistence barrier"
>it is going to remain a barrier.

Through my experience with distributed computing, I have learned to treat
the persistence barrier with great respect. Like a ten foot thick brick
wall, I only hurt myself to think it isn't really there. Thinking of it as
a barrier helps me identify workable solutions.

-----

Imagine we have two stand-alone computers.

Let's put a physical barrier between these two machines. We build a brick
wall between them. We make it ten feet thick.

Now, we have two stand alone computers, separated by physical space.
Nothing from the one computer comes in contact with the other. (No network;
no modem; no USB; no serial, parallel or fiber optic cable; nothing
cellular; nothing infrared; etc., etc..)

It is safe to say that software running on one machine could not possible
affect the software running on the other. When this is what we want, this
is a good thing.

-----

Imagine we have two stand-alone Java applications.

We could run a stand-alone Java application on each machine. A Java
application running on one machine could not possible affect a Java
application running on the other. When this is what we want, this is a good
thing.

-----

Imagine we have two stand-alone Java applications again, but this time,
have only one stand-alone computer. When this is what we want, this is a
good thing.

How can we do it? We need a virtual machine. In this case, I'm saying
"virtual machine" in the generic sense, not a Java Virtual Machine.

Let's put a conceptual barrier between these two virtual machines. We must
work hard to maintain the illusion of two stand-alone machines. We build a
machine code wall between them. We make it "thick" so that there can be no
accidental or malicious contact between them. As a rule, no data is shared
and objects are not share-able. A Java application running on one virtual
machine could not possible affect a Java application running on the other.

The persistence barrier is a conceptual barrier between physical machines.
It is not imaginary. Its properties are not an illusion. Like a brick wall,
it exists between every kind of computing device ever made. Many mechanisms
have been invented to punch "holes" through the persistence barrier. No
mechanism can tear it down. For more information, see also the
PersistenceBarrier article on JOS Wiki.

As always, a multiple tasking system must (1) put up a complete persistence
barrier and then (2) carefully punch "holes" through it. A protocol stack
is a widely accepted way to punch a hole through a persistence barrier. It
works. It is simple. It is fully test-able and therefore, can be made
highly reliable. Since data is always piped through a FIFO queue, it is
very predictable. It made the Internet possible.

MPCL was designed to put up a complete persistence barrier between bytecode
processes. MPCL is a brick wall, ten feet thick. If we start with the
assumption that Java primatives and only Java primatives can shared between
bytecode processes, we can immediately build a useful MPCL-compatible
machine. A primordial class loader seems to be the cornerstone of the
illusion of a Java application running on its own stand-alone machine.

Let's punch one "hole" for a protocol stack. When we implement the native
methods of java.io, it forms a hole in the persistence barrier so that
"packets" can pass through. Since CORBA and RMI already run on top of a
protocol stack, we automatically inherit industry-standard object sharing.





From tmiller@haverford.edu Tue, 30 May 2000 18:43:13 -0400 (EDT)
Date: Tue, 30 May 2000 18:43:13 -0400 (EDT)
From: Todd L. Miller tmiller@haverford.edu
Subject: [JOS-Arch] Static fields/object sharing

> A protocol stack needs a mechanism of shared data.

	Strictly speaking, you only a need IPC, not shared data.  (Unless
I'm accidentally/incorrectly conflating shared data and shared memory.)  
Message-passing will work just fine.  (In the work I've been doing,
message passing is usually the preferred API for data concurrency because
it can be implemented very efficiently for 'inside the box' computing, and
translates very cleanly to the network model for 'outside the box'
computing.  It is, however, more work than data sharing.)

> Data sharing (shared memory) is easy. Object sharing is not so easy.

	From the programmers P.O.V., I must disagree entirely.  I would
find it much easier to share an object than write de/serialization methods
for it.  If I'm making good use of OOP, I'm working with objects, not
data.

> Objects can be shared by proxy. A proxy mechanism reduces the puzzle
> to data sharing again.

	What happens if we generate a JavaObject on the share, as if a
'new' instruction were executed, but with its instance variable pointer
the same as the shared object's?  Clearly, the proxy would automatically
synchronize with the shared object.  The type safety of each JVM is
guaranteed because neither JVM uses the other's class(es).  (Though their
definitions/bytecode may be shared.)  The only requirement imposed by
sharing instance data is that the two classes have identical fields in
identical locations; otherwise, the JVM's behavior will be erroneous.

	We could then consider ensuring 'correct' behavior across the two
processes the domain of library or application code.  (However one might
ensure that the classes (methods) loaded by two different process are the
same; the API is still indeterminate/undecided.)  This would include
ensuring 'proper' parent classes.

	Two questions remain.  First, what about objects whose fields are
in turn objects?  Second, what about statics?

	Shared objects must recurse if they are to be transparent.  
Before an operation can be performed with or on an object, its reference
must be pushed onto the operand stack.  This provides an opportunity to
check if that reference is inside the current process.  (That is, if it
has the same (primordial) classloader as the method's class.)  If it's
not, we execute an implicit share.  (Yes, this means our security model
can't be as tight as would be otherwise, since this share must succeed.)  
Otherwise, since objects and (these) proxies are indistinguishable, we
just carry on.

	This does, however, mean that the proxy will be accessing the
statics within its process.  We may be able to work around this; I wanted
to get the idea out and checked for big gaping holes before I spent too
much time on it.  The key thing that makes this look like a good idea may
be that it's less restrictive than the object sharing we had been
discussing, but less objectionable than an explicity proxy approach.

	Gilbert, if you've been advocating an implicit proxy approach, my
apologies.  It would, however, make your positions on what to do more
clear (and convincing) if they included how to do, as well.

-_Quinn

* By which I mean, once the object is acquired, it behaves identically to
a non-shared object.

** RMI uses by-value rather than by-reference parameter
passing; additional exceptions are defined for RMI method invocations; RMI
only works for interfaces; and there are limitations on remote objects
passed as arguments to an RMI invocation.







From sean-cribbs@utulsa.edu Tue, 30 May 2000 21:14:08 -0500
Date: Tue, 30 May 2000 21:14:08 -0500
From: Sean D Cribbs sean-cribbs@utulsa.edu
Subject: [JOS-Arch] Object sharing

I think the discussion on object sharing between processes is very
interesting, but people aren't necessarily considering one aspect:
What _actually_ needs to be shared?

I believe there are a few obvious things that _need_ to be shared:
* Protocol stack
* Toolkit and other AWT junk
* Other system services

But seriously, these things can be handled with static calls.  I realize
that we are trying to separate processes, but they are still essentially
in the same VM.  The only problem with keeping it all open is the need to
separate multiple users.

If we assume we have a ten-foot thick brick wall like Gilbert suggests,
and those things listed above are provided to each process (either
directly or through proxy), I see no need to "share" objects other than
through message passing.  If what you really want is a way to pass
information, use pipes or FIFOs or messages or sockets.  They can be
implemented so that you achieve nearly the speed of direct sharing,
without worrying about obtaining a lock on an object. Or if you want the
completely-separate approach, use RPC(RMI).

If my argument here is completely off-base, would someone please explain
to me the distinct advantages and uses of direct sharing?

------------------------------------
Sean Cribbs <sean-cribbs@utulsa.edu>
Computer Science and Mathematics
University of Tulsa
------------------------------------




