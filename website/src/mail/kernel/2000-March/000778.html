<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [JOS-Kernel] Systematic</TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:tmiller%40haverford.edu">
   <LINK REL="Previous"  HREF="000770.html">
   <LINK REL="Next" HREF="000761.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[JOS-Kernel] Systematic</H1>
    <B>Todd L. Miller</B> 
    <A HREF="mailto:tmiller%40haverford.edu"
       TITLE="[JOS-Kernel] Systematic">tmiller@haverford.edu</A><BR>
    <I>Tue, 21 Mar 2000 21:34:27 -0500 (EST)</I>
    <P><UL>
        <LI> Previous message: <A HREF="000770.html">[JOS-Kernel] Systematic</A></li>
        <LI> Next message: <A HREF="000761.html">[JOS-Kernel] I'm writing a report</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#778">[ date ]</a>
              <a href="thread.html#778">[ thread ]</a>
              <a href="subject.html#778">[ subject ]</a>
              <a href="author.html#778">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>&gt;<i> Ah, you have misunderstood my words... I do not mean that we should
</I>&gt;<i> strive to make application mimic real world object, I am saying that the
</I>&gt;<i> *interface* to applications should be the best possible blending into
</I>&gt;<i> the real world. Speech is better than gestures (mouse), which in turn is
</I>&gt;<i> better than typing. Until natural language is understood by computers,
</I>&gt;<i> the mouse is the next best thing (IMHO, of course!)
</I>
	As an aside, research being done in &quot;multimodal&quot; interfaces
suggest that speech is almost only useful when combined with a 'gestural
interface' (either a mouse, a touchscreen, or some other higher-tech
solution like real-time video analysis), because there is no consistent
naming for on-screen objects between people, between a person's different
sessions using the computer, and in many cases, after shifting between
tasks.  The gesture is necessary for selection.  This suprised a great
many of the researchers, who were only expecting problems in determining
pronoun references (though gestural input helps here, too).  (As another
aside, since I can type an order of magnitude faster than I can talk, I'm
likely to keep using the keyboard long past when speech recognition is
effective.  Also, it's easier to shift a finger over and hit backspace (or
ctrl-h/ctrl-d, whatever) then speak corrections, for me, anyway.)

	&quot;the interface should to applications should be the best possible
blending into the real world&quot; is a good way of phrasing it -- though one
must be careful to remember that applications are not 'real'.  One
interesting idea -- inspired by the smalltalk(IIRC)-based 'reality
toolkit' demonstration -- is to give interface elements inertia, and
redefine mouse motions to be accelerations, so that you could 'fling'
windows into the corners or push them out of the way without having to
worry about placing them exactly.  Other elements of the reality toolkit
would be worth investigating also; especially if 'require' applications to
be JavaBeans, it shouldn't be too hard to set up controller/reciever links
between applications in an intuitive fashion with more precision than just
pipes.  (Although this would probably be more useful with application
components, given how large and tightly-bound most graphical applications
are.)  I guess we'll find out :)

-_Quinn




</pre>







<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI> Previous message: <A HREF="000770.html">[JOS-Kernel] Systematic</A></li>
	<LI> Next message: <A HREF="000761.html">[JOS-Kernel] I'm writing a report</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#778">[ date ]</a>
              <a href="thread.html#778">[ thread ]</a>
              <a href="subject.html#778">[ subject ]</a>
              <a href="author.html#778">[ author ]</a>
         </LI>
       </UL>
</body></html>
